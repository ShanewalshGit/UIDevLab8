{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0d831181-2971-518c-9d49-2af4b48d522b"
   },
   "source": [
    "MLPClassifier example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "c8e186df-a808-e0ee-d017-db14b6b0f78d"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "c3dc65a7-d559-37bd-0757-55608b8c9889"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the file Dataset_spine.csv\n",
    "\n",
    "- Use Pandas\n",
    "- Drop the column Unnamed: 13\n",
    "\n",
    "Always inspect the dataframe using .head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "dc573a8d-981e-bcf8-93d0-27041c3157b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (310, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "      <th>Col5</th>\n",
       "      <th>Col6</th>\n",
       "      <th>Col7</th>\n",
       "      <th>Col8</th>\n",
       "      <th>Col9</th>\n",
       "      <th>Col10</th>\n",
       "      <th>Col11</th>\n",
       "      <th>Col12</th>\n",
       "      <th>Class_att</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.027817</td>\n",
       "      <td>22.552586</td>\n",
       "      <td>39.609117</td>\n",
       "      <td>40.475232</td>\n",
       "      <td>98.672917</td>\n",
       "      <td>-0.254400</td>\n",
       "      <td>0.744503</td>\n",
       "      <td>12.5661</td>\n",
       "      <td>14.5386</td>\n",
       "      <td>15.30468</td>\n",
       "      <td>-28.658501</td>\n",
       "      <td>43.5123</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.056951</td>\n",
       "      <td>10.060991</td>\n",
       "      <td>25.015378</td>\n",
       "      <td>28.995960</td>\n",
       "      <td>114.405425</td>\n",
       "      <td>4.564259</td>\n",
       "      <td>0.415186</td>\n",
       "      <td>12.8874</td>\n",
       "      <td>17.5323</td>\n",
       "      <td>16.78486</td>\n",
       "      <td>-25.530607</td>\n",
       "      <td>16.1102</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.832021</td>\n",
       "      <td>22.218482</td>\n",
       "      <td>50.092194</td>\n",
       "      <td>46.613539</td>\n",
       "      <td>105.985135</td>\n",
       "      <td>-3.530317</td>\n",
       "      <td>0.474889</td>\n",
       "      <td>26.8343</td>\n",
       "      <td>17.4861</td>\n",
       "      <td>16.65897</td>\n",
       "      <td>-29.031888</td>\n",
       "      <td>19.2221</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.297008</td>\n",
       "      <td>24.652878</td>\n",
       "      <td>44.311238</td>\n",
       "      <td>44.644130</td>\n",
       "      <td>101.868495</td>\n",
       "      <td>11.211523</td>\n",
       "      <td>0.369345</td>\n",
       "      <td>23.5603</td>\n",
       "      <td>12.7074</td>\n",
       "      <td>11.42447</td>\n",
       "      <td>-30.470246</td>\n",
       "      <td>18.8329</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.712859</td>\n",
       "      <td>9.652075</td>\n",
       "      <td>28.317406</td>\n",
       "      <td>40.060784</td>\n",
       "      <td>108.168725</td>\n",
       "      <td>7.918501</td>\n",
       "      <td>0.543360</td>\n",
       "      <td>35.4940</td>\n",
       "      <td>15.9546</td>\n",
       "      <td>8.87237</td>\n",
       "      <td>-16.378376</td>\n",
       "      <td>24.9171</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Col1       Col2       Col3       Col4        Col5       Col6  \\\n",
       "0  63.027817  22.552586  39.609117  40.475232   98.672917  -0.254400   \n",
       "1  39.056951  10.060991  25.015378  28.995960  114.405425   4.564259   \n",
       "2  68.832021  22.218482  50.092194  46.613539  105.985135  -3.530317   \n",
       "3  69.297008  24.652878  44.311238  44.644130  101.868495  11.211523   \n",
       "4  49.712859   9.652075  28.317406  40.060784  108.168725   7.918501   \n",
       "\n",
       "       Col7     Col8     Col9     Col10      Col11    Col12 Class_att  \n",
       "0  0.744503  12.5661  14.5386  15.30468 -28.658501  43.5123  Abnormal  \n",
       "1  0.415186  12.8874  17.5323  16.78486 -25.530607  16.1102  Abnormal  \n",
       "2  0.474889  26.8343  17.4861  16.65897 -29.031888  19.2221  Abnormal  \n",
       "3  0.369345  23.5603  12.7074  11.42447 -30.470246  18.8329  Abnormal  \n",
       "4  0.543360  35.4940  15.9546   8.87237 -16.378376  24.9171  Abnormal  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "# Load the dataset\n",
    "spine_data = pd.read_csv('Dataset_spine.csv', skipinitialspace=True)\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"Dataset shape:\", spine_data.shape)\n",
    "\n",
    "# Drop column 13\n",
    "spine_data.drop(columns=['Unnamed: 13'], inplace=True)\n",
    "\n",
    "spine_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values per column:\n",
      "Col1         0\n",
      "Col2         0\n",
      "Col3         0\n",
      "Col4         0\n",
      "Col5         0\n",
      "Col6         0\n",
      "Col7         0\n",
      "Col8         0\n",
      "Col9         0\n",
      "Col10        0\n",
      "Col11        0\n",
      "Col12        0\n",
      "Class_att    0\n",
      "dtype: int64\n",
      "\n",
      "Dataset statistics:\n",
      "             Col1        Col2        Col3        Col4        Col5        Col6  \\\n",
      "count  310.000000  310.000000  310.000000  310.000000  310.000000  310.000000   \n",
      "mean    60.496653   17.542822   51.930930   42.953831  117.920655   26.296694   \n",
      "std     17.236520   10.008330   18.554064   13.423102   13.317377   37.559027   \n",
      "min     26.147921   -6.554948   14.000000   13.366931   70.082575  -11.058179   \n",
      "25%     46.430294   10.667069   37.000000   33.347122  110.709196    1.603727   \n",
      "50%     58.691038   16.357689   49.562398   42.404912  118.268178   11.767934   \n",
      "75%     72.877696   22.120395   63.000000   52.695888  125.467674   41.287352   \n",
      "max    129.834041   49.431864  125.742385  121.429566  163.071041  418.543082   \n",
      "\n",
      "             Col7        Col8        Col9       Col10       Col11       Col12  \n",
      "count  310.000000  310.000000  310.000000  310.000000  310.000000  310.000000  \n",
      "mean     0.472979   21.321526   13.064511   11.933317  -14.053139   25.645981  \n",
      "std      0.285787    8.639423    3.399713    2.893265   12.225582   10.450558  \n",
      "min      0.003220    7.027000    7.037800    7.030600  -35.287375    7.007900  \n",
      "25%      0.224367   13.054400   10.417800    9.541140  -24.289522   17.189075  \n",
      "50%      0.475989   21.907150   12.938450   11.953835  -14.622856   24.931950  \n",
      "75%      0.704846   28.954075   15.889525   14.371810   -3.497094   33.979600  \n",
      "max      0.998827   36.743900   19.324000   16.821080    6.972071   44.341200  \n",
      "\n",
      "Target classes:\n",
      "Class_att\n",
      "Abnormal    210\n",
      "Normal      100\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(spine_data.isnull().sum())\n",
    "\n",
    "# Dataset statistics\n",
    "print(\"\\nDataset statistics:\")\n",
    "print(spine_data.describe())\n",
    "\n",
    "# Check the target classes\n",
    "print(\"\\nTarget classes:\")\n",
    "print(spine_data[\"Class_att\"].value_counts())\n",
    "\n",
    "# Visualize the distribution of classes\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='Class_att', data=spine_data)\n",
    "plt.title('Distribution of Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also drop ['Col7','Col8','Col9','Col10','Col11','Col12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "459fd9ba-8900-9b29-0317-23d8abf034c4"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# Drop col 7 - 12 but not don't drop the \"Class_att\" column\n",
    "#spine_data.drop(columns=spine_data.columns[7:13], inplace=True)\n",
    "#spine_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8fefbd23-d73b-0544-f540-c01f8cd24cb7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will show the classes, obviously that column will be our y, the rest will be X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Abnormal', 'Normal'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spine_data[\"Class_att\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Classifier\n",
    "\n",
    "import the things we need from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "train_test_split\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "1f01b202-9cac-dcc8-0831-99b7241e992c"
   },
   "outputs": [],
   "source": [
    "# your code here \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the variables X and y by picking the columns as discussed above\n",
    "\n",
    "Do a train_test_split, use a fixed random_state and make the test_size be 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "d817746f-8582-c3dc-dd14-822830337eba"
   },
   "outputs": [],
   "source": [
    "X = spine_data.iloc[:, :-1]\n",
    "y = spine_data.iloc[:, -1]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9c99af5c-3f0a-136e-a870-77245031f393"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets use MLPClassifier from sklearn\n",
    "\n",
    "Do for 3 hidden layers with 100 units in each\n",
    "\n",
    "set tol=0.000000001\n",
    "\n",
    "use solver 'sgd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[51  6]\n",
      " [ 7 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Abnormal       0.88      0.89      0.89        57\n",
      "      Normal       0.70      0.67      0.68        21\n",
      "\n",
      "    accuracy                           0.83        78\n",
      "   macro avg       0.79      0.78      0.78        78\n",
      "weighted avg       0.83      0.83      0.83        78\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mMLPClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mhidden_layer_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'constant'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlearning_rate_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpower_t\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnesterovs_momentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_fraction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbeta_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbeta_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.999\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-08\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_iter_no_change\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_fun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Multi-layer Perceptron classifier.\n",
      "\n",
      "This model optimizes the log-loss function using LBFGS or stochastic\n",
      "gradient descent.\n",
      "\n",
      ".. versionadded:: 0.18\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "hidden_layer_sizes : array-like of shape(n_layers - 2,), default=(100,)\n",
      "    The ith element represents the number of neurons in the ith\n",
      "    hidden layer.\n",
      "\n",
      "activation : {'identity', 'logistic', 'tanh', 'relu'}, default='relu'\n",
      "    Activation function for the hidden layer.\n",
      "\n",
      "    - 'identity', no-op activation, useful to implement linear bottleneck,\n",
      "      returns f(x) = x\n",
      "\n",
      "    - 'logistic', the logistic sigmoid function,\n",
      "      returns f(x) = 1 / (1 + exp(-x)).\n",
      "\n",
      "    - 'tanh', the hyperbolic tan function,\n",
      "      returns f(x) = tanh(x).\n",
      "\n",
      "    - 'relu', the rectified linear unit function,\n",
      "      returns f(x) = max(0, x)\n",
      "\n",
      "solver : {'lbfgs', 'sgd', 'adam'}, default='adam'\n",
      "    The solver for weight optimization.\n",
      "\n",
      "    - 'lbfgs' is an optimizer in the family of quasi-Newton methods.\n",
      "\n",
      "    - 'sgd' refers to stochastic gradient descent.\n",
      "\n",
      "    - 'adam' refers to a stochastic gradient-based optimizer proposed\n",
      "      by Kingma, Diederik, and Jimmy Ba\n",
      "\n",
      "    For a comparison between Adam optimizer and SGD, see\n",
      "    :ref:`sphx_glr_auto_examples_neural_networks_plot_mlp_training_curves.py`.\n",
      "\n",
      "    Note: The default solver 'adam' works pretty well on relatively\n",
      "    large datasets (with thousands of training samples or more) in terms of\n",
      "    both training time and validation score.\n",
      "    For small datasets, however, 'lbfgs' can converge faster and perform\n",
      "    better.\n",
      "\n",
      "alpha : float, default=0.0001\n",
      "    Strength of the L2 regularization term. The L2 regularization term\n",
      "    is divided by the sample size when added to the loss.\n",
      "\n",
      "    For an example usage and visualization of varying regularization, see\n",
      "    :ref:`sphx_glr_auto_examples_neural_networks_plot_mlp_alpha.py`.\n",
      "\n",
      "batch_size : int, default='auto'\n",
      "    Size of minibatches for stochastic optimizers.\n",
      "    If the solver is 'lbfgs', the classifier will not use minibatch.\n",
      "    When set to \"auto\", `batch_size=min(200, n_samples)`.\n",
      "\n",
      "learning_rate : {'constant', 'invscaling', 'adaptive'}, default='constant'\n",
      "    Learning rate schedule for weight updates.\n",
      "\n",
      "    - 'constant' is a constant learning rate given by\n",
      "      'learning_rate_init'.\n",
      "\n",
      "    - 'invscaling' gradually decreases the learning rate at each\n",
      "      time step 't' using an inverse scaling exponent of 'power_t'.\n",
      "      effective_learning_rate = learning_rate_init / pow(t, power_t)\n",
      "\n",
      "    - 'adaptive' keeps the learning rate constant to\n",
      "      'learning_rate_init' as long as training loss keeps decreasing.\n",
      "      Each time two consecutive epochs fail to decrease training loss by at\n",
      "      least tol, or fail to increase validation score by at least tol if\n",
      "      'early_stopping' is on, the current learning rate is divided by 5.\n",
      "\n",
      "    Only used when ``solver='sgd'``.\n",
      "\n",
      "learning_rate_init : float, default=0.001\n",
      "    The initial learning rate used. It controls the step-size\n",
      "    in updating the weights. Only used when solver='sgd' or 'adam'.\n",
      "\n",
      "power_t : float, default=0.5\n",
      "    The exponent for inverse scaling learning rate.\n",
      "    It is used in updating effective learning rate when the learning_rate\n",
      "    is set to 'invscaling'. Only used when solver='sgd'.\n",
      "\n",
      "max_iter : int, default=200\n",
      "    Maximum number of iterations. The solver iterates until convergence\n",
      "    (determined by 'tol') or this number of iterations. For stochastic\n",
      "    solvers ('sgd', 'adam'), note that this determines the number of epochs\n",
      "    (how many times each data point will be used), not the number of\n",
      "    gradient steps.\n",
      "\n",
      "shuffle : bool, default=True\n",
      "    Whether to shuffle samples in each iteration. Only used when\n",
      "    solver='sgd' or 'adam'.\n",
      "\n",
      "random_state : int, RandomState instance, default=None\n",
      "    Determines random number generation for weights and bias\n",
      "    initialization, train-test split if early stopping is used, and batch\n",
      "    sampling when solver='sgd' or 'adam'.\n",
      "    Pass an int for reproducible results across multiple function calls.\n",
      "    See :term:`Glossary <random_state>`.\n",
      "\n",
      "tol : float, default=1e-4\n",
      "    Tolerance for the optimization. When the loss or score is not improving\n",
      "    by at least ``tol`` for ``n_iter_no_change`` consecutive iterations,\n",
      "    unless ``learning_rate`` is set to 'adaptive', convergence is\n",
      "    considered to be reached and training stops.\n",
      "\n",
      "verbose : bool, default=False\n",
      "    Whether to print progress messages to stdout.\n",
      "\n",
      "warm_start : bool, default=False\n",
      "    When set to True, reuse the solution of the previous\n",
      "    call to fit as initialization, otherwise, just erase the\n",
      "    previous solution. See :term:`the Glossary <warm_start>`.\n",
      "\n",
      "momentum : float, default=0.9\n",
      "    Momentum for gradient descent update. Should be between 0 and 1. Only\n",
      "    used when solver='sgd'.\n",
      "\n",
      "nesterovs_momentum : bool, default=True\n",
      "    Whether to use Nesterov's momentum. Only used when solver='sgd' and\n",
      "    momentum > 0.\n",
      "\n",
      "early_stopping : bool, default=False\n",
      "    Whether to use early stopping to terminate training when validation\n",
      "    score is not improving. If set to true, it will automatically set\n",
      "    aside 10% of training data as validation and terminate training when\n",
      "    validation score is not improving by at least ``tol`` for\n",
      "    ``n_iter_no_change`` consecutive epochs. The split is stratified,\n",
      "    except in a multilabel setting.\n",
      "    If early stopping is False, then the training stops when the training\n",
      "    loss does not improve by more than tol for n_iter_no_change consecutive\n",
      "    passes over the training set.\n",
      "    Only effective when solver='sgd' or 'adam'.\n",
      "\n",
      "validation_fraction : float, default=0.1\n",
      "    The proportion of training data to set aside as validation set for\n",
      "    early stopping. Must be between 0 and 1.\n",
      "    Only used if early_stopping is True.\n",
      "\n",
      "beta_1 : float, default=0.9\n",
      "    Exponential decay rate for estimates of first moment vector in adam,\n",
      "    should be in [0, 1). Only used when solver='adam'.\n",
      "\n",
      "beta_2 : float, default=0.999\n",
      "    Exponential decay rate for estimates of second moment vector in adam,\n",
      "    should be in [0, 1). Only used when solver='adam'.\n",
      "\n",
      "epsilon : float, default=1e-8\n",
      "    Value for numerical stability in adam. Only used when solver='adam'.\n",
      "\n",
      "n_iter_no_change : int, default=10\n",
      "    Maximum number of epochs to not meet ``tol`` improvement.\n",
      "    Only effective when solver='sgd' or 'adam'.\n",
      "\n",
      "    .. versionadded:: 0.20\n",
      "\n",
      "max_fun : int, default=15000\n",
      "    Only used when solver='lbfgs'. Maximum number of loss function calls.\n",
      "    The solver iterates until convergence (determined by 'tol'), number\n",
      "    of iterations reaches max_iter, or this number of loss function calls.\n",
      "    Note that number of loss function calls will be greater than or equal\n",
      "    to the number of iterations for the `MLPClassifier`.\n",
      "\n",
      "    .. versionadded:: 0.22\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "classes_ : ndarray or list of ndarray of shape (n_classes,)\n",
      "    Class labels for each output.\n",
      "\n",
      "loss_ : float\n",
      "    The current loss computed with the loss function.\n",
      "\n",
      "best_loss_ : float or None\n",
      "    The minimum loss reached by the solver throughout fitting.\n",
      "    If `early_stopping=True`, this attribute is set to `None`. Refer to\n",
      "    the `best_validation_score_` fitted attribute instead.\n",
      "\n",
      "loss_curve_ : list of shape (`n_iter_`,)\n",
      "    The ith element in the list represents the loss at the ith iteration.\n",
      "\n",
      "validation_scores_ : list of shape (`n_iter_`,) or None\n",
      "    The score at each iteration on a held-out validation set. The score\n",
      "    reported is the accuracy score. Only available if `early_stopping=True`,\n",
      "    otherwise the attribute is set to `None`.\n",
      "\n",
      "best_validation_score_ : float or None\n",
      "    The best validation score (i.e. accuracy score) that triggered the\n",
      "    early stopping. Only available if `early_stopping=True`, otherwise the\n",
      "    attribute is set to `None`.\n",
      "\n",
      "t_ : int\n",
      "    The number of training samples seen by the solver during fitting.\n",
      "\n",
      "coefs_ : list of shape (n_layers - 1,)\n",
      "    The ith element in the list represents the weight matrix corresponding\n",
      "    to layer i.\n",
      "\n",
      "intercepts_ : list of shape (n_layers - 1,)\n",
      "    The ith element in the list represents the bias vector corresponding to\n",
      "    layer i + 1.\n",
      "\n",
      "n_features_in_ : int\n",
      "    Number of features seen during :term:`fit`.\n",
      "\n",
      "    .. versionadded:: 0.24\n",
      "\n",
      "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "    Names of features seen during :term:`fit`. Defined only when `X`\n",
      "    has feature names that are all strings.\n",
      "\n",
      "    .. versionadded:: 1.0\n",
      "\n",
      "n_iter_ : int\n",
      "    The number of iterations the solver has run.\n",
      "\n",
      "n_layers_ : int\n",
      "    Number of layers.\n",
      "\n",
      "n_outputs_ : int\n",
      "    Number of outputs.\n",
      "\n",
      "out_activation_ : str\n",
      "    Name of the output activation function.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "MLPRegressor : Multi-layer Perceptron regressor.\n",
      "BernoulliRBM : Bernoulli Restricted Boltzmann Machine (RBM).\n",
      "\n",
      "Notes\n",
      "-----\n",
      "MLPClassifier trains iteratively since at each time step\n",
      "the partial derivatives of the loss function with respect to the model\n",
      "parameters are computed to update the parameters.\n",
      "\n",
      "It can also have a regularization term added to the loss function\n",
      "that shrinks model parameters to prevent overfitting.\n",
      "\n",
      "This implementation works with data represented as dense numpy arrays or\n",
      "sparse scipy arrays of floating point values.\n",
      "\n",
      "References\n",
      "----------\n",
      "Hinton, Geoffrey E. \"Connectionist learning procedures.\"\n",
      "Artificial intelligence 40.1 (1989): 185-234.\n",
      "\n",
      "Glorot, Xavier, and Yoshua Bengio.\n",
      "\"Understanding the difficulty of training deep feedforward neural networks.\"\n",
      "International Conference on Artificial Intelligence and Statistics. 2010.\n",
      "\n",
      ":arxiv:`He, Kaiming, et al (2015). \"Delving deep into rectifiers:\n",
      "Surpassing human-level performance on imagenet classification.\" <1502.01852>`\n",
      "\n",
      ":arxiv:`Kingma, Diederik, and Jimmy Ba (2014)\n",
      "\"Adam: A method for stochastic optimization.\" <1412.6980>`\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from sklearn.neural_network import MLPClassifier\n",
      ">>> from sklearn.datasets import make_classification\n",
      ">>> from sklearn.model_selection import train_test_split\n",
      ">>> X, y = make_classification(n_samples=100, random_state=1)\n",
      ">>> X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
      "...                                                     random_state=1)\n",
      ">>> clf = MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train)\n",
      ">>> clf.predict_proba(X_test[:1])\n",
      "array([[0.038..., 0.961...]])\n",
      ">>> clf.predict(X_test[:5, :])\n",
      "array([1, 0, 1, 0, 1])\n",
      ">>> clf.score(X_test, y_test)\n",
      "0.8...\n",
      "\u001b[0;31mFile:\u001b[0m           ~/.local/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\n",
      "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "MLPClassifier?\n",
    "\n",
    "# Use a Multi-layer Perceptron classifier for 3 hidden layers with 100 units each, set tol to 0.set tol=0.000000001 and use solver 'sgd'\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 100, 100), max_iter=1000, tol=0.000000001, solver='sgd', random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict the test set\n",
    "y_pred = mlp.predict(X_test_scaled)\n",
    "\n",
    "# Analyze the results\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit the classifier using training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c992c033-ef51-ce74-fe22-94394c05759a"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get y_pred using .predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "20c44ff4-bd47-4b67-1e09-830561670d27"
   },
   "source": [
    "Get the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "# Get accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "aeda713a-6dbc-fcc4-be5a-c6e0fb35d71b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view a heatmap with the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "8bc84c75-5959-bfcb-1ae1-2994ddafdbb5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm, center=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow\n",
    "\n",
    "Now what about Tensorflow??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 15:01:48.347474: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-24 15:01:48.371137: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-24 15:01:48.631300: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-24 15:01:48.781466: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742828509.103415   29885 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742828509.194797   29885 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1742828509.863538   29885 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742828509.863574   29885 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742828509.863577   29885 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742828509.863580   29885 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-24 15:01:49.941495: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 15:01:53.390625: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a new sequential model, call it model_tf\n",
    "\n",
    "Have 3 hidden layers, each with activation relu\n",
    "\n",
    "have an output layer with only 1 unit, no activation function\n",
    "\n",
    "Should you also set up a normaliser as well. See example workbooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_tf = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model, pick an optimizer, use Adam or tf.keras.optimizers.experimental.SGD(0.001). loss is binarycrossentropy\n",
    "\n",
    "    metrics=['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_tf.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140    Abnormal\n",
       "208    Abnormal\n",
       "278      Normal\n",
       "203    Abnormal\n",
       "144    Abnormal\n",
       "         ...   \n",
       "188    Abnormal\n",
       "71     Abnormal\n",
       "106    Abnormal\n",
       "270      Normal\n",
       "102    Abnormal\n",
       "Name: Class_att, Length: 232, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try fitting, 20 epochs, do \n",
    "\n",
    "    X_train.values, y_train.values, epochs=20, validation_split=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid dtype: object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Fit the model with 20 epochs\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_tf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/optree/ops.py:766\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[1;32m    764\u001b[0m leaves, treespec \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39mflatten(tree, is_leaf, none_is_leaf, namespace)\n\u001b[1;32m    765\u001b[0m flat_args \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treespec\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[0;32m--> 766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreespec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid dtype: object"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fit the model with 20 epochs\n",
    "history = model_tf.fit(X_train_scaled, y_train, epochs=20, validation_data=(X_test_scaled, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " You should get a bunch of errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why this error?\n",
    "\n",
    "Well look at y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140    Abnormal\n",
       "208    Abnormal\n",
       "278      Normal\n",
       "203    Abnormal\n",
       "144    Abnormal\n",
       "         ...   \n",
       "188    Abnormal\n",
       "71     Abnormal\n",
       "106    Abnormal\n",
       "270      Normal\n",
       "102    Abnormal\n",
       "Name: Class_att, Length: 232, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They're not numbers, we need to convert those to numbers. Using LabelEncoder\n",
    "\n",
    "Scikit-learn didn't care, but Tensorflow is a \"lower-level\" programming tool so you need to do the conversion yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "\n",
    "# Convert to numbers using LabelEncoder\n",
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the label encoder on y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LabelEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.LabelEncoder.html\">?<span>Documentation for LabelEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LabelEncoder()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Fit the encoder on the target classes\n",
    "le.fit(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now transform both y_train and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = y_test_enc = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting again\n",
    "\n",
    "Try fitting your model again with y_train_enc. It should work now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6632 - loss: 1.0884 - val_accuracy: 0.7949 - val_loss: 0.4623\n",
      "Epoch 2/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7820 - loss: 0.5106 - val_accuracy: 0.8205 - val_loss: 0.3961\n",
      "Epoch 3/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8541 - loss: 0.3857 - val_accuracy: 0.8462 - val_loss: 0.3760\n",
      "Epoch 4/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8557 - loss: 0.5106 - val_accuracy: 0.8462 - val_loss: 0.5443\n",
      "Epoch 5/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8730 - loss: 0.4767 - val_accuracy: 0.8333 - val_loss: 0.5274\n",
      "Epoch 6/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9074 - loss: 0.2686 - val_accuracy: 0.8205 - val_loss: 0.6839\n",
      "Epoch 7/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9181 - loss: 0.2957 - val_accuracy: 0.8462 - val_loss: 0.6949\n",
      "Epoch 8/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9393 - loss: 0.4132 - val_accuracy: 0.8205 - val_loss: 0.8766\n",
      "Epoch 9/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9235 - loss: 0.2923 - val_accuracy: 0.8077 - val_loss: 0.9159\n",
      "Epoch 10/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9739 - loss: 0.2046 - val_accuracy: 0.8462 - val_loss: 0.8768\n",
      "Epoch 11/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9471 - loss: 0.1847 - val_accuracy: 0.8333 - val_loss: 0.6972\n",
      "Epoch 12/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9511 - loss: 0.3418 - val_accuracy: 0.8077 - val_loss: 0.7038\n",
      "Epoch 13/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9675 - loss: 0.2965 - val_accuracy: 0.8077 - val_loss: 0.7566\n",
      "Epoch 14/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9818 - loss: 0.1391 - val_accuracy: 0.7949 - val_loss: 0.9551\n",
      "Epoch 15/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9760 - loss: 0.1689 - val_accuracy: 0.7949 - val_loss: 0.9568\n",
      "Epoch 16/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9680 - loss: 0.2712 - val_accuracy: 0.8077 - val_loss: 1.4342\n",
      "Epoch 17/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9813 - loss: 0.2231 - val_accuracy: 0.8077 - val_loss: 0.9642\n",
      "Epoch 18/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9879 - loss: 0.1772 - val_accuracy: 0.7949 - val_loss: 1.2962\n",
      "Epoch 19/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9817 - loss: 0.1748 - val_accuracy: 0.7821 - val_loss: 1.3069\n",
      "Epoch 20/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9872 - loss: 0.1893 - val_accuracy: 0.7564 - val_loss: 1.1972\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "# Fit the model with 20 epochs\n",
    "history = model_tf.fit(X_train_scaled, y_train_enc, epochs=20, validation_data=(X_test_scaled, y_test_enc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy for both the training and validation sets is a little all over the place. Maybe we need more Epochs or some other way to decide when to finish. Anyway..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_tf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   9.713096  ],\n",
       "       [   4.6514783 ],\n",
       "       [  -3.6894684 ],\n",
       "       [ -58.796368  ],\n",
       "       [ -13.113508  ],\n",
       "       [ -28.51698   ],\n",
       "       [ -66.772354  ],\n",
       "       [ -35.81682   ],\n",
       "       [ -18.211226  ],\n",
       "       [ -17.504757  ],\n",
       "       [-137.09096   ],\n",
       "       [ -86.49535   ],\n",
       "       [   3.0172496 ],\n",
       "       [  -2.2275639 ],\n",
       "       [   0.794561  ],\n",
       "       [   2.517322  ],\n",
       "       [  -6.716208  ],\n",
       "       [ -33.82141   ],\n",
       "       [ -23.24468   ],\n",
       "       [ -59.433163  ],\n",
       "       [ -36.768215  ],\n",
       "       [ -92.475174  ],\n",
       "       [ -55.57617   ],\n",
       "       [ -81.034836  ],\n",
       "       [-104.66911   ],\n",
       "       [ -16.290565  ],\n",
       "       [ -48.188366  ],\n",
       "       [  -1.72866   ],\n",
       "       [  -3.0285707 ],\n",
       "       [  14.989953  ],\n",
       "       [ -31.97293   ],\n",
       "       [ -16.892181  ],\n",
       "       [ -57.328037  ],\n",
       "       [   7.967672  ],\n",
       "       [ -43.48882   ],\n",
       "       [ -34.196625  ],\n",
       "       [  -7.6747036 ],\n",
       "       [   4.58311   ],\n",
       "       [-107.135635  ],\n",
       "       [ -31.536097  ],\n",
       "       [  -9.125707  ],\n",
       "       [  -6.9648633 ],\n",
       "       [ -65.59427   ],\n",
       "       [  15.662223  ],\n",
       "       [   3.8861365 ],\n",
       "       [ -48.680733  ],\n",
       "       [  -3.8933816 ],\n",
       "       [  19.831371  ],\n",
       "       [   8.682231  ],\n",
       "       [ -42.0725    ],\n",
       "       [ -83.81244   ],\n",
       "       [   4.824098  ],\n",
       "       [ -59.00442   ],\n",
       "       [ -58.452393  ],\n",
       "       [ -28.554003  ],\n",
       "       [  -1.0451874 ],\n",
       "       [  -7.5070496 ],\n",
       "       [ -28.64828   ],\n",
       "       [ -30.679749  ],\n",
       "       [ -15.1690645 ],\n",
       "       [  -6.282707  ],\n",
       "       [ -33.415886  ],\n",
       "       [ -29.988607  ],\n",
       "       [ -34.231712  ],\n",
       "       [  -5.4305935 ],\n",
       "       [  -9.861701  ],\n",
       "       [ -99.696175  ],\n",
       "       [ -28.116047  ],\n",
       "       [ -15.8158245 ],\n",
       "       [ -12.253427  ],\n",
       "       [ -26.27916   ],\n",
       "       [  -4.534133  ],\n",
       "       [ -56.012417  ],\n",
       "       [ -11.289479  ],\n",
       "       [ -14.840519  ],\n",
       "       [  -1.4686741 ],\n",
       "       [  -0.61698806],\n",
       "       [ -30.234219  ]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those are not probabilities. Damn. Well we need to do some more\n",
    "\n",
    "We could have set the activation to sigmoid on the last layer and that would've given us probabilities but tensorflow manual says not to do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs = tf.keras.activations.sigmoid(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert those probabilities to 0s or 1s. This is not the best way of doing this, Tensorflow almost certainly has something better, but this is how I want to do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(y_probs, columns=[\"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"which\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc[results['value'] >= 0.5, 'which'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>which</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.999395e-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.905428e-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.437623e-02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.917844e-26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.017785e-06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1.250363e-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>3.587933e-07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1.871442e-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>3.504668e-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>7.403647e-14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           value  which\n",
       "0   9.999395e-01      1\n",
       "1   9.905428e-01      1\n",
       "2   2.437623e-02      0\n",
       "3   2.917844e-26      0\n",
       "4   2.017785e-06      0\n",
       "..           ...    ...\n",
       "73  1.250363e-05      0\n",
       "74  3.587933e-07      0\n",
       "75  1.871442e-01      0\n",
       "76  3.504668e-01      0\n",
       "77  7.403647e-14      0\n",
       "\n",
       "[78 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.which.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistakes = (results.which.values != y_test_enc).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8360 - loss: 2.6401 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.889181613922119, 0.8205128312110901]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tf.evaluate(X_test, y_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8205128205128205)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-mistakes/78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, it's worse than the sklearn implementation in test data but I haven't tried anything to tweak it, sklearn you will have noticed did more epochs in its training. It also didn't use any validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Epochs! Lower learning rate\n",
    "\n",
    "I'm going to take the same basic structure and see what happens when I make some changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100,activation='relu'),\n",
    "    tf.keras.layers.Dense(100,activation='relu'),\n",
    "    tf.keras.layers.Dense(100,activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll also do a lower learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.0001),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots and lots of epochs, let's run it and store the history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.3532 - loss: 10.8892 - val_accuracy: 0.3404 - val_loss: 7.6129\n",
      "Epoch 2/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3295 - loss: 7.2078 - val_accuracy: 0.3404 - val_loss: 3.7149\n",
      "Epoch 3/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3323 - loss: 3.5002 - val_accuracy: 0.5532 - val_loss: 1.2077\n",
      "Epoch 4/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5194 - loss: 1.2269 - val_accuracy: 0.6809 - val_loss: 1.4201\n",
      "Epoch 5/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6643 - loss: 1.2740 - val_accuracy: 0.6596 - val_loss: 1.4771\n",
      "Epoch 6/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6427 - loss: 1.3033 - val_accuracy: 0.7234 - val_loss: 1.0094\n",
      "Epoch 7/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6298 - loss: 0.9076 - val_accuracy: 0.6596 - val_loss: 0.6532\n",
      "Epoch 8/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6342 - loss: 0.6572 - val_accuracy: 0.6809 - val_loss: 0.5949\n",
      "Epoch 9/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6421 - loss: 0.6771 - val_accuracy: 0.6809 - val_loss: 0.5398\n",
      "Epoch 10/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6860 - loss: 0.6012 - val_accuracy: 0.7872 - val_loss: 0.4879\n",
      "Epoch 11/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6670 - loss: 0.5327 - val_accuracy: 0.7234 - val_loss: 0.4801\n",
      "Epoch 12/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6418 - loss: 0.5685 - val_accuracy: 0.7660 - val_loss: 0.4354\n",
      "Epoch 13/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7154 - loss: 0.4538 - val_accuracy: 0.7872 - val_loss: 0.3998\n",
      "Epoch 14/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7994 - loss: 0.4296 - val_accuracy: 0.7872 - val_loss: 0.3841\n",
      "Epoch 15/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7805 - loss: 0.4116 - val_accuracy: 0.7872 - val_loss: 0.3711\n",
      "Epoch 16/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7826 - loss: 0.4100 - val_accuracy: 0.7660 - val_loss: 0.3616\n",
      "Epoch 17/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7800 - loss: 0.3918 - val_accuracy: 0.8085 - val_loss: 0.3544\n",
      "Epoch 18/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7755 - loss: 0.4427 - val_accuracy: 0.7872 - val_loss: 0.3489\n",
      "Epoch 19/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7538 - loss: 0.3965 - val_accuracy: 0.7872 - val_loss: 0.3412\n",
      "Epoch 20/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7907 - loss: 0.3691 - val_accuracy: 0.7872 - val_loss: 0.3360\n",
      "Epoch 21/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8211 - loss: 0.3591 - val_accuracy: 0.8085 - val_loss: 0.3312\n",
      "Epoch 22/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7912 - loss: 0.3763 - val_accuracy: 0.8085 - val_loss: 0.3278\n",
      "Epoch 23/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7926 - loss: 0.3601 - val_accuracy: 0.8511 - val_loss: 0.3273\n",
      "Epoch 24/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7949 - loss: 0.3739 - val_accuracy: 0.8298 - val_loss: 0.3214\n",
      "Epoch 25/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7726 - loss: 0.3785 - val_accuracy: 0.8298 - val_loss: 0.3185\n",
      "Epoch 26/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7916 - loss: 0.3433 - val_accuracy: 0.8511 - val_loss: 0.3161\n",
      "Epoch 27/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7913 - loss: 0.3611 - val_accuracy: 0.8298 - val_loss: 0.3187\n",
      "Epoch 28/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8505 - loss: 0.3301 - val_accuracy: 0.8298 - val_loss: 0.3101\n",
      "Epoch 29/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7857 - loss: 0.3551 - val_accuracy: 0.8298 - val_loss: 0.3091\n",
      "Epoch 30/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8342 - loss: 0.3408 - val_accuracy: 0.8511 - val_loss: 0.3161\n",
      "Epoch 31/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8137 - loss: 0.3414 - val_accuracy: 0.8298 - val_loss: 0.3054\n",
      "Epoch 32/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7708 - loss: 0.3826 - val_accuracy: 0.8085 - val_loss: 0.3022\n",
      "Epoch 33/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8115 - loss: 0.3528 - val_accuracy: 0.8511 - val_loss: 0.3111\n",
      "Epoch 34/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8701 - loss: 0.3380 - val_accuracy: 0.8298 - val_loss: 0.3040\n",
      "Epoch 35/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8286 - loss: 0.3252 - val_accuracy: 0.8298 - val_loss: 0.2991\n",
      "Epoch 36/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7996 - loss: 0.3606 - val_accuracy: 0.8298 - val_loss: 0.2993\n",
      "Epoch 37/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8711 - loss: 0.2906 - val_accuracy: 0.8511 - val_loss: 0.3012\n",
      "Epoch 38/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8472 - loss: 0.3382 - val_accuracy: 0.8511 - val_loss: 0.3001\n",
      "Epoch 39/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8887 - loss: 0.3071 - val_accuracy: 0.8511 - val_loss: 0.2993\n",
      "Epoch 40/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8862 - loss: 0.3273 - val_accuracy: 0.8511 - val_loss: 0.2964\n",
      "Epoch 41/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8406 - loss: 0.3327 - val_accuracy: 0.8298 - val_loss: 0.2927\n",
      "Epoch 42/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8075 - loss: 0.3348 - val_accuracy: 0.8298 - val_loss: 0.2932\n",
      "Epoch 43/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8614 - loss: 0.3181 - val_accuracy: 0.8511 - val_loss: 0.2977\n",
      "Epoch 44/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8455 - loss: 0.3364 - val_accuracy: 0.8298 - val_loss: 0.3010\n",
      "Epoch 45/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8528 - loss: 0.3271 - val_accuracy: 0.8511 - val_loss: 0.2924\n",
      "Epoch 46/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8697 - loss: 0.2943 - val_accuracy: 0.8511 - val_loss: 0.2927\n",
      "Epoch 47/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8637 - loss: 0.3389 - val_accuracy: 0.8511 - val_loss: 0.2948\n",
      "Epoch 48/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8608 - loss: 0.3175 - val_accuracy: 0.8511 - val_loss: 0.2913\n",
      "Epoch 49/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8888 - loss: 0.3211 - val_accuracy: 0.8298 - val_loss: 0.2976\n",
      "Epoch 50/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8593 - loss: 0.3374 - val_accuracy: 0.8298 - val_loss: 0.2882\n",
      "Epoch 51/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8232 - loss: 0.3236 - val_accuracy: 0.8511 - val_loss: 0.2909\n",
      "Epoch 52/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8389 - loss: 0.3577 - val_accuracy: 0.8511 - val_loss: 0.2912\n",
      "Epoch 53/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8935 - loss: 0.3024 - val_accuracy: 0.8511 - val_loss: 0.2913\n",
      "Epoch 54/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8872 - loss: 0.2979 - val_accuracy: 0.8511 - val_loss: 0.2913\n",
      "Epoch 55/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8972 - loss: 0.3029 - val_accuracy: 0.8298 - val_loss: 0.2965\n",
      "Epoch 56/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9040 - loss: 0.2970 - val_accuracy: 0.8085 - val_loss: 0.2918\n",
      "Epoch 57/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8696 - loss: 0.3107 - val_accuracy: 0.8298 - val_loss: 0.2936\n",
      "Epoch 58/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8650 - loss: 0.3218 - val_accuracy: 0.8298 - val_loss: 0.2933\n",
      "Epoch 59/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8653 - loss: 0.3325 - val_accuracy: 0.8085 - val_loss: 0.2917\n",
      "Epoch 60/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8965 - loss: 0.2708 - val_accuracy: 0.8511 - val_loss: 0.2963\n",
      "Epoch 61/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8672 - loss: 0.3045 - val_accuracy: 0.8085 - val_loss: 0.2947\n",
      "Epoch 62/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8880 - loss: 0.2678 - val_accuracy: 0.8511 - val_loss: 0.2958\n",
      "Epoch 63/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8877 - loss: 0.2632 - val_accuracy: 0.8298 - val_loss: 0.2945\n",
      "Epoch 64/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8823 - loss: 0.2777 - val_accuracy: 0.8298 - val_loss: 0.2947\n",
      "Epoch 65/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8695 - loss: 0.2748 - val_accuracy: 0.8298 - val_loss: 0.2876\n",
      "Epoch 66/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8355 - loss: 0.3365 - val_accuracy: 0.8511 - val_loss: 0.2981\n",
      "Epoch 67/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9095 - loss: 0.2926 - val_accuracy: 0.8723 - val_loss: 0.3015\n",
      "Epoch 68/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9067 - loss: 0.2572 - val_accuracy: 0.8298 - val_loss: 0.2929\n",
      "Epoch 69/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8614 - loss: 0.2929 - val_accuracy: 0.8085 - val_loss: 0.2855\n",
      "Epoch 70/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8822 - loss: 0.2662 - val_accuracy: 0.8723 - val_loss: 0.2974\n",
      "Epoch 71/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8697 - loss: 0.3096 - val_accuracy: 0.8511 - val_loss: 0.2997\n",
      "Epoch 72/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8837 - loss: 0.3169 - val_accuracy: 0.8085 - val_loss: 0.2835\n",
      "Epoch 73/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8787 - loss: 0.2845 - val_accuracy: 0.8723 - val_loss: 0.2935\n",
      "Epoch 74/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9026 - loss: 0.2871 - val_accuracy: 0.8511 - val_loss: 0.2837\n",
      "Epoch 75/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8540 - loss: 0.2866 - val_accuracy: 0.8298 - val_loss: 0.2735\n",
      "Epoch 76/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8527 - loss: 0.2759 - val_accuracy: 0.8511 - val_loss: 0.2926\n",
      "Epoch 77/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8682 - loss: 0.2931 - val_accuracy: 0.8298 - val_loss: 0.2734\n",
      "Epoch 78/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8750 - loss: 0.3116 - val_accuracy: 0.8298 - val_loss: 0.2734\n",
      "Epoch 79/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8941 - loss: 0.2707 - val_accuracy: 0.8511 - val_loss: 0.2777\n",
      "Epoch 80/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9099 - loss: 0.2590 - val_accuracy: 0.8511 - val_loss: 0.2776\n",
      "Epoch 81/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9088 - loss: 0.2419 - val_accuracy: 0.8511 - val_loss: 0.2771\n",
      "Epoch 82/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8699 - loss: 0.2527 - val_accuracy: 0.8511 - val_loss: 0.2800\n",
      "Epoch 83/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9027 - loss: 0.2666 - val_accuracy: 0.8298 - val_loss: 0.2729\n",
      "Epoch 84/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8790 - loss: 0.2539 - val_accuracy: 0.8511 - val_loss: 0.2847\n",
      "Epoch 85/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9088 - loss: 0.2466 - val_accuracy: 0.8511 - val_loss: 0.2740\n",
      "Epoch 86/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8719 - loss: 0.2768 - val_accuracy: 0.8511 - val_loss: 0.2759\n",
      "Epoch 87/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8676 - loss: 0.2815 - val_accuracy: 0.8511 - val_loss: 0.2850\n",
      "Epoch 88/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9081 - loss: 0.2613 - val_accuracy: 0.8511 - val_loss: 0.2731\n",
      "Epoch 89/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9032 - loss: 0.2422 - val_accuracy: 0.8511 - val_loss: 0.2851\n",
      "Epoch 90/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8803 - loss: 0.2985 - val_accuracy: 0.8511 - val_loss: 0.2842\n",
      "Epoch 91/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9186 - loss: 0.2636 - val_accuracy: 0.8511 - val_loss: 0.2794\n",
      "Epoch 92/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9129 - loss: 0.2398 - val_accuracy: 0.8511 - val_loss: 0.2724\n",
      "Epoch 93/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8851 - loss: 0.2784 - val_accuracy: 0.8511 - val_loss: 0.2874\n",
      "Epoch 94/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8559 - loss: 0.3064 - val_accuracy: 0.8511 - val_loss: 0.2782\n",
      "Epoch 95/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8729 - loss: 0.2662 - val_accuracy: 0.8511 - val_loss: 0.2820\n",
      "Epoch 96/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9016 - loss: 0.2425 - val_accuracy: 0.8511 - val_loss: 0.2773\n",
      "Epoch 97/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9142 - loss: 0.2428 - val_accuracy: 0.8511 - val_loss: 0.2743\n",
      "Epoch 98/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9213 - loss: 0.2341 - val_accuracy: 0.8298 - val_loss: 0.2926\n",
      "Epoch 99/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8995 - loss: 0.2458 - val_accuracy: 0.8298 - val_loss: 0.2863\n",
      "Epoch 100/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8943 - loss: 0.2611 - val_accuracy: 0.8511 - val_loss: 0.2698\n",
      "Epoch 101/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8711 - loss: 0.2319 - val_accuracy: 0.8298 - val_loss: 0.2854\n",
      "Epoch 102/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8960 - loss: 0.2442 - val_accuracy: 0.8298 - val_loss: 0.2882\n",
      "Epoch 103/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8715 - loss: 0.2715 - val_accuracy: 0.8511 - val_loss: 0.2729\n",
      "Epoch 104/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9095 - loss: 0.2419 - val_accuracy: 0.8298 - val_loss: 0.2923\n",
      "Epoch 105/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9093 - loss: 0.2752 - val_accuracy: 0.8511 - val_loss: 0.2749\n",
      "Epoch 106/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9150 - loss: 0.2234 - val_accuracy: 0.8511 - val_loss: 0.2775\n",
      "Epoch 107/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9077 - loss: 0.2467 - val_accuracy: 0.8298 - val_loss: 0.2894\n",
      "Epoch 108/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9098 - loss: 0.2473 - val_accuracy: 0.8511 - val_loss: 0.2776\n",
      "Epoch 109/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8888 - loss: 0.2390 - val_accuracy: 0.8511 - val_loss: 0.2753\n",
      "Epoch 110/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8607 - loss: 0.2850 - val_accuracy: 0.8298 - val_loss: 0.2912\n",
      "Epoch 111/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9006 - loss: 0.2481 - val_accuracy: 0.8511 - val_loss: 0.2828\n",
      "Epoch 112/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9054 - loss: 0.2600 - val_accuracy: 0.8511 - val_loss: 0.2739\n",
      "Epoch 113/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8845 - loss: 0.2675 - val_accuracy: 0.8298 - val_loss: 0.2963\n",
      "Epoch 114/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9183 - loss: 0.2303 - val_accuracy: 0.8298 - val_loss: 0.2847\n",
      "Epoch 115/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8866 - loss: 0.2664 - val_accuracy: 0.8511 - val_loss: 0.2772\n",
      "Epoch 116/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9140 - loss: 0.2256 - val_accuracy: 0.8298 - val_loss: 0.2864\n",
      "Epoch 117/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8968 - loss: 0.2542 - val_accuracy: 0.8511 - val_loss: 0.2738\n",
      "Epoch 118/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8715 - loss: 0.2582 - val_accuracy: 0.8298 - val_loss: 0.2824\n",
      "Epoch 119/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9106 - loss: 0.2391 - val_accuracy: 0.8511 - val_loss: 0.2789\n",
      "Epoch 120/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8992 - loss: 0.2315 - val_accuracy: 0.8511 - val_loss: 0.2762\n",
      "Epoch 121/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8958 - loss: 0.2542 - val_accuracy: 0.8511 - val_loss: 0.2808\n",
      "Epoch 122/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9188 - loss: 0.2282 - val_accuracy: 0.8298 - val_loss: 0.2884\n",
      "Epoch 123/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9049 - loss: 0.2270 - val_accuracy: 0.8511 - val_loss: 0.2721\n",
      "Epoch 124/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8832 - loss: 0.2588 - val_accuracy: 0.8298 - val_loss: 0.2850\n",
      "Epoch 125/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9183 - loss: 0.2287 - val_accuracy: 0.8511 - val_loss: 0.2801\n",
      "Epoch 126/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8993 - loss: 0.2289 - val_accuracy: 0.8298 - val_loss: 0.2832\n",
      "Epoch 127/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8956 - loss: 0.2506 - val_accuracy: 0.8298 - val_loss: 0.2821\n",
      "Epoch 128/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9179 - loss: 0.2163 - val_accuracy: 0.8298 - val_loss: 0.2837\n",
      "Epoch 129/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9029 - loss: 0.2525 - val_accuracy: 0.8298 - val_loss: 0.2819\n",
      "Epoch 130/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8884 - loss: 0.2571 - val_accuracy: 0.8298 - val_loss: 0.2823\n",
      "Epoch 131/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9017 - loss: 0.2455 - val_accuracy: 0.8511 - val_loss: 0.2775\n",
      "Epoch 132/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9107 - loss: 0.2321 - val_accuracy: 0.8298 - val_loss: 0.2819\n",
      "Epoch 133/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9051 - loss: 0.2244 - val_accuracy: 0.8298 - val_loss: 0.2851\n",
      "Epoch 134/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9319 - loss: 0.2126 - val_accuracy: 0.8511 - val_loss: 0.2750\n",
      "Epoch 135/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9153 - loss: 0.2354 - val_accuracy: 0.8298 - val_loss: 0.2824\n",
      "Epoch 136/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9175 - loss: 0.2041 - val_accuracy: 0.8298 - val_loss: 0.2929\n",
      "Epoch 137/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9190 - loss: 0.2083 - val_accuracy: 0.8511 - val_loss: 0.2767\n",
      "Epoch 138/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9283 - loss: 0.1919 - val_accuracy: 0.8511 - val_loss: 0.2737\n",
      "Epoch 139/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8912 - loss: 0.2636 - val_accuracy: 0.8298 - val_loss: 0.2966\n",
      "Epoch 140/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9035 - loss: 0.2284 - val_accuracy: 0.8511 - val_loss: 0.2762\n",
      "Epoch 141/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8988 - loss: 0.2304 - val_accuracy: 0.8511 - val_loss: 0.2783\n",
      "Epoch 142/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9210 - loss: 0.2256 - val_accuracy: 0.8298 - val_loss: 0.2898\n",
      "Epoch 143/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9216 - loss: 0.2259 - val_accuracy: 0.8298 - val_loss: 0.2813\n",
      "Epoch 144/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8990 - loss: 0.2338 - val_accuracy: 0.8298 - val_loss: 0.2821\n",
      "Epoch 145/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9060 - loss: 0.2249 - val_accuracy: 0.8298 - val_loss: 0.2864\n",
      "Epoch 146/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9279 - loss: 0.2100 - val_accuracy: 0.8298 - val_loss: 0.2789\n",
      "Epoch 147/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9304 - loss: 0.2056 - val_accuracy: 0.8298 - val_loss: 0.2784\n",
      "Epoch 148/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9195 - loss: 0.2022 - val_accuracy: 0.8298 - val_loss: 0.2927\n",
      "Epoch 149/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9016 - loss: 0.2424 - val_accuracy: 0.8511 - val_loss: 0.2740\n",
      "Epoch 150/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9219 - loss: 0.2042 - val_accuracy: 0.8298 - val_loss: 0.2845\n",
      "Epoch 151/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9035 - loss: 0.2194 - val_accuracy: 0.8298 - val_loss: 0.3002\n",
      "Epoch 152/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9015 - loss: 0.2342 - val_accuracy: 0.8511 - val_loss: 0.2725\n",
      "Epoch 153/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8896 - loss: 0.2111 - val_accuracy: 0.8298 - val_loss: 0.2836\n",
      "Epoch 154/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9263 - loss: 0.2196 - val_accuracy: 0.8298 - val_loss: 0.2901\n",
      "Epoch 155/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9195 - loss: 0.2133 - val_accuracy: 0.8298 - val_loss: 0.2773\n",
      "Epoch 156/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9230 - loss: 0.2100 - val_accuracy: 0.8298 - val_loss: 0.2846\n",
      "Epoch 157/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9017 - loss: 0.2161 - val_accuracy: 0.8298 - val_loss: 0.2811\n",
      "Epoch 158/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9071 - loss: 0.2051 - val_accuracy: 0.8298 - val_loss: 0.2771\n",
      "Epoch 159/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9239 - loss: 0.2141 - val_accuracy: 0.8298 - val_loss: 0.2862\n",
      "Epoch 160/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9144 - loss: 0.2264 - val_accuracy: 0.8298 - val_loss: 0.2898\n",
      "Epoch 161/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9176 - loss: 0.2223 - val_accuracy: 0.8298 - val_loss: 0.2777\n",
      "Epoch 162/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9337 - loss: 0.2128 - val_accuracy: 0.8298 - val_loss: 0.2884\n",
      "Epoch 163/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9265 - loss: 0.2140 - val_accuracy: 0.8298 - val_loss: 0.2945\n",
      "Epoch 164/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9254 - loss: 0.2092 - val_accuracy: 0.8298 - val_loss: 0.2783\n",
      "Epoch 165/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8999 - loss: 0.2122 - val_accuracy: 0.8298 - val_loss: 0.2861\n",
      "Epoch 166/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9165 - loss: 0.2101 - val_accuracy: 0.8298 - val_loss: 0.2846\n",
      "Epoch 167/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9163 - loss: 0.2202 - val_accuracy: 0.8298 - val_loss: 0.2812\n",
      "Epoch 168/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9258 - loss: 0.1888 - val_accuracy: 0.8298 - val_loss: 0.2914\n",
      "Epoch 169/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9157 - loss: 0.2381 - val_accuracy: 0.8298 - val_loss: 0.2778\n",
      "Epoch 170/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9297 - loss: 0.2152 - val_accuracy: 0.8298 - val_loss: 0.2884\n",
      "Epoch 171/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9420 - loss: 0.1870 - val_accuracy: 0.8298 - val_loss: 0.2951\n",
      "Epoch 172/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9203 - loss: 0.1852 - val_accuracy: 0.8511 - val_loss: 0.2773\n",
      "Epoch 173/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8752 - loss: 0.2292 - val_accuracy: 0.8298 - val_loss: 0.2879\n",
      "Epoch 174/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9027 - loss: 0.2397 - val_accuracy: 0.8298 - val_loss: 0.2865\n",
      "Epoch 175/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9331 - loss: 0.2093 - val_accuracy: 0.8298 - val_loss: 0.2972\n",
      "Epoch 176/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9159 - loss: 0.2184 - val_accuracy: 0.8298 - val_loss: 0.2808\n",
      "Epoch 177/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9055 - loss: 0.2167 - val_accuracy: 0.8298 - val_loss: 0.2951\n",
      "Epoch 178/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9128 - loss: 0.2148 - val_accuracy: 0.8298 - val_loss: 0.2953\n",
      "Epoch 179/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9156 - loss: 0.2060 - val_accuracy: 0.8298 - val_loss: 0.2866\n",
      "Epoch 180/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9299 - loss: 0.1897 - val_accuracy: 0.8298 - val_loss: 0.2820\n",
      "Epoch 181/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9297 - loss: 0.1877 - val_accuracy: 0.8298 - val_loss: 0.2945\n",
      "Epoch 182/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9022 - loss: 0.2180 - val_accuracy: 0.8298 - val_loss: 0.2857\n",
      "Epoch 183/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9136 - loss: 0.2010 - val_accuracy: 0.8298 - val_loss: 0.2898\n",
      "Epoch 184/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9148 - loss: 0.2081 - val_accuracy: 0.8298 - val_loss: 0.2865\n",
      "Epoch 185/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9061 - loss: 0.2120 - val_accuracy: 0.8298 - val_loss: 0.2901\n",
      "Epoch 186/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9241 - loss: 0.1832 - val_accuracy: 0.8298 - val_loss: 0.2815\n",
      "Epoch 187/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9145 - loss: 0.2142 - val_accuracy: 0.8298 - val_loss: 0.2923\n",
      "Epoch 188/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9466 - loss: 0.1628 - val_accuracy: 0.8298 - val_loss: 0.2868\n",
      "Epoch 189/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9167 - loss: 0.2057 - val_accuracy: 0.8298 - val_loss: 0.2851\n",
      "Epoch 190/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9375 - loss: 0.1941 - val_accuracy: 0.8298 - val_loss: 0.3090\n",
      "Epoch 191/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9413 - loss: 0.2073 - val_accuracy: 0.8298 - val_loss: 0.2832\n",
      "Epoch 192/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9240 - loss: 0.1946 - val_accuracy: 0.8298 - val_loss: 0.2857\n",
      "Epoch 193/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9502 - loss: 0.1951 - val_accuracy: 0.8298 - val_loss: 0.3071\n",
      "Epoch 194/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9309 - loss: 0.1882 - val_accuracy: 0.8298 - val_loss: 0.2884\n",
      "Epoch 195/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9232 - loss: 0.2008 - val_accuracy: 0.8298 - val_loss: 0.2851\n",
      "Epoch 196/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9431 - loss: 0.1804 - val_accuracy: 0.8298 - val_loss: 0.2955\n",
      "Epoch 197/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9217 - loss: 0.2167 - val_accuracy: 0.8298 - val_loss: 0.2843\n",
      "Epoch 198/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9483 - loss: 0.1692 - val_accuracy: 0.8298 - val_loss: 0.2935\n",
      "Epoch 199/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9119 - loss: 0.2002 - val_accuracy: 0.8298 - val_loss: 0.2879\n",
      "Epoch 200/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9245 - loss: 0.1796 - val_accuracy: 0.8298 - val_loss: 0.2963\n",
      "Epoch 201/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9362 - loss: 0.1696 - val_accuracy: 0.8298 - val_loss: 0.2831\n",
      "Epoch 202/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9213 - loss: 0.2061 - val_accuracy: 0.8298 - val_loss: 0.2899\n",
      "Epoch 203/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9262 - loss: 0.1750 - val_accuracy: 0.8298 - val_loss: 0.3090\n",
      "Epoch 204/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9277 - loss: 0.1858 - val_accuracy: 0.8298 - val_loss: 0.2869\n",
      "Epoch 205/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9070 - loss: 0.1969 - val_accuracy: 0.8298 - val_loss: 0.2893\n",
      "Epoch 206/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9143 - loss: 0.1923 - val_accuracy: 0.8298 - val_loss: 0.2934\n",
      "Epoch 207/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9311 - loss: 0.1953 - val_accuracy: 0.8298 - val_loss: 0.2948\n",
      "Epoch 208/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9240 - loss: 0.1850 - val_accuracy: 0.8298 - val_loss: 0.2860\n",
      "Epoch 209/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9235 - loss: 0.1969 - val_accuracy: 0.8298 - val_loss: 0.3113\n",
      "Epoch 210/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9351 - loss: 0.1826 - val_accuracy: 0.8298 - val_loss: 0.2872\n",
      "Epoch 211/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9044 - loss: 0.2100 - val_accuracy: 0.8298 - val_loss: 0.2898\n",
      "Epoch 212/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9103 - loss: 0.2029 - val_accuracy: 0.8298 - val_loss: 0.2994\n",
      "Epoch 213/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9405 - loss: 0.1873 - val_accuracy: 0.8298 - val_loss: 0.2866\n",
      "Epoch 214/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9259 - loss: 0.1944 - val_accuracy: 0.8298 - val_loss: 0.3098\n",
      "Epoch 215/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9348 - loss: 0.1823 - val_accuracy: 0.8298 - val_loss: 0.2956\n",
      "Epoch 216/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8969 - loss: 0.1998 - val_accuracy: 0.8298 - val_loss: 0.2915\n",
      "Epoch 217/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9329 - loss: 0.1695 - val_accuracy: 0.8298 - val_loss: 0.2937\n",
      "Epoch 218/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9374 - loss: 0.1926 - val_accuracy: 0.8298 - val_loss: 0.2942\n",
      "Epoch 219/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9121 - loss: 0.1982 - val_accuracy: 0.8298 - val_loss: 0.3077\n",
      "Epoch 220/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9543 - loss: 0.1600 - val_accuracy: 0.8298 - val_loss: 0.2906\n",
      "Epoch 221/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9212 - loss: 0.1893 - val_accuracy: 0.8298 - val_loss: 0.2993\n",
      "Epoch 222/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9358 - loss: 0.1846 - val_accuracy: 0.8298 - val_loss: 0.2982\n",
      "Epoch 223/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9378 - loss: 0.1739 - val_accuracy: 0.8298 - val_loss: 0.2944\n",
      "Epoch 224/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9258 - loss: 0.1798 - val_accuracy: 0.8298 - val_loss: 0.3028\n",
      "Epoch 225/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9428 - loss: 0.1622 - val_accuracy: 0.8298 - val_loss: 0.2960\n",
      "Epoch 226/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8931 - loss: 0.2254 - val_accuracy: 0.8298 - val_loss: 0.2904\n",
      "Epoch 227/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9325 - loss: 0.1821 - val_accuracy: 0.8298 - val_loss: 0.3124\n",
      "Epoch 228/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9196 - loss: 0.1748 - val_accuracy: 0.8298 - val_loss: 0.2950\n",
      "Epoch 229/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9137 - loss: 0.1846 - val_accuracy: 0.8298 - val_loss: 0.3005\n",
      "Epoch 230/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9276 - loss: 0.1700 - val_accuracy: 0.8298 - val_loss: 0.2954\n",
      "Epoch 231/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9345 - loss: 0.1725 - val_accuracy: 0.8298 - val_loss: 0.3035\n",
      "Epoch 232/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9411 - loss: 0.1999 - val_accuracy: 0.8298 - val_loss: 0.2996\n",
      "Epoch 233/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9250 - loss: 0.1928 - val_accuracy: 0.8298 - val_loss: 0.3048\n",
      "Epoch 234/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9387 - loss: 0.1890 - val_accuracy: 0.8298 - val_loss: 0.2927\n",
      "Epoch 235/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9448 - loss: 0.1591 - val_accuracy: 0.8298 - val_loss: 0.3022\n",
      "Epoch 236/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9497 - loss: 0.1729 - val_accuracy: 0.8298 - val_loss: 0.3037\n",
      "Epoch 237/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9477 - loss: 0.1658 - val_accuracy: 0.8298 - val_loss: 0.3020\n",
      "Epoch 238/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9160 - loss: 0.2118 - val_accuracy: 0.8298 - val_loss: 0.2972\n",
      "Epoch 239/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9223 - loss: 0.1797 - val_accuracy: 0.8298 - val_loss: 0.3003\n",
      "Epoch 240/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9399 - loss: 0.1735 - val_accuracy: 0.8298 - val_loss: 0.3074\n",
      "Epoch 241/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9400 - loss: 0.1671 - val_accuracy: 0.8298 - val_loss: 0.3041\n",
      "Epoch 242/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9168 - loss: 0.1692 - val_accuracy: 0.8298 - val_loss: 0.3035\n",
      "Epoch 243/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9319 - loss: 0.1844 - val_accuracy: 0.8298 - val_loss: 0.3152\n",
      "Epoch 244/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9363 - loss: 0.1623 - val_accuracy: 0.8298 - val_loss: 0.2994\n",
      "Epoch 245/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9359 - loss: 0.1647 - val_accuracy: 0.8298 - val_loss: 0.2956\n",
      "Epoch 246/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9393 - loss: 0.1635 - val_accuracy: 0.8298 - val_loss: 0.3199\n",
      "Epoch 247/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9572 - loss: 0.1648 - val_accuracy: 0.8298 - val_loss: 0.2974\n",
      "Epoch 248/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9146 - loss: 0.1812 - val_accuracy: 0.8298 - val_loss: 0.3091\n",
      "Epoch 249/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9450 - loss: 0.1622 - val_accuracy: 0.8298 - val_loss: 0.3205\n",
      "Epoch 250/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9198 - loss: 0.1734 - val_accuracy: 0.8298 - val_loss: 0.2985\n",
      "Epoch 251/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9115 - loss: 0.1779 - val_accuracy: 0.8298 - val_loss: 0.3035\n",
      "Epoch 252/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9461 - loss: 0.1496 - val_accuracy: 0.8298 - val_loss: 0.3201\n",
      "Epoch 253/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9363 - loss: 0.1977 - val_accuracy: 0.8511 - val_loss: 0.2995\n",
      "Epoch 254/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9337 - loss: 0.1707 - val_accuracy: 0.8298 - val_loss: 0.3401\n",
      "Epoch 255/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9624 - loss: 0.1472 - val_accuracy: 0.8298 - val_loss: 0.3044\n",
      "Epoch 256/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9251 - loss: 0.1661 - val_accuracy: 0.8511 - val_loss: 0.2992\n",
      "Epoch 257/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9277 - loss: 0.1654 - val_accuracy: 0.8298 - val_loss: 0.3165\n",
      "Epoch 258/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9319 - loss: 0.1763 - val_accuracy: 0.8298 - val_loss: 0.3091\n",
      "Epoch 259/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9229 - loss: 0.1768 - val_accuracy: 0.8298 - val_loss: 0.3049\n",
      "Epoch 260/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9512 - loss: 0.1567 - val_accuracy: 0.8298 - val_loss: 0.3255\n",
      "Epoch 261/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9576 - loss: 0.1799 - val_accuracy: 0.8298 - val_loss: 0.3055\n",
      "Epoch 262/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9316 - loss: 0.1739 - val_accuracy: 0.8298 - val_loss: 0.3100\n",
      "Epoch 263/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9556 - loss: 0.1604 - val_accuracy: 0.8298 - val_loss: 0.3101\n",
      "Epoch 264/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9648 - loss: 0.1364 - val_accuracy: 0.8298 - val_loss: 0.3142\n",
      "Epoch 265/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9337 - loss: 0.1756 - val_accuracy: 0.8298 - val_loss: 0.3065\n",
      "Epoch 266/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9257 - loss: 0.1757 - val_accuracy: 0.8298 - val_loss: 0.3197\n",
      "Epoch 267/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9568 - loss: 0.1573 - val_accuracy: 0.8298 - val_loss: 0.3074\n",
      "Epoch 268/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9229 - loss: 0.1702 - val_accuracy: 0.8298 - val_loss: 0.3132\n",
      "Epoch 269/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9633 - loss: 0.1732 - val_accuracy: 0.8298 - val_loss: 0.3153\n",
      "Epoch 270/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9330 - loss: 0.1511 - val_accuracy: 0.8298 - val_loss: 0.3071\n",
      "Epoch 271/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9426 - loss: 0.1532 - val_accuracy: 0.8298 - val_loss: 0.3109\n",
      "Epoch 272/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9451 - loss: 0.1506 - val_accuracy: 0.8298 - val_loss: 0.3289\n",
      "Epoch 273/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9376 - loss: 0.1635 - val_accuracy: 0.8298 - val_loss: 0.3090\n",
      "Epoch 274/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9501 - loss: 0.1525 - val_accuracy: 0.8298 - val_loss: 0.3103\n",
      "Epoch 275/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9363 - loss: 0.1659 - val_accuracy: 0.8298 - val_loss: 0.3218\n",
      "Epoch 276/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9520 - loss: 0.1650 - val_accuracy: 0.8298 - val_loss: 0.3112\n",
      "Epoch 277/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9421 - loss: 0.1539 - val_accuracy: 0.8298 - val_loss: 0.3225\n",
      "Epoch 278/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9676 - loss: 0.1501 - val_accuracy: 0.8298 - val_loss: 0.3164\n",
      "Epoch 279/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9662 - loss: 0.1402 - val_accuracy: 0.8298 - val_loss: 0.3167\n",
      "Epoch 280/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9254 - loss: 0.1647 - val_accuracy: 0.8298 - val_loss: 0.3157\n",
      "Epoch 281/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9413 - loss: 0.1572 - val_accuracy: 0.8298 - val_loss: 0.3090\n",
      "Epoch 282/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9392 - loss: 0.1598 - val_accuracy: 0.8298 - val_loss: 0.3343\n",
      "Epoch 283/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9534 - loss: 0.1590 - val_accuracy: 0.8511 - val_loss: 0.3108\n",
      "Epoch 284/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9361 - loss: 0.1571 - val_accuracy: 0.8298 - val_loss: 0.3268\n",
      "Epoch 285/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9728 - loss: 0.1398 - val_accuracy: 0.8298 - val_loss: 0.3150\n",
      "Epoch 286/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9458 - loss: 0.1646 - val_accuracy: 0.8298 - val_loss: 0.3108\n",
      "Epoch 287/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9724 - loss: 0.1299 - val_accuracy: 0.8298 - val_loss: 0.3257\n",
      "Epoch 288/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9457 - loss: 0.1518 - val_accuracy: 0.8298 - val_loss: 0.3163\n",
      "Epoch 289/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9520 - loss: 0.1396 - val_accuracy: 0.8298 - val_loss: 0.3186\n",
      "Epoch 290/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9488 - loss: 0.1644 - val_accuracy: 0.8298 - val_loss: 0.3137\n",
      "Epoch 291/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9683 - loss: 0.1434 - val_accuracy: 0.8298 - val_loss: 0.3250\n",
      "Epoch 292/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9537 - loss: 0.1475 - val_accuracy: 0.8298 - val_loss: 0.3149\n",
      "Epoch 293/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9593 - loss: 0.1365 - val_accuracy: 0.8298 - val_loss: 0.3135\n",
      "Epoch 294/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9473 - loss: 0.1554 - val_accuracy: 0.8298 - val_loss: 0.3247\n",
      "Epoch 295/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9699 - loss: 0.1461 - val_accuracy: 0.8298 - val_loss: 0.3240\n",
      "Epoch 296/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9603 - loss: 0.1429 - val_accuracy: 0.8298 - val_loss: 0.3193\n",
      "Epoch 297/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9488 - loss: 0.1486 - val_accuracy: 0.8298 - val_loss: 0.3189\n",
      "Epoch 298/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9548 - loss: 0.1377 - val_accuracy: 0.8298 - val_loss: 0.3248\n",
      "Epoch 299/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9412 - loss: 0.1607 - val_accuracy: 0.8298 - val_loss: 0.3193\n",
      "Epoch 300/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9594 - loss: 0.1515 - val_accuracy: 0.8298 - val_loss: 0.3233\n",
      "Epoch 301/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9582 - loss: 0.1384 - val_accuracy: 0.8298 - val_loss: 0.3272\n",
      "Epoch 302/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9516 - loss: 0.1591 - val_accuracy: 0.8298 - val_loss: 0.3239\n",
      "Epoch 303/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9662 - loss: 0.1487 - val_accuracy: 0.8298 - val_loss: 0.3293\n",
      "Epoch 304/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9587 - loss: 0.1354 - val_accuracy: 0.8298 - val_loss: 0.3196\n",
      "Epoch 305/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9337 - loss: 0.1471 - val_accuracy: 0.8298 - val_loss: 0.3257\n",
      "Epoch 306/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9397 - loss: 0.1700 - val_accuracy: 0.8298 - val_loss: 0.3323\n",
      "Epoch 307/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9452 - loss: 0.1349 - val_accuracy: 0.8511 - val_loss: 0.3171\n",
      "Epoch 308/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9749 - loss: 0.1202 - val_accuracy: 0.8298 - val_loss: 0.3332\n",
      "Epoch 309/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9554 - loss: 0.1567 - val_accuracy: 0.8298 - val_loss: 0.3247\n",
      "Epoch 310/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9597 - loss: 0.1278 - val_accuracy: 0.8298 - val_loss: 0.3333\n",
      "Epoch 311/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9431 - loss: 0.1639 - val_accuracy: 0.8298 - val_loss: 0.3233\n",
      "Epoch 312/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9121 - loss: 0.1615 - val_accuracy: 0.8298 - val_loss: 0.3339\n",
      "Epoch 313/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9570 - loss: 0.1394 - val_accuracy: 0.8298 - val_loss: 0.3280\n",
      "Epoch 314/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9564 - loss: 0.1269 - val_accuracy: 0.8298 - val_loss: 0.3291\n",
      "Epoch 315/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9553 - loss: 0.1420 - val_accuracy: 0.8298 - val_loss: 0.3344\n",
      "Epoch 316/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9470 - loss: 0.1550 - val_accuracy: 0.8511 - val_loss: 0.3235\n",
      "Epoch 317/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9581 - loss: 0.1377 - val_accuracy: 0.8298 - val_loss: 0.3452\n",
      "Epoch 318/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9465 - loss: 0.1660 - val_accuracy: 0.8298 - val_loss: 0.3281\n",
      "Epoch 319/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9532 - loss: 0.1422 - val_accuracy: 0.8298 - val_loss: 0.3436\n",
      "Epoch 320/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9245 - loss: 0.1658 - val_accuracy: 0.8298 - val_loss: 0.3261\n",
      "Epoch 321/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9373 - loss: 0.1509 - val_accuracy: 0.8298 - val_loss: 0.3398\n",
      "Epoch 322/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9699 - loss: 0.1234 - val_accuracy: 0.8298 - val_loss: 0.3292\n",
      "Epoch 323/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9347 - loss: 0.1545 - val_accuracy: 0.8298 - val_loss: 0.3339\n",
      "Epoch 324/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9611 - loss: 0.1448 - val_accuracy: 0.8298 - val_loss: 0.3394\n",
      "Epoch 325/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9559 - loss: 0.1319 - val_accuracy: 0.8298 - val_loss: 0.3338\n",
      "Epoch 326/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9669 - loss: 0.1322 - val_accuracy: 0.8298 - val_loss: 0.3418\n",
      "Epoch 327/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9526 - loss: 0.1334 - val_accuracy: 0.8298 - val_loss: 0.3339\n",
      "Epoch 328/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9675 - loss: 0.1359 - val_accuracy: 0.8298 - val_loss: 0.3434\n",
      "Epoch 329/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9742 - loss: 0.1058 - val_accuracy: 0.8298 - val_loss: 0.3360\n",
      "Epoch 330/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9414 - loss: 0.1427 - val_accuracy: 0.8298 - val_loss: 0.3402\n",
      "Epoch 331/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9543 - loss: 0.1618 - val_accuracy: 0.8298 - val_loss: 0.3347\n",
      "Epoch 332/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9551 - loss: 0.1254 - val_accuracy: 0.8298 - val_loss: 0.3612\n",
      "Epoch 333/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9725 - loss: 0.1320 - val_accuracy: 0.8511 - val_loss: 0.3342\n",
      "Epoch 334/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9299 - loss: 0.1508 - val_accuracy: 0.8298 - val_loss: 0.3549\n",
      "Epoch 335/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9635 - loss: 0.1343 - val_accuracy: 0.8511 - val_loss: 0.3327\n",
      "Epoch 336/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9644 - loss: 0.1243 - val_accuracy: 0.8298 - val_loss: 0.3475\n",
      "Epoch 337/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9686 - loss: 0.1452 - val_accuracy: 0.8298 - val_loss: 0.3427\n",
      "Epoch 338/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9437 - loss: 0.1611 - val_accuracy: 0.8511 - val_loss: 0.3343\n",
      "Epoch 339/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9777 - loss: 0.1095 - val_accuracy: 0.8298 - val_loss: 0.3610\n",
      "Epoch 340/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9532 - loss: 0.1668 - val_accuracy: 0.8298 - val_loss: 0.3409\n",
      "Epoch 341/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9606 - loss: 0.1282 - val_accuracy: 0.8298 - val_loss: 0.3413\n",
      "Epoch 342/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9653 - loss: 0.1350 - val_accuracy: 0.8298 - val_loss: 0.3439\n",
      "Epoch 343/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9510 - loss: 0.1398 - val_accuracy: 0.8298 - val_loss: 0.3389\n",
      "Epoch 344/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9410 - loss: 0.1444 - val_accuracy: 0.8298 - val_loss: 0.3604\n",
      "Epoch 345/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9409 - loss: 0.1477 - val_accuracy: 0.8298 - val_loss: 0.3398\n",
      "Epoch 346/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9610 - loss: 0.1331 - val_accuracy: 0.8298 - val_loss: 0.3447\n",
      "Epoch 347/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9686 - loss: 0.1331 - val_accuracy: 0.8298 - val_loss: 0.3474\n",
      "Epoch 348/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9779 - loss: 0.1092 - val_accuracy: 0.8298 - val_loss: 0.3495\n",
      "Epoch 349/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9559 - loss: 0.1315 - val_accuracy: 0.8298 - val_loss: 0.3489\n",
      "Epoch 350/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9475 - loss: 0.1365 - val_accuracy: 0.8298 - val_loss: 0.3545\n",
      "Epoch 351/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9557 - loss: 0.1270 - val_accuracy: 0.8511 - val_loss: 0.3410\n",
      "Epoch 352/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9489 - loss: 0.1500 - val_accuracy: 0.8298 - val_loss: 0.3646\n",
      "Epoch 353/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9854 - loss: 0.1081 - val_accuracy: 0.8298 - val_loss: 0.3526\n",
      "Epoch 354/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9435 - loss: 0.1262 - val_accuracy: 0.8298 - val_loss: 0.3503\n",
      "Epoch 355/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9825 - loss: 0.1114 - val_accuracy: 0.8298 - val_loss: 0.3502\n",
      "Epoch 356/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9576 - loss: 0.1316 - val_accuracy: 0.8298 - val_loss: 0.3505\n",
      "Epoch 357/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9730 - loss: 0.1138 - val_accuracy: 0.8298 - val_loss: 0.3464\n",
      "Epoch 358/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9644 - loss: 0.1245 - val_accuracy: 0.8298 - val_loss: 0.3571\n",
      "Epoch 359/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9648 - loss: 0.1230 - val_accuracy: 0.8298 - val_loss: 0.3601\n",
      "Epoch 360/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9518 - loss: 0.1277 - val_accuracy: 0.8298 - val_loss: 0.3550\n",
      "Epoch 361/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9487 - loss: 0.1432 - val_accuracy: 0.8298 - val_loss: 0.3654\n",
      "Epoch 362/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9737 - loss: 0.1290 - val_accuracy: 0.8511 - val_loss: 0.3449\n",
      "Epoch 363/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9519 - loss: 0.1419 - val_accuracy: 0.8298 - val_loss: 0.3624\n",
      "Epoch 364/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9693 - loss: 0.1197 - val_accuracy: 0.8298 - val_loss: 0.3516\n",
      "Epoch 365/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9565 - loss: 0.1268 - val_accuracy: 0.8298 - val_loss: 0.3507\n",
      "Epoch 366/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9480 - loss: 0.1379 - val_accuracy: 0.8298 - val_loss: 0.3615\n",
      "Epoch 367/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9650 - loss: 0.1219 - val_accuracy: 0.8298 - val_loss: 0.3579\n",
      "Epoch 368/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9359 - loss: 0.1334 - val_accuracy: 0.8511 - val_loss: 0.3524\n",
      "Epoch 369/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9593 - loss: 0.1342 - val_accuracy: 0.8298 - val_loss: 0.3900\n",
      "Epoch 370/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9241 - loss: 0.1484 - val_accuracy: 0.8298 - val_loss: 0.3564\n",
      "Epoch 371/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9565 - loss: 0.1148 - val_accuracy: 0.8298 - val_loss: 0.3595\n",
      "Epoch 372/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9681 - loss: 0.1205 - val_accuracy: 0.8298 - val_loss: 0.3649\n",
      "Epoch 373/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9642 - loss: 0.1279 - val_accuracy: 0.8298 - val_loss: 0.3579\n",
      "Epoch 374/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9727 - loss: 0.1064 - val_accuracy: 0.8298 - val_loss: 0.3638\n",
      "Epoch 375/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9424 - loss: 0.1426 - val_accuracy: 0.8298 - val_loss: 0.3615\n",
      "Epoch 376/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9739 - loss: 0.0970 - val_accuracy: 0.8298 - val_loss: 0.3645\n",
      "Epoch 377/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9573 - loss: 0.1207 - val_accuracy: 0.8298 - val_loss: 0.3635\n",
      "Epoch 378/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9652 - loss: 0.1267 - val_accuracy: 0.8298 - val_loss: 0.3589\n",
      "Epoch 379/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9761 - loss: 0.1053 - val_accuracy: 0.8298 - val_loss: 0.3793\n",
      "Epoch 380/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9595 - loss: 0.1394 - val_accuracy: 0.8511 - val_loss: 0.3568\n",
      "Epoch 381/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9524 - loss: 0.1267 - val_accuracy: 0.8298 - val_loss: 0.3714\n",
      "Epoch 382/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9724 - loss: 0.1189 - val_accuracy: 0.8298 - val_loss: 0.3621\n",
      "Epoch 383/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9640 - loss: 0.1146 - val_accuracy: 0.8298 - val_loss: 0.3624\n",
      "Epoch 384/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9416 - loss: 0.1368 - val_accuracy: 0.8298 - val_loss: 0.3705\n",
      "Epoch 385/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9642 - loss: 0.1182 - val_accuracy: 0.8298 - val_loss: 0.3631\n",
      "Epoch 386/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9556 - loss: 0.1182 - val_accuracy: 0.8298 - val_loss: 0.3694\n",
      "Epoch 387/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9518 - loss: 0.1309 - val_accuracy: 0.8298 - val_loss: 0.3638\n",
      "Epoch 388/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9669 - loss: 0.1228 - val_accuracy: 0.8298 - val_loss: 0.3738\n",
      "Epoch 389/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9803 - loss: 0.1181 - val_accuracy: 0.8298 - val_loss: 0.3689\n",
      "Epoch 390/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9797 - loss: 0.0950 - val_accuracy: 0.8298 - val_loss: 0.3763\n",
      "Epoch 391/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9560 - loss: 0.1160 - val_accuracy: 0.8298 - val_loss: 0.3599\n",
      "Epoch 392/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9574 - loss: 0.1145 - val_accuracy: 0.8298 - val_loss: 0.3840\n",
      "Epoch 393/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9802 - loss: 0.1255 - val_accuracy: 0.8298 - val_loss: 0.3705\n",
      "Epoch 394/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9494 - loss: 0.1260 - val_accuracy: 0.8298 - val_loss: 0.3765\n",
      "Epoch 395/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9569 - loss: 0.1258 - val_accuracy: 0.8298 - val_loss: 0.3715\n",
      "Epoch 396/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9658 - loss: 0.1286 - val_accuracy: 0.8298 - val_loss: 0.3663\n",
      "Epoch 397/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9640 - loss: 0.1113 - val_accuracy: 0.8298 - val_loss: 0.3717\n",
      "Epoch 398/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9762 - loss: 0.1043 - val_accuracy: 0.8298 - val_loss: 0.3751\n",
      "Epoch 399/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9717 - loss: 0.1187 - val_accuracy: 0.8298 - val_loss: 0.3673\n",
      "Epoch 400/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9673 - loss: 0.1019 - val_accuracy: 0.8298 - val_loss: 0.3803\n",
      "Epoch 401/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9692 - loss: 0.1047 - val_accuracy: 0.8298 - val_loss: 0.3727\n",
      "Epoch 402/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9647 - loss: 0.1098 - val_accuracy: 0.8298 - val_loss: 0.3726\n",
      "Epoch 403/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9671 - loss: 0.1090 - val_accuracy: 0.8298 - val_loss: 0.3747\n",
      "Epoch 404/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9625 - loss: 0.1045 - val_accuracy: 0.8298 - val_loss: 0.3727\n",
      "Epoch 405/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9669 - loss: 0.0995 - val_accuracy: 0.8298 - val_loss: 0.3760\n",
      "Epoch 406/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9673 - loss: 0.1130 - val_accuracy: 0.8298 - val_loss: 0.3850\n",
      "Epoch 407/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9662 - loss: 0.1028 - val_accuracy: 0.8298 - val_loss: 0.3729\n",
      "Epoch 408/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9498 - loss: 0.1212 - val_accuracy: 0.8298 - val_loss: 0.3813\n",
      "Epoch 409/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9755 - loss: 0.0940 - val_accuracy: 0.8298 - val_loss: 0.3820\n",
      "Epoch 410/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9615 - loss: 0.1253 - val_accuracy: 0.8298 - val_loss: 0.3735\n",
      "Epoch 411/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9828 - loss: 0.1032 - val_accuracy: 0.8298 - val_loss: 0.3844\n",
      "Epoch 412/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9847 - loss: 0.0786 - val_accuracy: 0.8298 - val_loss: 0.3749\n",
      "Epoch 413/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9613 - loss: 0.1177 - val_accuracy: 0.8298 - val_loss: 0.3913\n",
      "Epoch 414/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9681 - loss: 0.1056 - val_accuracy: 0.8298 - val_loss: 0.3791\n",
      "Epoch 415/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9793 - loss: 0.0898 - val_accuracy: 0.8298 - val_loss: 0.3742\n",
      "Epoch 416/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9642 - loss: 0.1183 - val_accuracy: 0.8298 - val_loss: 0.3842\n",
      "Epoch 417/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9613 - loss: 0.1101 - val_accuracy: 0.8298 - val_loss: 0.3785\n",
      "Epoch 418/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9775 - loss: 0.0955 - val_accuracy: 0.8298 - val_loss: 0.3853\n",
      "Epoch 419/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9688 - loss: 0.1083 - val_accuracy: 0.8298 - val_loss: 0.3872\n",
      "Epoch 420/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9799 - loss: 0.0910 - val_accuracy: 0.8298 - val_loss: 0.3753\n",
      "Epoch 421/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9407 - loss: 0.1202 - val_accuracy: 0.8298 - val_loss: 0.3937\n",
      "Epoch 422/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9621 - loss: 0.1245 - val_accuracy: 0.8298 - val_loss: 0.3862\n",
      "Epoch 423/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9385 - loss: 0.1261 - val_accuracy: 0.8298 - val_loss: 0.3791\n",
      "Epoch 424/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9690 - loss: 0.0977 - val_accuracy: 0.8298 - val_loss: 0.3863\n",
      "Epoch 425/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9593 - loss: 0.1108 - val_accuracy: 0.8298 - val_loss: 0.3945\n",
      "Epoch 426/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9617 - loss: 0.1091 - val_accuracy: 0.8085 - val_loss: 0.3821\n",
      "Epoch 427/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9349 - loss: 0.1253 - val_accuracy: 0.8298 - val_loss: 0.3935\n",
      "Epoch 428/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9684 - loss: 0.1159 - val_accuracy: 0.8298 - val_loss: 0.3857\n",
      "Epoch 429/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9688 - loss: 0.1067 - val_accuracy: 0.8298 - val_loss: 0.4058\n",
      "Epoch 430/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9696 - loss: 0.1004 - val_accuracy: 0.8085 - val_loss: 0.3831\n",
      "Epoch 431/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9715 - loss: 0.0944 - val_accuracy: 0.8298 - val_loss: 0.3895\n",
      "Epoch 432/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9732 - loss: 0.1003 - val_accuracy: 0.8298 - val_loss: 0.3930\n",
      "Epoch 433/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9595 - loss: 0.1109 - val_accuracy: 0.8298 - val_loss: 0.3853\n",
      "Epoch 434/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9702 - loss: 0.0896 - val_accuracy: 0.8298 - val_loss: 0.3901\n",
      "Epoch 435/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9593 - loss: 0.0999 - val_accuracy: 0.8298 - val_loss: 0.3930\n",
      "Epoch 436/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9768 - loss: 0.1144 - val_accuracy: 0.8298 - val_loss: 0.3903\n",
      "Epoch 437/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9695 - loss: 0.0968 - val_accuracy: 0.8298 - val_loss: 0.4050\n",
      "Epoch 438/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9777 - loss: 0.0911 - val_accuracy: 0.8298 - val_loss: 0.3886\n",
      "Epoch 439/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9550 - loss: 0.1092 - val_accuracy: 0.8298 - val_loss: 0.3901\n",
      "Epoch 440/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9535 - loss: 0.1151 - val_accuracy: 0.8298 - val_loss: 0.3948\n",
      "Epoch 441/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9653 - loss: 0.0983 - val_accuracy: 0.8298 - val_loss: 0.3975\n",
      "Epoch 442/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9646 - loss: 0.1017 - val_accuracy: 0.8298 - val_loss: 0.3898\n",
      "Epoch 443/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9684 - loss: 0.1123 - val_accuracy: 0.8298 - val_loss: 0.4090\n",
      "Epoch 444/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9818 - loss: 0.0971 - val_accuracy: 0.8298 - val_loss: 0.3893\n",
      "Epoch 445/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9551 - loss: 0.1034 - val_accuracy: 0.8085 - val_loss: 0.3874\n",
      "Epoch 446/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9686 - loss: 0.1046 - val_accuracy: 0.8298 - val_loss: 0.4044\n",
      "Epoch 447/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9764 - loss: 0.0870 - val_accuracy: 0.8085 - val_loss: 0.3857\n",
      "Epoch 448/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9474 - loss: 0.1131 - val_accuracy: 0.8298 - val_loss: 0.3968\n",
      "Epoch 449/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9607 - loss: 0.1099 - val_accuracy: 0.8298 - val_loss: 0.3941\n",
      "Epoch 450/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9532 - loss: 0.1138 - val_accuracy: 0.8085 - val_loss: 0.3916\n",
      "Epoch 451/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9804 - loss: 0.0946 - val_accuracy: 0.8298 - val_loss: 0.4015\n",
      "Epoch 452/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9735 - loss: 0.0945 - val_accuracy: 0.8298 - val_loss: 0.3939\n",
      "Epoch 453/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9808 - loss: 0.0781 - val_accuracy: 0.8298 - val_loss: 0.3981\n",
      "Epoch 454/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9694 - loss: 0.0865 - val_accuracy: 0.8298 - val_loss: 0.3995\n",
      "Epoch 455/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9636 - loss: 0.0972 - val_accuracy: 0.8298 - val_loss: 0.3958\n",
      "Epoch 456/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9440 - loss: 0.1062 - val_accuracy: 0.8298 - val_loss: 0.4019\n",
      "Epoch 457/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9607 - loss: 0.1155 - val_accuracy: 0.8298 - val_loss: 0.4009\n",
      "Epoch 458/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9545 - loss: 0.1110 - val_accuracy: 0.8298 - val_loss: 0.4013\n",
      "Epoch 459/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9796 - loss: 0.0980 - val_accuracy: 0.8298 - val_loss: 0.4159\n",
      "Epoch 460/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9804 - loss: 0.0907 - val_accuracy: 0.8085 - val_loss: 0.3969\n",
      "Epoch 461/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9654 - loss: 0.1024 - val_accuracy: 0.8298 - val_loss: 0.4207\n",
      "Epoch 462/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9850 - loss: 0.0923 - val_accuracy: 0.8085 - val_loss: 0.3973\n",
      "Epoch 463/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9431 - loss: 0.1157 - val_accuracy: 0.8085 - val_loss: 0.3982\n",
      "Epoch 464/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9671 - loss: 0.0930 - val_accuracy: 0.8298 - val_loss: 0.4178\n",
      "Epoch 465/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9634 - loss: 0.0986 - val_accuracy: 0.8085 - val_loss: 0.4010\n",
      "Epoch 466/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9723 - loss: 0.0926 - val_accuracy: 0.8298 - val_loss: 0.4087\n",
      "Epoch 467/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9595 - loss: 0.0965 - val_accuracy: 0.8298 - val_loss: 0.4081\n",
      "Epoch 468/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9741 - loss: 0.0986 - val_accuracy: 0.8085 - val_loss: 0.4029\n",
      "Epoch 469/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9677 - loss: 0.1047 - val_accuracy: 0.8298 - val_loss: 0.4136\n",
      "Epoch 470/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9720 - loss: 0.1009 - val_accuracy: 0.8298 - val_loss: 0.4064\n",
      "Epoch 471/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9580 - loss: 0.1037 - val_accuracy: 0.8298 - val_loss: 0.4113\n",
      "Epoch 472/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9655 - loss: 0.0951 - val_accuracy: 0.8298 - val_loss: 0.4152\n",
      "Epoch 473/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9638 - loss: 0.0979 - val_accuracy: 0.8298 - val_loss: 0.4079\n",
      "Epoch 474/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9602 - loss: 0.1006 - val_accuracy: 0.8298 - val_loss: 0.4112\n",
      "Epoch 475/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9674 - loss: 0.0921 - val_accuracy: 0.8298 - val_loss: 0.4136\n",
      "Epoch 476/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9692 - loss: 0.0943 - val_accuracy: 0.8298 - val_loss: 0.4071\n",
      "Epoch 477/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9802 - loss: 0.0844 - val_accuracy: 0.8298 - val_loss: 0.4206\n",
      "Epoch 478/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9613 - loss: 0.1128 - val_accuracy: 0.8085 - val_loss: 0.4109\n",
      "Epoch 479/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9761 - loss: 0.0964 - val_accuracy: 0.8298 - val_loss: 0.4277\n",
      "Epoch 480/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9791 - loss: 0.0889 - val_accuracy: 0.8085 - val_loss: 0.4060\n",
      "Epoch 481/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9597 - loss: 0.0943 - val_accuracy: 0.8298 - val_loss: 0.4164\n",
      "Epoch 482/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9744 - loss: 0.0878 - val_accuracy: 0.8298 - val_loss: 0.4178\n",
      "Epoch 483/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9725 - loss: 0.0939 - val_accuracy: 0.8298 - val_loss: 0.4162\n",
      "Epoch 484/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9708 - loss: 0.1008 - val_accuracy: 0.8298 - val_loss: 0.4242\n",
      "Epoch 485/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9651 - loss: 0.1124 - val_accuracy: 0.8298 - val_loss: 0.4185\n",
      "Epoch 486/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9686 - loss: 0.0885 - val_accuracy: 0.8298 - val_loss: 0.4161\n",
      "Epoch 487/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9576 - loss: 0.0987 - val_accuracy: 0.8085 - val_loss: 0.4142\n",
      "Epoch 488/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9571 - loss: 0.1008 - val_accuracy: 0.8298 - val_loss: 0.4379\n",
      "Epoch 489/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9817 - loss: 0.0855 - val_accuracy: 0.8085 - val_loss: 0.4188\n",
      "Epoch 490/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9560 - loss: 0.1021 - val_accuracy: 0.8298 - val_loss: 0.4168\n",
      "Epoch 491/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9802 - loss: 0.0887 - val_accuracy: 0.8298 - val_loss: 0.4175\n",
      "Epoch 492/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9785 - loss: 0.0813 - val_accuracy: 0.8298 - val_loss: 0.4235\n",
      "Epoch 493/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9679 - loss: 0.0926 - val_accuracy: 0.8298 - val_loss: 0.4209\n",
      "Epoch 494/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9681 - loss: 0.0936 - val_accuracy: 0.8085 - val_loss: 0.4174\n",
      "Epoch 495/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9724 - loss: 0.0871 - val_accuracy: 0.8298 - val_loss: 0.4277\n",
      "Epoch 496/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9696 - loss: 0.0970 - val_accuracy: 0.8085 - val_loss: 0.4195\n",
      "Epoch 497/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9723 - loss: 0.0880 - val_accuracy: 0.8298 - val_loss: 0.4260\n",
      "Epoch 498/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9677 - loss: 0.0940 - val_accuracy: 0.8298 - val_loss: 0.4224\n",
      "Epoch 499/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9813 - loss: 0.0761 - val_accuracy: 0.8298 - val_loss: 0.4225\n",
      "Epoch 500/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9815 - loss: 0.0762 - val_accuracy: 0.8085 - val_loss: 0.4235\n",
      "Epoch 501/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9636 - loss: 0.0971 - val_accuracy: 0.8298 - val_loss: 0.4278\n",
      "Epoch 502/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9649 - loss: 0.0982 - val_accuracy: 0.8298 - val_loss: 0.4335\n",
      "Epoch 503/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9799 - loss: 0.0797 - val_accuracy: 0.8085 - val_loss: 0.4245\n",
      "Epoch 504/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9694 - loss: 0.0947 - val_accuracy: 0.8298 - val_loss: 0.4306\n",
      "Epoch 505/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9699 - loss: 0.0834 - val_accuracy: 0.8085 - val_loss: 0.4174\n",
      "Epoch 506/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9624 - loss: 0.0930 - val_accuracy: 0.8085 - val_loss: 0.4227\n",
      "Epoch 507/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9808 - loss: 0.0888 - val_accuracy: 0.8298 - val_loss: 0.4553\n",
      "Epoch 508/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9790 - loss: 0.0834 - val_accuracy: 0.7660 - val_loss: 0.4327\n",
      "Epoch 509/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9581 - loss: 0.0830 - val_accuracy: 0.8298 - val_loss: 0.4472\n",
      "Epoch 510/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9759 - loss: 0.0947 - val_accuracy: 0.8085 - val_loss: 0.4298\n",
      "Epoch 511/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9673 - loss: 0.0809 - val_accuracy: 0.8085 - val_loss: 0.4290\n",
      "Epoch 512/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9668 - loss: 0.0849 - val_accuracy: 0.8298 - val_loss: 0.4300\n",
      "Epoch 513/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9843 - loss: 0.0757 - val_accuracy: 0.8085 - val_loss: 0.4304\n",
      "Epoch 514/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9671 - loss: 0.0768 - val_accuracy: 0.8298 - val_loss: 0.4411\n",
      "Epoch 515/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9607 - loss: 0.0931 - val_accuracy: 0.8298 - val_loss: 0.4450\n",
      "Epoch 516/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9731 - loss: 0.0864 - val_accuracy: 0.8085 - val_loss: 0.4300\n",
      "Epoch 517/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9684 - loss: 0.0743 - val_accuracy: 0.8298 - val_loss: 0.4423\n",
      "Epoch 518/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9690 - loss: 0.0904 - val_accuracy: 0.8298 - val_loss: 0.4396\n",
      "Epoch 519/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9848 - loss: 0.0752 - val_accuracy: 0.8085 - val_loss: 0.4364\n",
      "Epoch 520/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9781 - loss: 0.0734 - val_accuracy: 0.8085 - val_loss: 0.4331\n",
      "Epoch 521/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9874 - loss: 0.0757 - val_accuracy: 0.8298 - val_loss: 0.4493\n",
      "Epoch 522/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9779 - loss: 0.0815 - val_accuracy: 0.7872 - val_loss: 0.4347\n",
      "Epoch 523/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9750 - loss: 0.0821 - val_accuracy: 0.8298 - val_loss: 0.4527\n",
      "Epoch 524/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9767 - loss: 0.0828 - val_accuracy: 0.8298 - val_loss: 0.4442\n",
      "Epoch 525/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9726 - loss: 0.0815 - val_accuracy: 0.8298 - val_loss: 0.4471\n",
      "Epoch 526/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9796 - loss: 0.0763 - val_accuracy: 0.8085 - val_loss: 0.4390\n",
      "Epoch 527/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9790 - loss: 0.0776 - val_accuracy: 0.8298 - val_loss: 0.4487\n",
      "Epoch 528/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9688 - loss: 0.0824 - val_accuracy: 0.8298 - val_loss: 0.4483\n",
      "Epoch 529/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9690 - loss: 0.0775 - val_accuracy: 0.8085 - val_loss: 0.4406\n",
      "Epoch 530/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9803 - loss: 0.0765 - val_accuracy: 0.8085 - val_loss: 0.4428\n",
      "Epoch 531/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9777 - loss: 0.0821 - val_accuracy: 0.8298 - val_loss: 0.4527\n",
      "Epoch 532/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9887 - loss: 0.0740 - val_accuracy: 0.8298 - val_loss: 0.4473\n",
      "Epoch 533/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9684 - loss: 0.0873 - val_accuracy: 0.8085 - val_loss: 0.4408\n",
      "Epoch 534/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9642 - loss: 0.0888 - val_accuracy: 0.8298 - val_loss: 0.4627\n",
      "Epoch 535/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9837 - loss: 0.0800 - val_accuracy: 0.8085 - val_loss: 0.4489\n",
      "Epoch 536/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9654 - loss: 0.0774 - val_accuracy: 0.8298 - val_loss: 0.4589\n",
      "Epoch 537/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9815 - loss: 0.0788 - val_accuracy: 0.8085 - val_loss: 0.4483\n",
      "Epoch 538/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9710 - loss: 0.0747 - val_accuracy: 0.8298 - val_loss: 0.4519\n",
      "Epoch 539/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9889 - loss: 0.0679 - val_accuracy: 0.8085 - val_loss: 0.4503\n",
      "Epoch 540/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9874 - loss: 0.0669 - val_accuracy: 0.8085 - val_loss: 0.4485\n",
      "Epoch 541/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9815 - loss: 0.0656 - val_accuracy: 0.8085 - val_loss: 0.4465\n",
      "Epoch 542/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9780 - loss: 0.0717 - val_accuracy: 0.8085 - val_loss: 0.4507\n",
      "Epoch 543/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9806 - loss: 0.0754 - val_accuracy: 0.8085 - val_loss: 0.4495\n",
      "Epoch 544/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9822 - loss: 0.0755 - val_accuracy: 0.8085 - val_loss: 0.4560\n",
      "Epoch 545/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9843 - loss: 0.0737 - val_accuracy: 0.8085 - val_loss: 0.4576\n",
      "Epoch 546/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9685 - loss: 0.0866 - val_accuracy: 0.8085 - val_loss: 0.4540\n",
      "Epoch 547/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9843 - loss: 0.0687 - val_accuracy: 0.8085 - val_loss: 0.4545\n",
      "Epoch 548/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9755 - loss: 0.0726 - val_accuracy: 0.7872 - val_loss: 0.4504\n",
      "Epoch 549/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9828 - loss: 0.0727 - val_accuracy: 0.8298 - val_loss: 0.4665\n",
      "Epoch 550/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9841 - loss: 0.0771 - val_accuracy: 0.8085 - val_loss: 0.4569\n",
      "Epoch 551/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9699 - loss: 0.0668 - val_accuracy: 0.8085 - val_loss: 0.4540\n",
      "Epoch 552/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9664 - loss: 0.0855 - val_accuracy: 0.8298 - val_loss: 0.4714\n",
      "Epoch 553/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9750 - loss: 0.0775 - val_accuracy: 0.7872 - val_loss: 0.4534\n",
      "Epoch 554/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9627 - loss: 0.0867 - val_accuracy: 0.8298 - val_loss: 0.4674\n",
      "Epoch 555/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9867 - loss: 0.0648 - val_accuracy: 0.7872 - val_loss: 0.4565\n",
      "Epoch 556/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9772 - loss: 0.0691 - val_accuracy: 0.8085 - val_loss: 0.4608\n",
      "Epoch 557/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9816 - loss: 0.0656 - val_accuracy: 0.8085 - val_loss: 0.4633\n",
      "Epoch 558/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9894 - loss: 0.0651 - val_accuracy: 0.8085 - val_loss: 0.4591\n",
      "Epoch 559/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9783 - loss: 0.0694 - val_accuracy: 0.8085 - val_loss: 0.4593\n",
      "Epoch 560/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9865 - loss: 0.0638 - val_accuracy: 0.8085 - val_loss: 0.4629\n",
      "Epoch 561/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9827 - loss: 0.0644 - val_accuracy: 0.8085 - val_loss: 0.4667\n",
      "Epoch 562/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9854 - loss: 0.0623 - val_accuracy: 0.8085 - val_loss: 0.4622\n",
      "Epoch 563/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9934 - loss: 0.0558 - val_accuracy: 0.8085 - val_loss: 0.4623\n",
      "Epoch 564/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9642 - loss: 0.0828 - val_accuracy: 0.8298 - val_loss: 0.4697\n",
      "Epoch 565/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9852 - loss: 0.0661 - val_accuracy: 0.8085 - val_loss: 0.4634\n",
      "Epoch 566/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9781 - loss: 0.0766 - val_accuracy: 0.8085 - val_loss: 0.4618\n",
      "Epoch 567/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9744 - loss: 0.0658 - val_accuracy: 0.8085 - val_loss: 0.4654\n",
      "Epoch 568/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9709 - loss: 0.0756 - val_accuracy: 0.7872 - val_loss: 0.4682\n",
      "Epoch 569/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9818 - loss: 0.0680 - val_accuracy: 0.8085 - val_loss: 0.4777\n",
      "Epoch 570/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9801 - loss: 0.0644 - val_accuracy: 0.8085 - val_loss: 0.4690\n",
      "Epoch 571/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9837 - loss: 0.0666 - val_accuracy: 0.7872 - val_loss: 0.4669\n",
      "Epoch 572/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9813 - loss: 0.0611 - val_accuracy: 0.8085 - val_loss: 0.4695\n",
      "Epoch 573/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9925 - loss: 0.0529 - val_accuracy: 0.8085 - val_loss: 0.4682\n",
      "Epoch 574/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9852 - loss: 0.0673 - val_accuracy: 0.7872 - val_loss: 0.4695\n",
      "Epoch 575/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9863 - loss: 0.0655 - val_accuracy: 0.8085 - val_loss: 0.4795\n",
      "Epoch 576/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9730 - loss: 0.0791 - val_accuracy: 0.8085 - val_loss: 0.4749\n",
      "Epoch 577/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9863 - loss: 0.0593 - val_accuracy: 0.8085 - val_loss: 0.4673\n",
      "Epoch 578/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9910 - loss: 0.0632 - val_accuracy: 0.8085 - val_loss: 0.4780\n",
      "Epoch 579/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9839 - loss: 0.0689 - val_accuracy: 0.8085 - val_loss: 0.4834\n",
      "Epoch 580/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9896 - loss: 0.0585 - val_accuracy: 0.8085 - val_loss: 0.4744\n",
      "Epoch 581/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9693 - loss: 0.0739 - val_accuracy: 0.7872 - val_loss: 0.4708\n",
      "Epoch 582/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9832 - loss: 0.0705 - val_accuracy: 0.8085 - val_loss: 0.4827\n",
      "Epoch 583/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9642 - loss: 0.0775 - val_accuracy: 0.8085 - val_loss: 0.4796\n",
      "Epoch 584/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9889 - loss: 0.0533 - val_accuracy: 0.8085 - val_loss: 0.4768\n",
      "Epoch 585/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9834 - loss: 0.0637 - val_accuracy: 0.8085 - val_loss: 0.4726\n",
      "Epoch 586/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9744 - loss: 0.0741 - val_accuracy: 0.8085 - val_loss: 0.4769\n",
      "Epoch 587/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9772 - loss: 0.0636 - val_accuracy: 0.8085 - val_loss: 0.4824\n",
      "Epoch 588/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9826 - loss: 0.0706 - val_accuracy: 0.8085 - val_loss: 0.4782\n",
      "Epoch 589/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9880 - loss: 0.0549 - val_accuracy: 0.8085 - val_loss: 0.4801\n",
      "Epoch 590/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9761 - loss: 0.0741 - val_accuracy: 0.8085 - val_loss: 0.4775\n",
      "Epoch 591/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9774 - loss: 0.0776 - val_accuracy: 0.8085 - val_loss: 0.4819\n",
      "Epoch 592/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9812 - loss: 0.0646 - val_accuracy: 0.8085 - val_loss: 0.4821\n",
      "Epoch 593/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9969 - loss: 0.0693 - val_accuracy: 0.7872 - val_loss: 0.4822\n",
      "Epoch 594/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9705 - loss: 0.0769 - val_accuracy: 0.8085 - val_loss: 0.4884\n",
      "Epoch 595/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9867 - loss: 0.0650 - val_accuracy: 0.8085 - val_loss: 0.4741\n",
      "Epoch 596/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9839 - loss: 0.0628 - val_accuracy: 0.7872 - val_loss: 0.4791\n",
      "Epoch 597/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9782 - loss: 0.0856 - val_accuracy: 0.8085 - val_loss: 0.4960\n",
      "Epoch 598/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9750 - loss: 0.0741 - val_accuracy: 0.7872 - val_loss: 0.4884\n",
      "Epoch 599/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9705 - loss: 0.0692 - val_accuracy: 0.8085 - val_loss: 0.4840\n",
      "Epoch 600/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9735 - loss: 0.0619 - val_accuracy: 0.8085 - val_loss: 0.4837\n",
      "Epoch 601/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9715 - loss: 0.0709 - val_accuracy: 0.8085 - val_loss: 0.4873\n",
      "Epoch 602/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9865 - loss: 0.0592 - val_accuracy: 0.8085 - val_loss: 0.4847\n",
      "Epoch 603/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9823 - loss: 0.0670 - val_accuracy: 0.8085 - val_loss: 0.4955\n",
      "Epoch 604/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9759 - loss: 0.0783 - val_accuracy: 0.8085 - val_loss: 0.4860\n",
      "Epoch 605/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9899 - loss: 0.0523 - val_accuracy: 0.8085 - val_loss: 0.4905\n",
      "Epoch 606/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9642 - loss: 0.0658 - val_accuracy: 0.8085 - val_loss: 0.4872\n",
      "Epoch 607/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9852 - loss: 0.0633 - val_accuracy: 0.8085 - val_loss: 0.4869\n",
      "Epoch 608/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9900 - loss: 0.0511 - val_accuracy: 0.8085 - val_loss: 0.4914\n",
      "Epoch 609/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9852 - loss: 0.0549 - val_accuracy: 0.8085 - val_loss: 0.4906\n",
      "Epoch 610/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9890 - loss: 0.0597 - val_accuracy: 0.8085 - val_loss: 0.4931\n",
      "Epoch 611/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9960 - loss: 0.0501 - val_accuracy: 0.8085 - val_loss: 0.4913\n",
      "Epoch 612/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9741 - loss: 0.0696 - val_accuracy: 0.7872 - val_loss: 0.4881\n",
      "Epoch 613/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9759 - loss: 0.0622 - val_accuracy: 0.8085 - val_loss: 0.4983\n",
      "Epoch 614/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9874 - loss: 0.0576 - val_accuracy: 0.7872 - val_loss: 0.4963\n",
      "Epoch 615/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9934 - loss: 0.0511 - val_accuracy: 0.8085 - val_loss: 0.4988\n",
      "Epoch 616/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9713 - loss: 0.0664 - val_accuracy: 0.8085 - val_loss: 0.4935\n",
      "Epoch 617/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9759 - loss: 0.0737 - val_accuracy: 0.8085 - val_loss: 0.4897\n",
      "Epoch 618/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9919 - loss: 0.0543 - val_accuracy: 0.8085 - val_loss: 0.4956\n",
      "Epoch 619/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9709 - loss: 0.0672 - val_accuracy: 0.8085 - val_loss: 0.5047\n",
      "Epoch 620/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9913 - loss: 0.0473 - val_accuracy: 0.8085 - val_loss: 0.5009\n",
      "Epoch 621/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9903 - loss: 0.0578 - val_accuracy: 0.8085 - val_loss: 0.4987\n",
      "Epoch 622/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9903 - loss: 0.0546 - val_accuracy: 0.8085 - val_loss: 0.5028\n",
      "Epoch 623/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9914 - loss: 0.0559 - val_accuracy: 0.7872 - val_loss: 0.4993\n",
      "Epoch 624/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9774 - loss: 0.0733 - val_accuracy: 0.8085 - val_loss: 0.5014\n",
      "Epoch 625/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9830 - loss: 0.0549 - val_accuracy: 0.8085 - val_loss: 0.5034\n",
      "Epoch 626/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9852 - loss: 0.0521 - val_accuracy: 0.8085 - val_loss: 0.5008\n",
      "Epoch 627/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9705 - loss: 0.0625 - val_accuracy: 0.8085 - val_loss: 0.5030\n",
      "Epoch 628/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9818 - loss: 0.0570 - val_accuracy: 0.8085 - val_loss: 0.5056\n",
      "Epoch 629/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9697 - loss: 0.0650 - val_accuracy: 0.8085 - val_loss: 0.5064\n",
      "Epoch 630/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9797 - loss: 0.0601 - val_accuracy: 0.8085 - val_loss: 0.5053\n",
      "Epoch 631/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9781 - loss: 0.0605 - val_accuracy: 0.8085 - val_loss: 0.5064\n",
      "Epoch 632/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9877 - loss: 0.0605 - val_accuracy: 0.8085 - val_loss: 0.5057\n",
      "Epoch 633/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9903 - loss: 0.0618 - val_accuracy: 0.8085 - val_loss: 0.5112\n",
      "Epoch 634/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9925 - loss: 0.0493 - val_accuracy: 0.8085 - val_loss: 0.5097\n",
      "Epoch 635/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9807 - loss: 0.0597 - val_accuracy: 0.7872 - val_loss: 0.5091\n",
      "Epoch 636/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9843 - loss: 0.0529 - val_accuracy: 0.8085 - val_loss: 0.5232\n",
      "Epoch 637/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9710 - loss: 0.0778 - val_accuracy: 0.7660 - val_loss: 0.5264\n",
      "Epoch 638/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9693 - loss: 0.0758 - val_accuracy: 0.8298 - val_loss: 0.5330\n",
      "Epoch 639/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9867 - loss: 0.0602 - val_accuracy: 0.7872 - val_loss: 0.5031\n",
      "Epoch 640/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9940 - loss: 0.0575 - val_accuracy: 0.8085 - val_loss: 0.5102\n",
      "Epoch 641/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9960 - loss: 0.0548 - val_accuracy: 0.8085 - val_loss: 0.5096\n",
      "Epoch 642/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9940 - loss: 0.0525 - val_accuracy: 0.7872 - val_loss: 0.5119\n",
      "Epoch 643/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9810 - loss: 0.0637 - val_accuracy: 0.8085 - val_loss: 0.5171\n",
      "Epoch 644/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9847 - loss: 0.0578 - val_accuracy: 0.8085 - val_loss: 0.5128\n",
      "Epoch 645/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9823 - loss: 0.0561 - val_accuracy: 0.8085 - val_loss: 0.5136\n",
      "Epoch 646/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9914 - loss: 0.0591 - val_accuracy: 0.8085 - val_loss: 0.5127\n",
      "Epoch 647/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9812 - loss: 0.0558 - val_accuracy: 0.8085 - val_loss: 0.5137\n",
      "Epoch 648/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9789 - loss: 0.0539 - val_accuracy: 0.8085 - val_loss: 0.5151\n",
      "Epoch 649/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9964 - loss: 0.0653 - val_accuracy: 0.7872 - val_loss: 0.5202\n",
      "Epoch 650/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9832 - loss: 0.0598 - val_accuracy: 0.8298 - val_loss: 0.5218\n",
      "Epoch 651/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9782 - loss: 0.0611 - val_accuracy: 0.7872 - val_loss: 0.5190\n",
      "Epoch 652/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9861 - loss: 0.0458 - val_accuracy: 0.8085 - val_loss: 0.5176\n",
      "Epoch 653/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9927 - loss: 0.0565 - val_accuracy: 0.7872 - val_loss: 0.5238\n",
      "Epoch 654/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9852 - loss: 0.0461 - val_accuracy: 0.8085 - val_loss: 0.5252\n",
      "Epoch 655/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9964 - loss: 0.0619 - val_accuracy: 0.7872 - val_loss: 0.5238\n",
      "Epoch 656/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9810 - loss: 0.0603 - val_accuracy: 0.8085 - val_loss: 0.5257\n",
      "Epoch 657/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9856 - loss: 0.0492 - val_accuracy: 0.8085 - val_loss: 0.5268\n",
      "Epoch 658/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9934 - loss: 0.0474 - val_accuracy: 0.8085 - val_loss: 0.5246\n",
      "Epoch 659/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9960 - loss: 0.0388 - val_accuracy: 0.7872 - val_loss: 0.5250\n",
      "Epoch 660/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9867 - loss: 0.0515 - val_accuracy: 0.8085 - val_loss: 0.5289\n",
      "Epoch 661/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9858 - loss: 0.0572 - val_accuracy: 0.8085 - val_loss: 0.5262\n",
      "Epoch 662/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9940 - loss: 0.0570 - val_accuracy: 0.7872 - val_loss: 0.5294\n",
      "Epoch 663/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9867 - loss: 0.0577 - val_accuracy: 0.8085 - val_loss: 0.5377\n",
      "Epoch 664/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9887 - loss: 0.0540 - val_accuracy: 0.7872 - val_loss: 0.5347\n",
      "Epoch 665/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9715 - loss: 0.0686 - val_accuracy: 0.8085 - val_loss: 0.5293\n",
      "Epoch 666/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9925 - loss: 0.0442 - val_accuracy: 0.7872 - val_loss: 0.5284\n",
      "Epoch 667/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9839 - loss: 0.0483 - val_accuracy: 0.8085 - val_loss: 0.5303\n",
      "Epoch 668/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9877 - loss: 0.0526 - val_accuracy: 0.8085 - val_loss: 0.5330\n",
      "Epoch 669/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9949 - loss: 0.0492 - val_accuracy: 0.8085 - val_loss: 0.5319\n",
      "Epoch 670/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9744 - loss: 0.0612 - val_accuracy: 0.7872 - val_loss: 0.5351\n",
      "Epoch 671/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9976 - loss: 0.0439 - val_accuracy: 0.8085 - val_loss: 0.5406\n",
      "Epoch 672/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9861 - loss: 0.0496 - val_accuracy: 0.7872 - val_loss: 0.5353\n",
      "Epoch 673/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9903 - loss: 0.0513 - val_accuracy: 0.8298 - val_loss: 0.5330\n",
      "Epoch 674/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9985 - loss: 0.0445 - val_accuracy: 0.7872 - val_loss: 0.5339\n",
      "Epoch 675/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9877 - loss: 0.0533 - val_accuracy: 0.8085 - val_loss: 0.5370\n",
      "Epoch 676/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9925 - loss: 0.0522 - val_accuracy: 0.8085 - val_loss: 0.5364\n",
      "Epoch 677/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9964 - loss: 0.0481 - val_accuracy: 0.7872 - val_loss: 0.5376\n",
      "Epoch 678/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9945 - loss: 0.0397 - val_accuracy: 0.7872 - val_loss: 0.5418\n",
      "Epoch 679/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9893 - loss: 0.0534 - val_accuracy: 0.8085 - val_loss: 0.5424\n",
      "Epoch 680/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9867 - loss: 0.0480 - val_accuracy: 0.8085 - val_loss: 0.5351\n",
      "Epoch 681/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9950 - loss: 0.0480 - val_accuracy: 0.7872 - val_loss: 0.5410\n",
      "Epoch 682/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9892 - loss: 0.0559 - val_accuracy: 0.8298 - val_loss: 0.5468\n",
      "Epoch 683/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9950 - loss: 0.0538 - val_accuracy: 0.7872 - val_loss: 0.5463\n",
      "Epoch 684/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9887 - loss: 0.0516 - val_accuracy: 0.8298 - val_loss: 0.5515\n",
      "Epoch 685/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9903 - loss: 0.0463 - val_accuracy: 0.8085 - val_loss: 0.5476\n",
      "Epoch 686/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9892 - loss: 0.0431 - val_accuracy: 0.7872 - val_loss: 0.5443\n",
      "Epoch 687/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9903 - loss: 0.0437 - val_accuracy: 0.8085 - val_loss: 0.5473\n",
      "Epoch 688/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9927 - loss: 0.0494 - val_accuracy: 0.8085 - val_loss: 0.5451\n",
      "Epoch 689/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9934 - loss: 0.0418 - val_accuracy: 0.7872 - val_loss: 0.5472\n",
      "Epoch 690/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9892 - loss: 0.0570 - val_accuracy: 0.8085 - val_loss: 0.5481\n",
      "Epoch 691/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0489 - val_accuracy: 0.7872 - val_loss: 0.5484\n",
      "Epoch 692/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9741 - loss: 0.0497 - val_accuracy: 0.8085 - val_loss: 0.5484\n",
      "Epoch 693/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0515 - val_accuracy: 0.7872 - val_loss: 0.5503\n",
      "Epoch 694/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9925 - loss: 0.0387 - val_accuracy: 0.8085 - val_loss: 0.5523\n",
      "Epoch 695/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9950 - loss: 0.0526 - val_accuracy: 0.8085 - val_loss: 0.5536\n",
      "Epoch 696/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0439 - val_accuracy: 0.7872 - val_loss: 0.5483\n",
      "Epoch 697/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9905 - loss: 0.0515 - val_accuracy: 0.8085 - val_loss: 0.5542\n",
      "Epoch 698/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9877 - loss: 0.0533 - val_accuracy: 0.8085 - val_loss: 0.5585\n",
      "Epoch 699/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9903 - loss: 0.0419 - val_accuracy: 0.7872 - val_loss: 0.5537\n",
      "Epoch 700/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9964 - loss: 0.0420 - val_accuracy: 0.8085 - val_loss: 0.5522\n",
      "Epoch 701/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0452 - val_accuracy: 0.7872 - val_loss: 0.5521\n",
      "Epoch 702/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9858 - loss: 0.0420 - val_accuracy: 0.7872 - val_loss: 0.5574\n",
      "Epoch 703/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9804 - loss: 0.0524 - val_accuracy: 0.8085 - val_loss: 0.5594\n",
      "Epoch 704/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9964 - loss: 0.0490 - val_accuracy: 0.7872 - val_loss: 0.5601\n",
      "Epoch 705/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9817 - loss: 0.0475 - val_accuracy: 0.8085 - val_loss: 0.5575\n",
      "Epoch 706/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9969 - loss: 0.0352 - val_accuracy: 0.8085 - val_loss: 0.5566\n",
      "Epoch 707/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9903 - loss: 0.0412 - val_accuracy: 0.7660 - val_loss: 0.5627\n",
      "Epoch 708/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9830 - loss: 0.0496 - val_accuracy: 0.8085 - val_loss: 0.5599\n",
      "Epoch 709/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9929 - loss: 0.0505 - val_accuracy: 0.8085 - val_loss: 0.5596\n",
      "Epoch 710/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9898 - loss: 0.0514 - val_accuracy: 0.7872 - val_loss: 0.5626\n",
      "Epoch 711/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9832 - loss: 0.0501 - val_accuracy: 0.8085 - val_loss: 0.5679\n",
      "Epoch 712/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9823 - loss: 0.0630 - val_accuracy: 0.7660 - val_loss: 0.5692\n",
      "Epoch 713/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9807 - loss: 0.0479 - val_accuracy: 0.8298 - val_loss: 0.5663\n",
      "Epoch 714/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9949 - loss: 0.0509 - val_accuracy: 0.8085 - val_loss: 0.5581\n",
      "Epoch 715/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9865 - loss: 0.0514 - val_accuracy: 0.7660 - val_loss: 0.5673\n",
      "Epoch 716/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9899 - loss: 0.0449 - val_accuracy: 0.8085 - val_loss: 0.5833\n",
      "Epoch 717/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9950 - loss: 0.0520 - val_accuracy: 0.7872 - val_loss: 0.5662\n",
      "Epoch 718/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9864 - loss: 0.0403 - val_accuracy: 0.8085 - val_loss: 0.5626\n",
      "Epoch 719/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9950 - loss: 0.0467 - val_accuracy: 0.8085 - val_loss: 0.5612\n",
      "Epoch 720/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0480 - val_accuracy: 0.7872 - val_loss: 0.5622\n",
      "Epoch 721/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9945 - loss: 0.0396 - val_accuracy: 0.7872 - val_loss: 0.5679\n",
      "Epoch 722/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9960 - loss: 0.0415 - val_accuracy: 0.8298 - val_loss: 0.5661\n",
      "Epoch 723/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9934 - loss: 0.0385 - val_accuracy: 0.7660 - val_loss: 0.5771\n",
      "Epoch 724/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9810 - loss: 0.0507 - val_accuracy: 0.8298 - val_loss: 0.5701\n",
      "Epoch 725/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9867 - loss: 0.0489 - val_accuracy: 0.7872 - val_loss: 0.5656\n",
      "Epoch 726/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9858 - loss: 0.0478 - val_accuracy: 0.8085 - val_loss: 0.5633\n",
      "Epoch 727/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9985 - loss: 0.0374 - val_accuracy: 0.8085 - val_loss: 0.5646\n",
      "Epoch 728/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9916 - loss: 0.0423 - val_accuracy: 0.7872 - val_loss: 0.5729\n",
      "Epoch 729/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9765 - loss: 0.0508 - val_accuracy: 0.8085 - val_loss: 0.5689\n",
      "Epoch 730/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9927 - loss: 0.0445 - val_accuracy: 0.7872 - val_loss: 0.5704\n",
      "Epoch 731/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9858 - loss: 0.0403 - val_accuracy: 0.7872 - val_loss: 0.5695\n",
      "Epoch 732/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9964 - loss: 0.0445 - val_accuracy: 0.7872 - val_loss: 0.5711\n",
      "Epoch 733/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9985 - loss: 0.0362 - val_accuracy: 0.7872 - val_loss: 0.5711\n",
      "Epoch 734/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0452 - val_accuracy: 0.7872 - val_loss: 0.5728\n",
      "Epoch 735/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9969 - loss: 0.0391 - val_accuracy: 0.7872 - val_loss: 0.5818\n",
      "Epoch 736/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9950 - loss: 0.0344 - val_accuracy: 0.8085 - val_loss: 0.5775\n",
      "Epoch 737/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0329 - val_accuracy: 0.7872 - val_loss: 0.5773\n",
      "Epoch 738/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9985 - loss: 0.0356 - val_accuracy: 0.7872 - val_loss: 0.5753\n",
      "Epoch 739/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0389 - val_accuracy: 0.7872 - val_loss: 0.5766\n",
      "Epoch 740/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9852 - loss: 0.0436 - val_accuracy: 0.7872 - val_loss: 0.5840\n",
      "Epoch 741/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9858 - loss: 0.0536 - val_accuracy: 0.8298 - val_loss: 0.5858\n",
      "Epoch 742/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9985 - loss: 0.0369 - val_accuracy: 0.7660 - val_loss: 0.5891\n",
      "Epoch 743/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9730 - loss: 0.0530 - val_accuracy: 0.8085 - val_loss: 0.5786\n",
      "Epoch 744/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9976 - loss: 0.0386 - val_accuracy: 0.8085 - val_loss: 0.5787\n",
      "Epoch 745/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0414 - val_accuracy: 0.7872 - val_loss: 0.5841\n",
      "Epoch 746/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9854 - loss: 0.0404 - val_accuracy: 0.7872 - val_loss: 0.5834\n",
      "Epoch 747/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9903 - loss: 0.0420 - val_accuracy: 0.8085 - val_loss: 0.5818\n",
      "Epoch 748/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9945 - loss: 0.0389 - val_accuracy: 0.7660 - val_loss: 0.5929\n",
      "Epoch 749/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0392 - val_accuracy: 0.8298 - val_loss: 0.5926\n",
      "Epoch 750/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9950 - loss: 0.0388 - val_accuracy: 0.7660 - val_loss: 0.5888\n",
      "Epoch 751/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9912 - loss: 0.0432 - val_accuracy: 0.7872 - val_loss: 0.5823\n",
      "Epoch 752/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9927 - loss: 0.0537 - val_accuracy: 0.8085 - val_loss: 0.5823\n",
      "Epoch 753/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0413 - val_accuracy: 0.7872 - val_loss: 0.5833\n",
      "Epoch 754/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9950 - loss: 0.0385 - val_accuracy: 0.8085 - val_loss: 0.5845\n",
      "Epoch 755/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0364 - val_accuracy: 0.7872 - val_loss: 0.5901\n",
      "Epoch 756/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9875 - loss: 0.0342 - val_accuracy: 0.8085 - val_loss: 0.5882\n",
      "Epoch 757/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0412 - val_accuracy: 0.8085 - val_loss: 0.5900\n",
      "Epoch 758/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9950 - loss: 0.0339 - val_accuracy: 0.7872 - val_loss: 0.5906\n",
      "Epoch 759/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9950 - loss: 0.0483 - val_accuracy: 0.8085 - val_loss: 0.5912\n",
      "Epoch 760/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0361 - val_accuracy: 0.8085 - val_loss: 0.5899\n",
      "Epoch 761/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9905 - loss: 0.0377 - val_accuracy: 0.7872 - val_loss: 0.5913\n",
      "Epoch 762/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0342 - val_accuracy: 0.8085 - val_loss: 0.5914\n",
      "Epoch 763/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0350 - val_accuracy: 0.7872 - val_loss: 0.5960\n",
      "Epoch 764/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9855 - loss: 0.0435 - val_accuracy: 0.7872 - val_loss: 0.5935\n",
      "Epoch 765/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9985 - loss: 0.0350 - val_accuracy: 0.7872 - val_loss: 0.5978\n",
      "Epoch 766/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9927 - loss: 0.0336 - val_accuracy: 0.7872 - val_loss: 0.5953\n",
      "Epoch 767/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9985 - loss: 0.0306 - val_accuracy: 0.7872 - val_loss: 0.5992\n",
      "Epoch 768/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9927 - loss: 0.0370 - val_accuracy: 0.7872 - val_loss: 0.5984\n",
      "Epoch 769/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0331 - val_accuracy: 0.7872 - val_loss: 0.6018\n",
      "Epoch 770/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9847 - loss: 0.0391 - val_accuracy: 0.7872 - val_loss: 0.6003\n",
      "Epoch 771/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0386 - val_accuracy: 0.7872 - val_loss: 0.5981\n",
      "Epoch 772/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9960 - loss: 0.0313 - val_accuracy: 0.7872 - val_loss: 0.6009\n",
      "Epoch 773/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9858 - loss: 0.0372 - val_accuracy: 0.8085 - val_loss: 0.5970\n",
      "Epoch 774/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0346 - val_accuracy: 0.7660 - val_loss: 0.6114\n",
      "Epoch 775/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9847 - loss: 0.0419 - val_accuracy: 0.7872 - val_loss: 0.6028\n",
      "Epoch 776/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0385 - val_accuracy: 0.7872 - val_loss: 0.6075\n",
      "Epoch 777/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9969 - loss: 0.0392 - val_accuracy: 0.7872 - val_loss: 0.6050\n",
      "Epoch 778/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9927 - loss: 0.0387 - val_accuracy: 0.8085 - val_loss: 0.5987\n",
      "Epoch 779/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0342 - val_accuracy: 0.7872 - val_loss: 0.6015\n",
      "Epoch 780/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9950 - loss: 0.0433 - val_accuracy: 0.7872 - val_loss: 0.6052\n",
      "Epoch 781/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0311 - val_accuracy: 0.7872 - val_loss: 0.6057\n",
      "Epoch 782/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9925 - loss: 0.0382 - val_accuracy: 0.7660 - val_loss: 0.6196\n",
      "Epoch 783/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9883 - loss: 0.0385 - val_accuracy: 0.8085 - val_loss: 0.6106\n",
      "Epoch 784/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0375 - val_accuracy: 0.7872 - val_loss: 0.6117\n",
      "Epoch 785/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9903 - loss: 0.0336 - val_accuracy: 0.7872 - val_loss: 0.6105\n",
      "Epoch 786/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9964 - loss: 0.0401 - val_accuracy: 0.7872 - val_loss: 0.6096\n",
      "Epoch 787/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0321 - val_accuracy: 0.8085 - val_loss: 0.6083\n",
      "Epoch 788/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9874 - loss: 0.0405 - val_accuracy: 0.7872 - val_loss: 0.6160\n",
      "Epoch 789/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0337 - val_accuracy: 0.8085 - val_loss: 0.6125\n",
      "Epoch 790/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0430 - val_accuracy: 0.7872 - val_loss: 0.6151\n",
      "Epoch 791/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9892 - loss: 0.0427 - val_accuracy: 0.7872 - val_loss: 0.6138\n",
      "Epoch 792/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0338 - val_accuracy: 0.7872 - val_loss: 0.6141\n",
      "Epoch 793/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0366 - val_accuracy: 0.7872 - val_loss: 0.6168\n",
      "Epoch 794/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0431 - val_accuracy: 0.7872 - val_loss: 0.6178\n",
      "Epoch 795/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9927 - loss: 0.0318 - val_accuracy: 0.7872 - val_loss: 0.6162\n",
      "Epoch 796/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0317 - val_accuracy: 0.7872 - val_loss: 0.6159\n",
      "Epoch 797/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9950 - loss: 0.0399 - val_accuracy: 0.7872 - val_loss: 0.6228\n",
      "Epoch 798/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9927 - loss: 0.0328 - val_accuracy: 0.7872 - val_loss: 0.6182\n",
      "Epoch 799/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9940 - loss: 0.0351 - val_accuracy: 0.7872 - val_loss: 0.6246\n",
      "Epoch 800/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9976 - loss: 0.0318 - val_accuracy: 0.7872 - val_loss: 0.6230\n",
      "Epoch 801/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0343 - val_accuracy: 0.7872 - val_loss: 0.6180\n",
      "Epoch 802/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9950 - loss: 0.0395 - val_accuracy: 0.7660 - val_loss: 0.6331\n",
      "Epoch 803/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9883 - loss: 0.0410 - val_accuracy: 0.7872 - val_loss: 0.6240\n",
      "Epoch 804/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9940 - loss: 0.0389 - val_accuracy: 0.7872 - val_loss: 0.6316\n",
      "Epoch 805/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0307 - val_accuracy: 0.7872 - val_loss: 0.6229\n",
      "Epoch 806/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9964 - loss: 0.0322 - val_accuracy: 0.7872 - val_loss: 0.6210\n",
      "Epoch 807/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9949 - loss: 0.0390 - val_accuracy: 0.7872 - val_loss: 0.6324\n",
      "Epoch 808/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0330 - val_accuracy: 0.8298 - val_loss: 0.6298\n",
      "Epoch 809/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9912 - loss: 0.0421 - val_accuracy: 0.7660 - val_loss: 0.6396\n",
      "Epoch 810/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9892 - loss: 0.0351 - val_accuracy: 0.7872 - val_loss: 0.6275\n",
      "Epoch 811/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0277 - val_accuracy: 0.7872 - val_loss: 0.6306\n",
      "Epoch 812/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0392 - val_accuracy: 0.7872 - val_loss: 0.6355\n",
      "Epoch 813/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9985 - loss: 0.0292 - val_accuracy: 0.7872 - val_loss: 0.6351\n",
      "Epoch 814/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0399 - val_accuracy: 0.7872 - val_loss: 0.6300\n",
      "Epoch 815/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0313 - val_accuracy: 0.7872 - val_loss: 0.6322\n",
      "Epoch 816/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0275 - val_accuracy: 0.7872 - val_loss: 0.6317\n",
      "Epoch 817/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0311 - val_accuracy: 0.7872 - val_loss: 0.6368\n",
      "Epoch 818/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9883 - loss: 0.0355 - val_accuracy: 0.7872 - val_loss: 0.6354\n",
      "Epoch 819/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9925 - loss: 0.0361 - val_accuracy: 0.7872 - val_loss: 0.6395\n",
      "Epoch 820/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0265 - val_accuracy: 0.7872 - val_loss: 0.6363\n",
      "Epoch 821/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9950 - loss: 0.0362 - val_accuracy: 0.7872 - val_loss: 0.6437\n",
      "Epoch 822/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9765 - loss: 0.0363 - val_accuracy: 0.7872 - val_loss: 0.6366\n",
      "Epoch 823/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0273 - val_accuracy: 0.7872 - val_loss: 0.6403\n",
      "Epoch 824/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0276 - val_accuracy: 0.7872 - val_loss: 0.6394\n",
      "Epoch 825/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9925 - loss: 0.0309 - val_accuracy: 0.7872 - val_loss: 0.6442\n",
      "Epoch 826/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0312 - val_accuracy: 0.7872 - val_loss: 0.6420\n",
      "Epoch 827/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0309 - val_accuracy: 0.7872 - val_loss: 0.6445\n",
      "Epoch 828/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9877 - loss: 0.0357 - val_accuracy: 0.7872 - val_loss: 0.6365\n",
      "Epoch 829/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0330 - val_accuracy: 0.7872 - val_loss: 0.6410\n",
      "Epoch 830/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9976 - loss: 0.0335 - val_accuracy: 0.7872 - val_loss: 0.6510\n",
      "Epoch 831/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9927 - loss: 0.0285 - val_accuracy: 0.7872 - val_loss: 0.6418\n",
      "Epoch 832/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0298 - val_accuracy: 0.7872 - val_loss: 0.6461\n",
      "Epoch 833/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9883 - loss: 0.0279 - val_accuracy: 0.7872 - val_loss: 0.6399\n",
      "Epoch 834/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0278 - val_accuracy: 0.7872 - val_loss: 0.6462\n",
      "Epoch 835/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0302 - val_accuracy: 0.7872 - val_loss: 0.6500\n",
      "Epoch 836/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0227 - val_accuracy: 0.7872 - val_loss: 0.6469\n",
      "Epoch 837/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0298 - val_accuracy: 0.7872 - val_loss: 0.6489\n",
      "Epoch 838/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0283 - val_accuracy: 0.7872 - val_loss: 0.6461\n",
      "Epoch 839/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0353 - val_accuracy: 0.7872 - val_loss: 0.6509\n",
      "Epoch 840/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0249 - val_accuracy: 0.7872 - val_loss: 0.6489\n",
      "Epoch 841/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0318 - val_accuracy: 0.7872 - val_loss: 0.6506\n",
      "Epoch 842/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0335 - val_accuracy: 0.7872 - val_loss: 0.6499\n",
      "Epoch 843/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0309 - val_accuracy: 0.7872 - val_loss: 0.6487\n",
      "Epoch 844/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0339 - val_accuracy: 0.7872 - val_loss: 0.6505\n",
      "Epoch 845/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0285 - val_accuracy: 0.7872 - val_loss: 0.6511\n",
      "Epoch 846/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0295 - val_accuracy: 0.7872 - val_loss: 0.6536\n",
      "Epoch 847/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0328 - val_accuracy: 0.7872 - val_loss: 0.6520\n",
      "Epoch 848/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0184 - val_accuracy: 0.7872 - val_loss: 0.6555\n",
      "Epoch 849/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9976 - loss: 0.0246 - val_accuracy: 0.7872 - val_loss: 0.6569\n",
      "Epoch 850/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0249 - val_accuracy: 0.7872 - val_loss: 0.6592\n",
      "Epoch 851/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9950 - loss: 0.0259 - val_accuracy: 0.7872 - val_loss: 0.6528\n",
      "Epoch 852/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9960 - loss: 0.0325 - val_accuracy: 0.7872 - val_loss: 0.6667\n",
      "Epoch 853/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0248 - val_accuracy: 0.7872 - val_loss: 0.6570\n",
      "Epoch 854/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9985 - loss: 0.0268 - val_accuracy: 0.7872 - val_loss: 0.6638\n",
      "Epoch 855/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9883 - loss: 0.0282 - val_accuracy: 0.7872 - val_loss: 0.6573\n",
      "Epoch 856/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9976 - loss: 0.0288 - val_accuracy: 0.7872 - val_loss: 0.6623\n",
      "Epoch 857/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0230 - val_accuracy: 0.7872 - val_loss: 0.6599\n",
      "Epoch 858/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9985 - loss: 0.0230 - val_accuracy: 0.7872 - val_loss: 0.6664\n",
      "Epoch 859/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0273 - val_accuracy: 0.7872 - val_loss: 0.6612\n",
      "Epoch 860/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0290 - val_accuracy: 0.7872 - val_loss: 0.6644\n",
      "Epoch 861/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0236 - val_accuracy: 0.7872 - val_loss: 0.6697\n",
      "Epoch 862/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0241 - val_accuracy: 0.7872 - val_loss: 0.6638\n",
      "Epoch 863/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0319 - val_accuracy: 0.7872 - val_loss: 0.6675\n",
      "Epoch 864/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0243 - val_accuracy: 0.7872 - val_loss: 0.6642\n",
      "Epoch 865/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0291 - val_accuracy: 0.7872 - val_loss: 0.6676\n",
      "Epoch 866/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0248 - val_accuracy: 0.7872 - val_loss: 0.6710\n",
      "Epoch 867/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0355 - val_accuracy: 0.7872 - val_loss: 0.6684\n",
      "Epoch 868/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0324 - val_accuracy: 0.7872 - val_loss: 0.6748\n",
      "Epoch 869/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0306 - val_accuracy: 0.7872 - val_loss: 0.6729\n",
      "Epoch 870/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0234 - val_accuracy: 0.7872 - val_loss: 0.6737\n",
      "Epoch 871/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9950 - loss: 0.0299 - val_accuracy: 0.7872 - val_loss: 0.6740\n",
      "Epoch 872/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0343 - val_accuracy: 0.7872 - val_loss: 0.6708\n",
      "Epoch 873/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0286 - val_accuracy: 0.7872 - val_loss: 0.6761\n",
      "Epoch 874/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9927 - loss: 0.0318 - val_accuracy: 0.7872 - val_loss: 0.6713\n",
      "Epoch 875/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0222 - val_accuracy: 0.7872 - val_loss: 0.6741\n",
      "Epoch 876/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0276 - val_accuracy: 0.7872 - val_loss: 0.6775\n",
      "Epoch 877/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9951 - loss: 0.0230 - val_accuracy: 0.7872 - val_loss: 0.6826\n",
      "Epoch 878/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0273 - val_accuracy: 0.7872 - val_loss: 0.6731\n",
      "Epoch 879/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0242 - val_accuracy: 0.7872 - val_loss: 0.6795\n",
      "Epoch 880/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0236 - val_accuracy: 0.7872 - val_loss: 0.6768\n",
      "Epoch 881/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0267 - val_accuracy: 0.7872 - val_loss: 0.6804\n",
      "Epoch 882/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0276 - val_accuracy: 0.7872 - val_loss: 0.6785\n",
      "Epoch 883/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0246 - val_accuracy: 0.7872 - val_loss: 0.6812\n",
      "Epoch 884/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9969 - loss: 0.0235 - val_accuracy: 0.7872 - val_loss: 0.6829\n",
      "Epoch 885/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0264 - val_accuracy: 0.7872 - val_loss: 0.6751\n",
      "Epoch 886/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0298 - val_accuracy: 0.7660 - val_loss: 0.6926\n",
      "Epoch 887/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0244 - val_accuracy: 0.7872 - val_loss: 0.6799\n",
      "Epoch 888/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0333 - val_accuracy: 0.7872 - val_loss: 0.6874\n",
      "Epoch 889/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0287 - val_accuracy: 0.7872 - val_loss: 0.6861\n",
      "Epoch 890/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0277 - val_accuracy: 0.7872 - val_loss: 0.6831\n",
      "Epoch 891/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0235 - val_accuracy: 0.7872 - val_loss: 0.6870\n",
      "Epoch 892/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9892 - loss: 0.0295 - val_accuracy: 0.7872 - val_loss: 0.6927\n",
      "Epoch 893/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0274 - val_accuracy: 0.8085 - val_loss: 0.6849\n",
      "Epoch 894/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9976 - loss: 0.0292 - val_accuracy: 0.7872 - val_loss: 0.6963\n",
      "Epoch 895/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9883 - loss: 0.0250 - val_accuracy: 0.7872 - val_loss: 0.6788\n",
      "Epoch 896/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9964 - loss: 0.0285 - val_accuracy: 0.7872 - val_loss: 0.6976\n",
      "Epoch 897/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0220 - val_accuracy: 0.7872 - val_loss: 0.6933\n",
      "Epoch 898/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0280 - val_accuracy: 0.7872 - val_loss: 0.6964\n",
      "Epoch 899/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0282 - val_accuracy: 0.7872 - val_loss: 0.6859\n",
      "Epoch 900/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9985 - loss: 0.0268 - val_accuracy: 0.7872 - val_loss: 0.6993\n",
      "Epoch 901/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0283 - val_accuracy: 0.8085 - val_loss: 0.6914\n",
      "Epoch 902/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0246 - val_accuracy: 0.7872 - val_loss: 0.7013\n",
      "Epoch 903/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9950 - loss: 0.0318 - val_accuracy: 0.7872 - val_loss: 0.6956\n",
      "Epoch 904/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0292 - val_accuracy: 0.7872 - val_loss: 0.6935\n",
      "Epoch 905/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0300 - val_accuracy: 0.7872 - val_loss: 0.6971\n",
      "Epoch 906/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0254 - val_accuracy: 0.7872 - val_loss: 0.6906\n",
      "Epoch 907/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9985 - loss: 0.0245 - val_accuracy: 0.7872 - val_loss: 0.7047\n",
      "Epoch 908/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0206 - val_accuracy: 0.7872 - val_loss: 0.6987\n",
      "Epoch 909/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0267 - val_accuracy: 0.7872 - val_loss: 0.7065\n",
      "Epoch 910/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0201 - val_accuracy: 0.7872 - val_loss: 0.7011\n",
      "Epoch 911/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0191 - val_accuracy: 0.7872 - val_loss: 0.6968\n",
      "Epoch 912/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9985 - loss: 0.0229 - val_accuracy: 0.7872 - val_loss: 0.7107\n",
      "Epoch 913/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0198 - val_accuracy: 0.7872 - val_loss: 0.7025\n",
      "Epoch 914/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0238 - val_accuracy: 0.7872 - val_loss: 0.7124\n",
      "Epoch 915/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9927 - loss: 0.0233 - val_accuracy: 0.7872 - val_loss: 0.7038\n",
      "Epoch 916/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0190 - val_accuracy: 0.7872 - val_loss: 0.7048\n",
      "Epoch 917/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9940 - loss: 0.0245 - val_accuracy: 0.7872 - val_loss: 0.7154\n",
      "Epoch 918/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0231 - val_accuracy: 0.7872 - val_loss: 0.7057\n",
      "Epoch 919/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0199 - val_accuracy: 0.7872 - val_loss: 0.7088\n",
      "Epoch 920/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0221 - val_accuracy: 0.7872 - val_loss: 0.7072\n",
      "Epoch 921/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0213 - val_accuracy: 0.7872 - val_loss: 0.7045\n",
      "Epoch 922/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0251 - val_accuracy: 0.7872 - val_loss: 0.7121\n",
      "Epoch 923/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0267 - val_accuracy: 0.7872 - val_loss: 0.7085\n",
      "Epoch 924/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9976 - loss: 0.0274 - val_accuracy: 0.7872 - val_loss: 0.7180\n",
      "Epoch 925/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0262 - val_accuracy: 0.7872 - val_loss: 0.7072\n",
      "Epoch 926/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0291 - val_accuracy: 0.7872 - val_loss: 0.7127\n",
      "Epoch 927/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0214 - val_accuracy: 0.7872 - val_loss: 0.7091\n",
      "Epoch 928/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0204 - val_accuracy: 0.7872 - val_loss: 0.7112\n",
      "Epoch 929/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0272 - val_accuracy: 0.7872 - val_loss: 0.7154\n",
      "Epoch 930/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0228 - val_accuracy: 0.7872 - val_loss: 0.7173\n",
      "Epoch 931/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0216 - val_accuracy: 0.7872 - val_loss: 0.7173\n",
      "Epoch 932/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0245 - val_accuracy: 0.7872 - val_loss: 0.7136\n",
      "Epoch 933/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0198 - val_accuracy: 0.7872 - val_loss: 0.7172\n",
      "Epoch 934/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0209 - val_accuracy: 0.7872 - val_loss: 0.7202\n",
      "Epoch 935/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0262 - val_accuracy: 0.7872 - val_loss: 0.7161\n",
      "Epoch 936/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0174 - val_accuracy: 0.7872 - val_loss: 0.7199\n",
      "Epoch 937/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0248 - val_accuracy: 0.7872 - val_loss: 0.7194\n",
      "Epoch 938/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9985 - loss: 0.0166 - val_accuracy: 0.7872 - val_loss: 0.7243\n",
      "Epoch 939/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0244 - val_accuracy: 0.7872 - val_loss: 0.7142\n",
      "Epoch 940/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0198 - val_accuracy: 0.7872 - val_loss: 0.7216\n",
      "Epoch 941/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0198 - val_accuracy: 0.7872 - val_loss: 0.7226\n",
      "Epoch 942/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0202 - val_accuracy: 0.7872 - val_loss: 0.7256\n",
      "Epoch 943/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9929 - loss: 0.0267 - val_accuracy: 0.7872 - val_loss: 0.7240\n",
      "Epoch 944/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0204 - val_accuracy: 0.7872 - val_loss: 0.7222\n",
      "Epoch 945/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0231 - val_accuracy: 0.7872 - val_loss: 0.7309\n",
      "Epoch 946/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0177 - val_accuracy: 0.7872 - val_loss: 0.7231\n",
      "Epoch 947/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0195 - val_accuracy: 0.7872 - val_loss: 0.7305\n",
      "Epoch 948/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0193 - val_accuracy: 0.7872 - val_loss: 0.7257\n",
      "Epoch 949/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0217 - val_accuracy: 0.7872 - val_loss: 0.7365\n",
      "Epoch 950/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0244 - val_accuracy: 0.7872 - val_loss: 0.7296\n",
      "Epoch 951/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0209 - val_accuracy: 0.7872 - val_loss: 0.7327\n",
      "Epoch 952/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0186 - val_accuracy: 0.7872 - val_loss: 0.7307\n",
      "Epoch 953/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0264 - val_accuracy: 0.7872 - val_loss: 0.7269\n",
      "Epoch 954/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9960 - loss: 0.0261 - val_accuracy: 0.7872 - val_loss: 0.7528\n",
      "Epoch 955/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0227 - val_accuracy: 0.8298 - val_loss: 0.7351\n",
      "Epoch 956/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0322 - val_accuracy: 0.7872 - val_loss: 0.7543\n",
      "Epoch 957/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0202 - val_accuracy: 0.7872 - val_loss: 0.7320\n",
      "Epoch 958/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0191 - val_accuracy: 0.7872 - val_loss: 0.7407\n",
      "Epoch 959/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0195 - val_accuracy: 0.7872 - val_loss: 0.7423\n",
      "Epoch 960/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0205 - val_accuracy: 0.7872 - val_loss: 0.7377\n",
      "Epoch 961/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0165 - val_accuracy: 0.7872 - val_loss: 0.7383\n",
      "Epoch 962/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0149 - val_accuracy: 0.7872 - val_loss: 0.7382\n",
      "Epoch 963/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0178 - val_accuracy: 0.7872 - val_loss: 0.7418\n",
      "Epoch 964/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0208 - val_accuracy: 0.7872 - val_loss: 0.7397\n",
      "Epoch 965/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0242 - val_accuracy: 0.7872 - val_loss: 0.7435\n",
      "Epoch 966/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9964 - loss: 0.0258 - val_accuracy: 0.7872 - val_loss: 0.7442\n",
      "Epoch 967/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0186 - val_accuracy: 0.7872 - val_loss: 0.7439\n",
      "Epoch 968/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0236 - val_accuracy: 0.7872 - val_loss: 0.7444\n",
      "Epoch 969/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0162 - val_accuracy: 0.7872 - val_loss: 0.7461\n",
      "Epoch 970/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0213 - val_accuracy: 0.7872 - val_loss: 0.7432\n",
      "Epoch 971/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0237 - val_accuracy: 0.7872 - val_loss: 0.7400\n",
      "Epoch 972/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0197 - val_accuracy: 0.7872 - val_loss: 0.7503\n",
      "Epoch 973/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0182 - val_accuracy: 0.7872 - val_loss: 0.7448\n",
      "Epoch 974/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0223 - val_accuracy: 0.7872 - val_loss: 0.7515\n",
      "Epoch 975/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0185 - val_accuracy: 0.7872 - val_loss: 0.7470\n",
      "Epoch 976/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0179 - val_accuracy: 0.7872 - val_loss: 0.7458\n",
      "Epoch 977/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0239 - val_accuracy: 0.7872 - val_loss: 0.7608\n",
      "Epoch 978/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0150 - val_accuracy: 0.7872 - val_loss: 0.7512\n",
      "Epoch 979/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0190 - val_accuracy: 0.7872 - val_loss: 0.7611\n",
      "Epoch 980/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0188 - val_accuracy: 0.7872 - val_loss: 0.7507\n",
      "Epoch 981/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0178 - val_accuracy: 0.7872 - val_loss: 0.7502\n",
      "Epoch 982/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0178 - val_accuracy: 0.7872 - val_loss: 0.7519\n",
      "Epoch 983/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0171 - val_accuracy: 0.7872 - val_loss: 0.7609\n",
      "Epoch 984/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0228 - val_accuracy: 0.7872 - val_loss: 0.7457\n",
      "Epoch 985/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0201 - val_accuracy: 0.7872 - val_loss: 0.7596\n",
      "Epoch 986/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0192 - val_accuracy: 0.7872 - val_loss: 0.7519\n",
      "Epoch 987/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0205 - val_accuracy: 0.7872 - val_loss: 0.7632\n",
      "Epoch 988/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0197 - val_accuracy: 0.7872 - val_loss: 0.7603\n",
      "Epoch 989/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0191 - val_accuracy: 0.7872 - val_loss: 0.7647\n",
      "Epoch 990/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0150 - val_accuracy: 0.7872 - val_loss: 0.7541\n",
      "Epoch 991/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0173 - val_accuracy: 0.7872 - val_loss: 0.7595\n",
      "Epoch 992/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0135 - val_accuracy: 0.7872 - val_loss: 0.7614\n",
      "Epoch 993/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0203 - val_accuracy: 0.7872 - val_loss: 0.7541\n",
      "Epoch 994/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0205 - val_accuracy: 0.7872 - val_loss: 0.7713\n",
      "Epoch 995/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0169 - val_accuracy: 0.7872 - val_loss: 0.7590\n",
      "Epoch 996/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0203 - val_accuracy: 0.7872 - val_loss: 0.7660\n",
      "Epoch 997/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0219 - val_accuracy: 0.7872 - val_loss: 0.7723\n",
      "Epoch 998/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0169 - val_accuracy: 0.7872 - val_loss: 0.7546\n",
      "Epoch 999/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0189 - val_accuracy: 0.7872 - val_loss: 0.7665\n",
      "Epoch 1000/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0187 - val_accuracy: 0.7872 - val_loss: 0.7697\n"
     ]
    }
   ],
   "source": [
    "history = model_tf.fit(X_train.values, y_train_enc, epochs=1000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,300</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m1,300\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m101\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64,805</span> (253.15 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m64,805\u001b[0m (253.15 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,601</span> (84.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,601\u001b[0m (84.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">43,204</span> (168.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m43,204\u001b[0m (168.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_tf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7468 - loss: 1.0727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1307544708251953, 0.7435897588729858]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tf.evaluate(X_test, y_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history, which='loss'):\n",
    "    plt.plot(history.history[which], label='train')\n",
    "    try:\n",
    "        plt.plot(history.history['val_'+which], label='validation')\n",
    "    except:\n",
    "        None\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(which)\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAGwCAYAAACzXI8XAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/GU6VOAAAACXBIWXMAAA9hAAAPYQGoP6dpAABMcklEQVR4nO3deXxTVcI+8OdmT9qmK92gQFlk3xRkAH+OC4uiuIzjjMLMC868OioqDuM6jgo6iKMO4igvjvOO2zvivo4gWlFhQHYBQVlEWSpQytamaZvkJvf8/jhN2tAC5SbNTeD5fj6lyc3NzckJ7X16tqsIIQSIiIiIUpDJ6AIQERER6cUgQ0RERCmLQYaIiIhSFoMMERERpSwGGSIiIkpZDDJERESUshhkiIiIKGVZjC5AW9M0DXv37kVGRgYURTG6OERERNQKQgjU1NSguLgYJtOx211O+SCzd+9elJSUGF0MIiIi0qG8vBwdOnQ45uOnfJDJyMgAICvC7XbH7biqquKTTz7B6NGjYbVa43Zcao51nRis58RgPScO6zox2qqePR4PSkpKIufxYznlg0y4O8ntdsc9yLhcLrjdbv6AtDHWdWKwnhOD9Zw4rOvEaOt6PtGwEA72JSIiopTFIENEREQpi0GGiIiIUtYpP0aGiIhOHaFQCKqqtmpfVVVhsVjg8/kQCoXauGSnL731bLVaYTabY359BhkiIkp6QghUVFSgqqrqpJ5TWFiI8vJyriPWhmKp56ysLBQWFsb0+TDIEBFR0guHmPz8fLhcrlad+DRNg9frRXp6+nEXVKPY6KlnIQTq6upQWVkJACgqKtL9+gwyRESU1EKhUCTE5Obmtvp5mqYhEAjA4XAwyLQhvfXsdDoBAJWVlcjPz9fdzcRPloiIklp4TIzL5TK4JBRv4c+0teOeWsIgQ0REKYHjXE498fhMGWSIiIgoZTHIEBERUcpikCEiIkoBnTt3xuzZs40uRtLhrCWdjtQFcMgHeOpV5PJiZERE1ILzzjsPAwcOjEsAWb16NdLS0mIv1CmGLTI6/bVsOx5aZ8HLK3YbXRQiIkpRQggEg8FW7duuXTvO3GoBg4xO4YHWwthiEBGdloQQqAsET/hVHwi1ar+T+RKidb/5J02ahMWLF+Opp56CoihQFAUvvvgiFEXBRx99hLPOOgt2ux1Lly7F999/j8svvxwFBQVIT0/HkCFD8Omnn0Yd7+iuJUVR8L//+7+48sor4XK50L17d3zwwQfxrOaUwK4lIiJKOfVqCL0f+NiQ1/72oTFw2U58+nzqqaewbds29O3bFw899BAA4JtvvgEA3HPPPXjiiSfQpUsXZGdno7y8HGPHjsWMGTNgt9vx8ssvY9y4cdi6dSs6dux4zNeYPn06HnvsMTz++ON4+umnMWHCBOzatQs5OTnxebMpgC0yOkVmvrNJhoiIWpCZmQmbzQaXy4XCwkIUFhZGVq996KGHMGrUKHTt2hU5OTkYMGAAfve736Fv377o3r07Hn74YXTt2vWELSyTJk3Ctddei27duuGRRx6B1+vFqlWrEvH2kgZbZHRq7FpikiEiSjSn1YxvHxpz3H00TUONpwYZ7oy4XqLAaY39is2DBw+Ouu/1ejFt2jTMnz8f+/btQzAYRH19PXbvPv44zP79+0dup6Wlwe12R65fdLpgkNFJaWiTaWVXKRERxZGiKCfs3tE0DUGbGS6bJemutXT07KM77rgDZWVleOKJJ9CtWzc4nU78/Oc/RyAQOO5xrEfNmlUUBZqmxb28yYxBRicO9iUiohOx2WwIhUIn3G/ZsmWYNGkSrrzySgCyhWbnzp1tXLpTQ3JF1BQSHiPDFhkiIjqWzp07Y+XKldi5cycOHjx4zNaS7t2745133sH69euxYcMGjB8//rRrWdGLQUavhiYZjpEhIqJjueOOO2A2m9G7d2+0a9fumGNeZs2ahezsbAwfPhzjxo3DmDFjcOaZZya4tKmJXUs6cdYSERGdyBlnnIHly5dHbZs0aVKz/Tp37ozPPvssatvkyZOj7h/d1dTSejZVVVW6ypnK2CKjE8fIEBERGY9BRieOkSEiIjIeg4xOCsfIEBERGc7QILNkyRKMGzcOxcXFUBQF7733XtTjQgg88MADKCoqgtPpxMiRI/Hdd98ZU9ijsEWGiIjIeIYGmdraWgwYMABz5sxp8fHHHnsMf/vb3/Dss89i5cqVSEtLw5gxY+Dz+RJc0uY4RoaIiMh4hs5auvjii3HxxRe3+JgQArNnz8af/vQnXH755QCAl19+GQUFBXjvvfdwzTXXJLKox9Taq6ASERFR/CXt9OsdO3agoqICI0eOjGzLzMzE0KFDsXz58mMGGb/fD7/fH7nv8XgAAKqqQlXVuJVPNCxUFAppcT0uNReuX9Zz22I9Jwbr+eSpqgohBDRNO6lF4sJ/aIafS20jlnrWNA1CCKiqGrmgZlhrf0aSNshUVFQAAAoKCqK2FxQURB5rycyZMzF9+vRm2z/55BO4XK64lW/XLhMAE3bu2oUFC3bE7bh0bGVlZUYX4bTAek4M1nPrWSwWFBYWwuv1nvDaQy2pqalpg1LR0fTUcyAQQH19PZYsWYJgMBj1WF1dXauOkbRBRq97770XU6dOjdz3eDwoKSnB6NGj4Xa74/Y6Gz/aAuzdjU4dO2Ls2N5xOy41p6oqysrKMGrUqGYXSKP4YT0nBuv55Pl8PpSXlyM9PR0Oh6PVzxNCoKamBhkZGZGZpqmmS5cumDJlCqZMmQIAMJvNePvtt3HFFVe0uP/OnTvRtWtXrF27FgMHDtT9uidznFjq2efzwel04txzz2322YZ7VE4kaYNMYWEhAGD//v0oKiqKbN+/f/9xK9Vut8NutzfbbrVa4/pLI9wEpphM/GWUIPH+DKllrOfEYD23XigUgqIoMJlMJ3UV63A3R/i5qapp+fft24fs7Oxjvp/w9pOpq0mTJqGqqipq5nCnTp2wb98+5OXlnfA4sdSzyWSCoigt/jy09ucjaT/Z0tJSFBYWYtGiRZFtHo8HK1euxLBhwwwsWTQO9SUiokQpLCxs8Y/1eDObzSgsLITFkrTtHRGGBhmv14v169dj/fr1AOQA3/Xr12P37t1QFAW33347/vznP+ODDz7Axo0b8V//9V8oLi4+ZpNaIqVoKyURESXIc889h+Li4mYDYC+//HL85je/wffff4/LL78cBQUFSE9Px5AhQ/Dpp58e95hHr7m2atUqDBo0CA6HA4MHD8a6deui9g+FQvjtb3+L0tJSOJ1O9OjRA0899VTk8WnTpuGll17C+++/D0VRoCgKvvjiC+zcuROKokTOzwCwePFinH322bDb7SgqKsI999wTNa7lggsuwG233Ya77roLOTk5KCwsxLRp006+4k6SoVFrzZo1OP/88yP3w2NbJk6ciBdffBF33XUXamtrccMNN6CqqgrnnHMOFi5ceFJ9pG2FC+IRERlICEA9wWBQTZP7BMxAPLuWrK5W/TV79dVX49Zbb8Xnn3+OCy+8EABw+PBhLFy4EAsWLIDX68XYsWMxY8YM2O12vPzyyxg3bhy2bt2Kjh07nvD4Xq8Xl156KUaNGoV//etf2LFjR2QsTZimaejQoQPefPNN5Obm4ssvv8QNN9yAoqIi/OIXv8Add9yBzZs3w+Px4IUXXgAA5OTkYO/evVHH2bNnD8aOHYtJkybh5ZdfxpYtW3D99dfD4XDggQceiOz30ksvYerUqVi5ciWWL1+OSZMmYcSIERg1atQJ349ehgaZ884777jrsCiKgoceeggPPfRQAkvVSlwQj4jIOGod8EjxcXcxAchqi9f+417AlnbC3bKzs3HxxRdj3rx5kSDz1ltvIS8vD+effz5MJhMGDBgQ2f/hhx/Gu+++iw8++AC33HLLCY8/b948aJqGf/7zn3A4HOjTpw9+/PFH3HTTTZF9rFZr1Eze0tJSLF++HG+88QZ+8YtfID09HU6nE36/PzI2tSX/8z//g5KSEjzzzDNQFAU9e/bE3r17cffdd+NPf/pTZL/+/fvjwQcfBAB0794dzzzzDBYtWtSmQSZpx8gkOyWSZBhliIioZRMmTMDbb78dWd/slVdewTXXXAOTyQSv14s77rgDvXr1QlZWFtLT07F582bs3r27VcfevHkz+vfvH9VL0dIY0jlz5uCss85Cu3btkJ6ejueee67Vr9H0tYYNGxY1K2nEiBHwer348ccfI9v69+8f9byioiJUVlae1GudrOQfxZOkeIkCIiIDWV2yZeQ4NE2Dp6YG7oyM+M5asrZ+TbJx48ZBCIH58+djyJAh+M9//oMnn3wSAHDHHXegrKwMTzzxBLp16wan04mf//znutbKOZbXXnsNd9xxB/76179i2LBhyMjIwOOPP46VK1fG7TWaOnqmkaIobb4YIYOMThwjQ0RkIEU5cfeOpgHWkNzPoOnXDocDP/vZz/DKK69g+/bt6NGjB84880wAwLJlyzBp0iRceeWVAOSYl507d7b62L169cL//d//wefzRVplVqxYEbXPsmXLMHz4cNx8882Rbd9//33UPjabDaFQ6ISv9fbbb0MIEWmVWbZsGTIyMtChQwd4vd5Wlzve2LWkU2OLDJMMEREd24QJEzB//nw8//zzmDBhQmR79+7d8c4772D9+vXYsGEDxo8ff1KtF+PHj4eiKLj++uvx7bffYsGCBXjiiSei9unevTvWrFmDjz/+GNu2bcP999+P1atXR+3TuXNnfP3119i6dSsOHjzY4qUBbr75ZpSXl+PWW2/Fli1b8P777+PBBx/E1KlTDV+jh0FGp/AYGbbIEBHR8VxwwQXIycnB1q1bMX78+Mj2WbNmITs7G8OHD8e4ceMwZsyYSGtNa6Snp+Pf//43Nm7ciEGDBuG+++7DX/7yl6h9fve73+FnP/sZfvnLX2Lo0KE4dOhQVOsMAFx//fXo0aMHBg8ejHbt2mHZsmXNXqt9+/ZYsGABVq1ahQEDBuDGG2/Eb3/726iBvkZh15JeHCNDREStYDKZmk1nBmRLyGeffRa1bfLkyVH3j+5qOnqm709+8pOotV6O3sdut+OFF16ITK0OmzlzZuR2u3bt8MknnzQr39Gv9dOf/hSrVq1qtl+4Femzzz5r1jrTdM2btsIWGZ04RoaIiMh4DDI6NU5BY5IhIiIyCoOMTmyRISIiMh6DjE5cR4aIiMh4DDI6sUWGiCixjndJG0pN8fhMGWR0Co+R4ToyRERtK7xabF3dCS4SSSkn/JkevSLwyeD06xjxDwQiorZlNpuRlZUVuWaPy+WKuubPsWiahkAgAJ/PZ/iibacyPfUshEBdXR0qKyuRlZUFs9ms+/UZZGLEHENE1PbCV2Y+mQsQCiFQX18Pp9PZquBD+sRSz1lZWce96nZrMMjopHCQDBFRwiiKgqKiIuTn57e4hH5LVFXFkiVLcO6558bUdUHHp7eerVZrTC0xYQwyOjHcExElntlsbvXJz2w2IxgMwuFwMMi0IaPrmZ2GOvFaS0RERMZjkNGJ68gQEREZj0FGJw6RISIiMh6DjE5cR4aIiMh4DDIxYosMERGRcRhkdOIYGSIiIuMxyOgUmX3NJENERGQYBhmdOEaGiIjIeAwyOnHWEhERkfEYZHTiGBkiIiLjMcjo1NgiwyhDRERkFAYZvSJjZIiIiMgoDDI6cYwMERGR8RhkdOLVr4mIiIzHIKNT49Wv2SRDRERkFAaZGDHGEBERGYdBRqfI9GsmGSIiIsMwyOgUGezLNhkiIiLDMMjoxMG+RERExmOQ0S082NfgYhAREZ3GGGR04iUKiIiIjMcgo1OkZ4lJhoiIyDAMMjo1tsgwyRARERmFQUYnhWNkiIiIDMcgoxPHyBARERmPQUYnXjSSiIjIeAwyejU0yXCMDBERkXEYZHTirCUiIiLjMcjoxDEyRERExmOQ0alxjAyjDBERkVEYZHRSImNkiIiIyCgMMjpx1hIREZHxGGRixBxDRERkHAYZnSKDfdkkQ0REZBgGGSIiIkpZDDI6RQb7skGGiIjIMAwyOkUG+xpaCiIiotNbUgeZUCiE+++/H6WlpXA6nejatSsefvjhpBiXoign3oeIiIjalsXoAhzPX/7yF8ydOxcvvfQS+vTpgzVr1uC6665DZmYmbrvtNkPLpiDctWR8qCIiIjpdJXWQ+fLLL3H55ZfjkksuAQB07twZr776KlatWmVwyXiJAiIiomSQ1EFm+PDheO6557Bt2zacccYZ2LBhA5YuXYpZs2Yd8zl+vx9+vz9y3+PxAABUVYWqqnErWygUAgBomojrcam5cP2yntsW6zkxWM+Jw7pOjLaq59YeTxFJ3DeiaRr++Mc/4rHHHoPZbEYoFMKMGTNw7733HvM506ZNw/Tp05ttnzdvHlwuV9zKtumwgn9sNaNTusDUfqG4HZeIiIiAuro6jB8/HtXV1XC73cfcL6lbZN544w288sormDdvHvr06YP169fj9ttvR3FxMSZOnNjic+69915MnTo1ct/j8aCkpASjR48+bkWcLOs3+4CtG+F2uzF27LC4HZeaU1UVZWVlGDVqFKxWq9HFOWWxnhOD9Zw4rOvEaKt6DveonEhSB5k777wT99xzD6655hoAQL9+/bBr1y7MnDnzmEHGbrfDbrc32261WuNawRZLQ9UpCn9AEiTenyG1jPWcGKznxGFdJ0a867m1x0rq6dd1dXUwmaKLaDaboWmaQSVq1HiJAmPLQUREdDpL6haZcePGYcaMGejYsSP69OmDdevWYdasWfjNb35jdNGaLIjHJENERGSUpA4yTz/9NO6//37cfPPNqKysRHFxMX73u9/hgQceMLpovEQBERFREkjqIJORkYHZs2dj9uzZRhelmUiLDIMMERGRYZJ6jExS44J4REREhmOQ0UkBR/sSEREZjUEmRowxRERExmGQ0YnTr4mIiIzHIKNT541Po8x2Jy4JLDC6KERERKetpJ61lMzsvgPobNoDt9a6JZSJiIgo/tgio1dD35LCUTJERESGYZDRTTnxLkRERNSmGGT0CrfIcLQvERGRYRhkYsYgQ0REZBQGGb0UWXUcI0NERGQcBhm9lMbrXxMREZExGGRixRxDRERkGAYZnRQlXHWaoeUgIiI6nTHI6KY0+ZeIiIiMwCCjV/haS8aWgoiI6LTGIBMjriNDRERkHAYZvSJjZBhkiIiIjMIgo5MCXmuJiIjIaAwyOjG+EBERGY9BRiclvCCe4PRrIiIiozDI6BW5RAEREREZhUEmZuxkIiIiMgqDjF4KB/sSEREZjUFGr8gYGQYZIiIiozDI6KSw6oiIiAzHs7FeSvgbW2SIiIiMwiCjG8fIEBERGY1BRqfIOjIMMkRERIZhkNErfK0l5hgiIiLDMMjEjEmGiIjIKAwyeilR34iIiMgADDI6NU6/ZosMERGRURhk9OLKvkRERIZjkNGLs5aIiIgMxyCjE3MMERGR8RhkdJNVx64lIiIi4zDI6MYxMkREREZjkNGLfUtERESGY5DRK7yOjGCQISIiMgqDjF4Kl8IjIiIyGoOMTlwQj4iIyHgMMnpxQTwiIiLDMcjopPAqS0RERIZjkNErkmPYIkNERGQUBhndGrqWmGOIiIgMwyCjk8IxMkRERIZjkNGLC+IREREZjkFGL7bIEBERGY5BRifOWiIiIjIeg4xebJEhIiIyHIOMThzsS0REZDwGGb0iQQYQvHAkERGRIZI+yOzZswe/+tWvkJubC6fTiX79+mHNmjVGFwuNK+IJMMcQEREZw2J0AY7nyJEjGDFiBM4//3x89NFHaNeuHb777jtkZ2cbXbSoMTLMMURERMZI6iDzl7/8BSUlJXjhhRci20pLSw0sUSOlWdcSZzERERElWlIHmQ8++ABjxozB1VdfjcWLF6N9+/a4+eabcf311x/zOX6/H36/P3Lf4/EAAFRVhaqqcStbSJPtMAoEAqoKoSV9L13KCn9u8fz8qDnWc2KwnhOHdZ0YbVXPrT2eIpJ4pKrD4QAATJ06FVdffTVWr16NKVOm4Nlnn8XEiRNbfM60adMwffr0ZtvnzZsHl8sVt7IV7/8MQ/a+iI9CQ1B35q2wMMcQERHFTV1dHcaPH4/q6mq43e5j7pfUQcZms2Hw4MH48ssvI9tuu+02rF69GsuXL2/xOS21yJSUlODgwYPHrYiTVffl35H5+X1YGBqCc/44H3YmmTajqirKysowatQoWK1Wo4tzymI9JwbrOXFY14nRVvXs8XiQl5d3wiCT1F1LRUVF6N27d9S2Xr164e233z7mc+x2O+x2e7PtVqs1rhVsMcuqUyBgsVhgtZrjdmxqWbw/Q2oZ6zkxWM+Jw7pOjHjXc2uPldTNCCNGjMDWrVujtm3btg2dOnUyqERNKLLquCAeERGRcZI6yPz+97/HihUr8Mgjj2D79u2YN28ennvuOUyePNnooh21IJ6xRSEiIjpdJXWQGTJkCN599128+uqr6Nu3Lx5++GHMnj0bEyZMMLpoTS4aKbiSDBERkUGSeowMAFx66aW49NJLjS5Gc00XxGOOISIiMkRSt8gks6YL4hEREZExGGT04iUKiIiIDMcgo1N4jIzsWmKUISIiMgKDjF5NZy0ZWxIiIqLTFoOMTgoH+xIRERmOQUavJkGGTTJERETGYJDRSWkyX4nDfYmIiIzBIKOX0lh17FoiIiIyhq4g89JLL2H+/PmR+3fddReysrIwfPhw7Nq1K26FSwWcfk1ERGQcXUHmkUcegdPpBAAsX74cc+bMwWOPPYa8vDz8/ve/j2sBk1X0YF9GGSIiIiPoukRBeXk5unXrBgB47733cNVVV+GGG27AiBEjcN5558WzfElL4fRrIiIiw+lqkUlPT8ehQ4cAAJ988glGjRoFAHA4HKivr49f6ZIZp18TEREZTleLzKhRo/Df//3fGDRoELZt24axY8cCAL755ht07tw5nuVLXlEtMkwyRERERtDVIjNnzhwMGzYMBw4cwNtvv43c3FwAwNq1a3HttdfGtYDJqyHIKFxHhoiIyCi6WmSysrLwzDPPNNs+ffr0mAuUMnjRSCIiIsPpapFZuHAhli5dGrk/Z84cDBw4EOPHj8eRI0fiVrjk1mRBPCYZIiIiQ+gKMnfeeSc8Hg8AYOPGjfjDH/6AsWPHYseOHZg6dWpcC5i0olpkmGSIiIiMoKtraceOHejduzcA4O2338all16KRx55BF999VVk4O+pj7OWiIiIjKarRcZms6Gurg4A8Omnn2L06NEAgJycnEhLzamP68gQEREZTVeLzDnnnIOpU6dixIgRWLVqFV5//XUAwLZt29ChQ4e4FjBpNb36NRERERlCV4vMM888A4vFgrfeegtz585F+/btAQAfffQRLrroorgWMNnxEgVERETG0dUi07FjR3z44YfNtj/55JMxFygVMccQEREZQ1eQAYBQKIT33nsPmzdvBgD06dMHl112Gcxmc9wKl9SarOxLRERExtAVZLZv346xY8diz5496NGjBwBg5syZKCkpwfz589G1a9e4FjI5cdYSERGR0XSNkbntttvQtWtXlJeX46uvvsJXX32F3bt3o7S0FLfddlu8y5iclHBbDNeRISIiMoquFpnFixdjxYoVyMnJiWzLzc3Fo48+ihEjRsStcMmtyfRr5hgiIiJD6GqRsdvtqKmpabbd6/XCZrPFXKiUwGstERERGU5XkLn00ktxww03YOXKlRBCTj9esWIFbrzxRlx22WXxLmOSajpGhlGGiIjICLqCzN/+9jd07doVw4YNg8PhgMPhwPDhw9GtWzfMnj07zkVMUgpX9iUiIjKarjEyWVlZeP/997F9+/bI9OtevXqhW7ducS1ccuOsJSIiIqO1Osic6KrWn3/+eeT2rFmz9JcoVUStI8MkQ0REZIRWB5l169a1aj9FOV2WiGOLDBERkdFaHWSatrgQjlpHhoiIiIyga7AvAVxHhoiIyHgMMno16UFjmwwREZExGGRixDEyRERExmGQ0Y2DfYmIiIzGIKNX1IJ4TDJERERGYJDRrbFFhoiIiIzBIKOXwq4lIiIiozHI6Ha6LPxHRESUvBhk9GKLDBERkeEYZHRrEmQ4ToaIiMgQDDJ6KVzZl4iIyGgMMro1bZEhIiIiIzDI6BU1RoZRhoiIyAgMMro1XRCPiIiIjMAgo1tDkFE4a4mIiMgoDDJ6RS0jwyRDRERkBAaZOGCLDBERkTEYZHTjrCUiIiKjMcjoJLiyLxERkeEYZHRruiAekwwREZERGGT0Uti1REREZLSUCjKPPvooFEXB7bffbnRREDVGhkmGiIjIECkTZFavXo2///3v6N+/v9FFkZpea4ltMkRERIawGF2A1vB6vZgwYQL+8Y9/4M9//vNx9/X7/fD7/ZH7Ho8HAKCqKlRVjVuZgsEQrJAtMsFgMK7HpmjhumUdty3Wc2KwnhOHdZ0YbVXPrT2eIlJgpOrEiRORk5ODJ598Eueddx4GDhyI2bNnt7jvtGnTMH369Gbb582bB5fLFbcyZdSX44It9+GAcOPFrnNwRmbSVyMREVHKqKurw/jx41FdXQ23233M/ZK+Rea1117DV199hdWrV7dq/3vvvRdTp06N3Pd4PCgpKcHo0aOPWxEnK7h3I7BFdi2dffbZGN41N27HpmiqqqKsrAyjRo2C1Wo1ujinLNZzYrCeE4d1nRhtVc/hHpUTSeogU15ejilTpqCsrAwOh6NVz7Hb7bDb7c22W63W+P5HbjiWAgGz2cIfkgSI+2dILWI9JwbrOXFY14kR73pu7bGSOsisXbsWlZWVOPPMMyPbQqEQlixZgmeeeQZ+vx9ms9mg0jWdfs1uJSIiIiMkdZC58MILsXHjxqht1113HXr27Im7777bwBCD6FlLzDFERESGSOogk5GRgb59+0ZtS0tLQ25ubrPtidd4+WvmGCIiImOkzDoyyUouiMcoQ0REZISkbpFpyRdffGF0ESQl/I0jZIiIiIzCFhndGsfIMMkQEREZg0FGL0VWHWctERERGYdBRi+FF40kIiIyGoOMbgwyRERERmOQ0SvStcQhMkREREZhkNGroWvJBI3Tr4mIiAzCIKMXW2SIiIgMxyCjW3iMjMYxMkRERAZhkNGrybWW2CZDRERkDAYZ3ZqOkTG4KERERKcpBhm9ml792tiSEBERnbYYZPRqGOxrUhhjiIiIjMIgo5sSuSU0hhkiIiIjMMjopTRWnYBmYEGIiIhOXwwyeimNLTLQGGSIiIiMwCCjV1SLDLuWiIiIjMAgoxtbZIiIiIzGIKNX064ltsgQEREZgkFGL46RISIiMhyDjG5Npl9z1hIREZEhGGT0ajLYl9coICIiMgaDjF4KF8QjIiIyGoOMXpx+TUREZDgGGd2aDvYNGVcMIiKi0xiDjF5R06+JiIjICAwyekUN9uWsJSIiIiMwyOjWpEWGQYaIiMgQDDJ6NZ21xCBDRERkCAaZGGjgOBkiIiIjMcjEQDQEGa4jQ0REZAwGmRhEgozg9GsiIiIjMMjEINIOw0sUEBERGYJBJgaiofoEr35NRERkCAaZGITbYTTOWiIiIjIEg0wMwi0yGltkiIiIDMEgEwOOkSEiIjIWg0wMGqdfc9YSERGRERhkYhKefm1wMYiIiE5TDDIxCLfIcLAvERGRMRhkYhAOMrxoJBERkTEYZGIgGi4cqfESBURERIZgkIlBY4sMB/sSEREZgUEmJrxoJBERkZEYZGKgRWYtcYwMERGRERhk4oBBhoiIyBgMMjFoHCPDriUiIiIjMMjEgOvIEBERGYtBJhYKB/sSEREZiUEmBlwQj4iIyFgMMjGIXDSSY2SIiIgMwSATAy6IR0REZCwGmZjw6tdERERGYpCJQTi/aGyRISIiMkRSB5mZM2diyJAhyMjIQH5+Pq644gps3brV6GJFCKWh+tgkQ0REZIikDjKLFy/G5MmTsWLFCpSVlUFVVYwePRq1tbVGFy2axllLRERERrAYXYDjWbhwYdT9F198Efn5+Vi7di3OPffcFp/j9/vh9/sj9z0eDwBAVVWoqhq3sqmqCtGQA0NaKK7HpmjhumUdty3Wc2KwnhOHdZ0YbVXPrT1eUgeZo1VXVwMAcnJyjrnPzJkzMX369GbbP/nkE7hcrriWZ2jD9wOVlViwYEFcj03NlZWVGV2E0wLrOTFYz4nDuk6MeNdzXV1dq/ZTRIosgqJpGi677DJUVVVh6dKlx9yvpRaZkpISHDx4EG63O27lUVUV1X8djKLQHszp8FfcMHFi3I5N0VRVRVlZGUaNGgWr1Wp0cU5ZrOfEYD0nDus6Mdqqnj0eD/Ly8lBdXX3c83fKtMhMnjwZmzZtOm6IAQC73Q673d5su9Vqjft/ZNFwiQIo4A9JArTFZ0jNsZ4Tg/WcOKzrxIh3Pbf2WCkRZG655RZ8+OGHWLJkCTp06GB0cZrgyr5ERERGSuogI4TArbfeinfffRdffPEFSktLjS5SlMZLFHDWEhERkRGSOshMnjwZ8+bNw/vvv4+MjAxUVFQAADIzM+F0Og0uHRBukVEYZIiIiAyR1OvIzJ07F9XV1TjvvPNQVFQU+Xr99deNLhqAJi0yGruWiIiIjJDULTJJP/YkPNgXbJEhIiIyQlK3yCQ7wcG+REREhmKQiQMGGSIiImMwyMQg3CIDDvYlIiIyBINMDMIL4rFFhoiIyBgMMjHh9GsiIiIjMcjEhAviERERGYlBJgaRay2xa4mIiMgQDDIx4RgZIiIiIzHIxCA8a+n3VY8ANRUGl4aIiOj0wyATAwVNWmI2vWNcQYiIiE5TDDIxyFP3RW6HHFnGFYSIiOg0xSATg3StOnJ7xfeVBpaEiIjo9MQgEyeVh6tPvBMRERHFFYNMnFg0v9FFICIiOu0wyMSJOcQgQ0RElGgMMnHCFhkiIqLEY5CJE6H6jC4CERHRaYdBJl6C9UaXgIiI6LTDIBODBR3vjdzmGBkiIqLEY5CJgZrbCxv73A2AY2SIiIiMwCATI1daGgAGGSIiIiMwyMTIYnPJ7wwyRERECccgEyOTzQkAsIqAwSUhIiI6/TDIxMhsdwAAbIItMkRERInGIBMja0PXko0tMkRERAnHIBMji70hyCCAYEgzuDRERESnFwaZGNkcMsg4FBW+IIMMERFRIjHIxMja0CLjQAB+NWRwaYiIiE4vDDIxUmxysK8DAfjZIkNERJRQDDKxssgg41QC8AWCBheGiIjo9GIxugApz+KM3PT7fQAyjCsLERFRvAgBKErj/VAQCHgBRyawZy0Q9AFCQPHsg1017sLJDDKxsjoiN721XgDtjCsLERFRU5oGiBBwZCeghYB5VwNVu4FhtwCdhgMhFfB7AJ8HqD8MVJUD9UeA8lWAvxrI6QIc/uG4L2EB0K7T7xLydo71+hQLkxUaFJggcKS62ujSEBFRKhMCEBoABTi4Vd6v2AjU7JXbzFYgswPw4xqg7hBQPAjwVsrwUX8YUOuBik1AWq7cf+9XLb/O8mfk14mcIMQAgMjpCk0xn8y7jCsGmVgpClTFDrvwodpTY3RpiIjICJoGmEyA3wsc2QEEA7IlJOgHDm0H6g4CafkyfKyYC9jSgNJzgV1fAoe+O+pgCgDRutdd/0rL26t3H/95GUVAWh5gSwfsbsDhBhQTULMPyO8ju43s6UBmR9ma4/cA/X8h30NtJWDPkK01VbsRzO6OvQs/xsDWlTjuGGTiIGSyAyEfqmsYZIiIkpKmAaFA43AAIWQrhmcPYHXJgAEA+zc1TOJQgJBftnAoZnnb55En8Z3LZPhwZssTur9GHutk1EIGnhYdJ8RkFAM2lyyX0IC8M4DszoDVKceuWJ2ye6hdTxlUIABXLlDQT95WTIAr5+TK2kzPxpuF/QBVjfF4sWGQiYOgNQ0IVWP1N9/huisEzCblxE8iIqLW0zQZOtLayTCyfZE8med0AbwVjSf2usNATQVQtQuW3Stw6ZHdMO3tCRz+HlDr5EndbAd8VfJ+LOqPtBxgTBYgvVC2YkCR3TxCAzJL5GM/fA7kdgO6jwHMFmDLAqDjUBk+rE6g/WDZXZTXDXC3l60jjszYynoKY5CJA1E0CNixF2f4vsbWihr0LnYbXSQiosTweYDaA0BuV9nKodbJbpOmjuyS32sPAHvXyZaCUBDYt162fhT1B6p/BAK18uQfDADV5YCvGqivkq0hh7Y3Hs+RJYPICSgAzACwf2PjxnDLy9F7Otzy9cLHT2sHuIsBk1m2ulgc8ntaO3m78lugsD+Q2V7OXs3ujEjrhytXPq+1Rj10/Mct9tYf6zTEIBMHmb0vAHbMxzDTt9i638MgQ0SpxVcNHNwuT9S2NBko6o8A3v0yfAhNbj/8A6AFZatH3SEZLg5skcfoPhrY97V8TtGAhsCgNMyIqYpzeZscz5EpZ+PklMqA4cyWXUjuDtCqduHAoWrk9RoGc153OS7EmSUDV0aRDCoWBwAhg4do6NJR2KqeShhk4qHzuQCAs0zf4a/lB3DloA4GF4iITln7vwW+fg3I6ggMnCADQ0iV3Sm+Kjleo+6QbBkJBeWgz4PbZVeGdz9wYCvgypaDPBu6YKDFYTHP7z5pvL1vfcv7mG2yK6j2oGyVcRcDrjzg4DY5bsPdXgYTk0UGDme2HFxqdcquo+zOsnXCWynHhqTlHrdIIVXFigULMHbUWJit1hO/BwaYlMQgEw953eGz58HhP4h9GxfDd3F/OKzGTUUjIgOE/5pvuoiYEHLmSk2FbNn4cTWUwkFof2QFTF9uBwobZocoClC5RbZehAKy5aNh1XCEAvLEr9YDnr1ybY+w+X9offnKVzTebmlGi8UpX0tosmXG2RB2TGYZMoIBIK+7bP1Ia+g+cebILqCcLrJs6QVAdiegeo88ZnZneayMwjgMMG0it2v8jkUpj0EmHhQF5q7nAt++g5v8z+OJhaPwp3F9jC4V0eml9pCczWF1Nn8spEKuwdHwK8/vlWFh/zdAhyHy5CuEnLEiBLBjsew22bUM6HEJkNtFnsBrD8qWDnsGsPUjOV5CMQE/rpZreIQ5c+S0W7UOR89AsQAYDAA74/jeLQ7ZVWLPkK0r7XoA1jR52+GWrTf+Ghk08s6QLTOKIstvsshWkXZnyAG1isKWCUopDDJxYj1nCvDtO+ht2oUHVnyKsq55GNW7wOhiESUnTUNkXEJLavbLaa75feRCYIe2AzuWAENvkuHg0HcyLAhNLpV+6Htg1d/lc3teKrsl1v1LdktoavTMEmsaoNZGv55ialiErAUr5pz8+2saao4ioEBTLDALFcjt3jgw1myTIaP2gBxjYnXIVhKLXQYQe4YMaeHumN1fNkyxbQgj8QgfJl5+j1IPg0y8FA8E+v8S+Pp1XKIsw/Uvd8O5Z7TD9Mv6oDQv7YRPJ4qbULCx5SEe/F65MBYgA4GmyS4QbyWw5d9Aj7HyBPz950DVTqBoELDmn7JrIruz7I7wHpAn4frDcr8fPm88viNL7msyyxNyePBoS/7z1xOXd8uHjbdrK5s/fnSIARpDjNUlA8XRg1M7ndMwc8UuB8I63DJkpOXKsBTyy1aR3G6yqygtX4aj9HZyDZL0Ark6a35PBE0OLFiwAGPHjoW1NeM2jqXrBfqfS3QKYZCJp35XA1+/jl/ZvsDn2plYsq0fzn/iCwwsycLoPgXonp+Bn3TJQYYjhl9edGqrr5InRKtDnjCFkPcDXtnKAMjrpNjd8r6/pmFqq5DdBxvflOMmBv9GtkyYrcDal+Qy5UNvalzGvGYf8O37gLsD0PdK4PAOWA7/gH5aMcxvvQFs/VCGivAgUJNVtmy05MunY3vPvip9s1oUkwxAUOSqqXKjvH6MI0sGlswSAEJOEe55iXyOLU2O/QipQMmQhuBSLceHZBTLEBhepTWeSobI7wYvHkZ0qmGQiaeuFwDdRsG6vQwv22bia8dgPOcZhiXl/fBYeVVkty55aRjYMQs/6ZKL9llO9CzMQE6aDQr7pRMvFAQ2zAO6jZRN9i0J1MnWhPDn4/PIFTkL+soTo6I0v0ps0C9PjkLI9THUWjlY0uEGvn5dLuZV0Ee25AXqgMrNMihs/zT6ta0uGSj8HjkGomZf42PphXIhsJaseV5+NfXRnc338/wYCSIKgC74FghngqYzWY4VYlriym2+VodikiuAOrJk68fO/8iWCkcmMPg6WUfFg2RAEyE5HkVoso7ye8v3nZ4vt9vSZPho2i0V9MvXMOv8I+HocTXsYiFKGQwy8WQyA7/8P+Cju4GvXkZ/3xo8Y1sDACi3lmJPMBOHgzYcrMrEN0c646V1pQjBhAqRjUJrLZSMQmRnpKMww4LsrGwUpZvQLtOFwgwbCuwBpKdnIFOphzVUL3/xmu0nnH7YKqGgLHtrg5TqaziRNPll7/fK1gF3UfS+R5/gNU2eoDS14cRja3xc0+RJ3myVf2mX/lSWy1eNzgcWAZ4BQLAO2LYQOOMiYPdyuXbF/k3yL2xHppxKunOZXCXTbGuyIqYiB3ZWbpYn0epyObag9kDz99fhbHltEatD/kVfvqrxRJ7XQ17ILYrS0C1ilc8JBYFAKy5XcWRHdDdIi3XdZOXRpiEGOHaICbO7ZT1W7Wrcll4og0B1uWyByCyRASIUgKjajR2iPTp16QazvwbI7ym7Q/LOkPVY2E+2EmUUyq6S8AJhQpO3wyuPhj/PoF+GIasr9vEbjhOszcQFw4hOWwwy8WZ1Apf9DRgxBVg/D/j6DaB6N0rUHSgBGpaZPIY6IFhrgmW/hsMiHZmQfflm5fgXDwvCgh0dLofVmY6sg2sRSO+AnH3/gZZ7Biy+Q0B2Z5gObD7qpK3IdRxUX+NJ15EFdD5HnuC++0S2MKUXyL+w64/IVoSmJ8+CvvJkuf+b6Cmh+X1kPexZ07gto7jh6q0tsGUAwfpjrmVhBTAAAJ5+qXHjounHrROsnHv8x4GWQwwA/Liq8XbVUdNUm4UYABCy7FpQvo+T1f4sObg1Pb/xSrVmu2whyuooP4ND24EB18jPomafDB+BWhkg8rrLWTPphXL2jcUuP8ujA+QJWhmCqoqNCxagZGQr19w4EYsdAAMGEbUtBpm2ktsVuPB++VVTAexcKv+63fkf2UpRe0D20WtqVDO8RZGDDnMUb6tfyoIguv/4duOGI5vk9/3r5PcWr4Iqmp/IfVXRLQTff3b8F96/qeXtld8033asEAO0rvUiFhnFcjBmdml0uGrKliGn7tYdkouM7d8kuzE6DpODT8NrYBQNlK0Te9c3hobcbjLw5J3RcF2UeiCrk2z5qK+S41vyezWuz6H6ZMvN0a1Vseh9+fEfZ1cJEZ2iGGQSIaMQ6Pdz+dWSQJ0cB1FbKZvj/TWyW8TmkuMIFBOQ1g6h+iocqdiFvT4bjlTsRHrN98jZ8zlKDy3Bate5qNTcGBhYC00oEELD0mAvnGnajoPCjQPIwkBlOzSYkK7Uo1Y4EIQZAVixV8juqe7Kj1gnuiMP1UhX6vGd1gE7RSGylRpkoA4OJYA8VKOPaSc2ia6othfhsJKFs4LrEIIZGkxwOuzwZHSFoigIBAUyHWYE7NnIClTApCjQzHaEskvh1yxw55cgXy2HpaAXLJ4fAbUOwp6JH2sVFBSXwFZbAdjdCNZVYeXmcgwd8VNYLFYZfByZstXBYpe3g37ZjRJomJES7opQ61teVyRRMgqbbwtffZdjooiIYsYgkwxsLvk98/iXNjBn5CMvIx95ANBvQMPWqQCAIS3sf2UghKCmIUcNwXGoDntUDdlpVvihYPM+D/ZU1UMI4KDXD4fVhIXeAH6sqkddIIiQBvjVEKrqVQSCGnxqCEHtqC6uQPjGZY3b6gAcewmNFvQAoMFm7gCTCfCp4bU86lGaVwyXzQyHJRsVB7Ngr/ADCCCoKShw+3G4thyjehfikPcQMp1WdMr1wh/UkGa3oNDtg91igt1qgt0SgN1iQl0ghMO1AXTKdcFmMUFRFKzfXYXdh+swaXhnOG1cjZmIKNUwyJzC5InZjAyHFfkZjqjHTvbClkII1AVkmLGZTdh9uA57q+shhIACBV5/EJoQ2FNVjyO1AXjq5XiXejWEWn8QNf4gvL4gDtX6YbeYoYY0HPIGEAjJ4BIIaUAo+jV3HGy63ocC1DUOfN19WN7+fvH3J/U+juUvC7fAZjEBAujSLg1upxV2iwkOq7lh5XkBRVGQn2FHVZ2KH6vq0a+9G+3SHbBZTHBaTXDazNAEkO2ywh/UYFIUmBQFXr+KTKcNLpsZAsAhrx8hTaBXkRtd26XDalZgMZvgU0PYuKcah7x+9C7KhNNmRl569Gw2j0+FSVGQbm/5R7f8cB08PhV9ijPjUi9ERMmOQYZaRVEUpDU5efYozECPwoyYjimEQCCkoT4QQo0vCCEaT9RevwxCdYEgvPUBLF31FTp07Yl0hxW7D9fDpAD7qn2AAtT4GgcJ1wfkbX9Qg1/V4A+G4G9oUaquV6EJwGY2RQJUU4Gg3LalonVjdjY0mVIfK6tZgRpqPqjbZjZBUYB0uwUdclzYWuFBSBPo2i4dpXlpUEMaFEVBfSCENLsZizZXIqgJXDmoPfoUu2E2KdhzpB61gRDOKEiHy2aG02aBXw1h56Fa2C1m9G3vhhBARVUdDtQAOw/VwmKxQhMCmibw45F65Kbb4HZYERICxZlO1PhkXQaCGjrmupqVWwiBg94A2mVwsC8RtS0GGTKMoiiwW8ywW8zIctmOuZ+qqgjtEhh7bmlsK6FCnmAVRYFPDaGqTkW6wxJpYdKEQFWdCk+9ino1hLpAEEFNtjgpChDSBCqqfUizW5DtsmJLRQ0CIRmYfA37mxQFR+oCsFvM8AVDOOj1w2Iywd7QlVUfCMJqNiGoCez3+FAXkM1QLYUYAJHA5Q8GcKg20peHLRU1xw1c767bg3fX7dFRQxbM3rTspJ7hspnhspnhVzXU+IMozUuLtKblpdvgdsrPzKwoKHA7cNDrR20giCynDbnpNljNJtjMJljNCqxmE9SQhmXfH0JJthP5GQ4oCtCryA2TAjisZjhtZmQ3/H8xKQrsFhMO1QYa6jOILnnpyHBYkOGwIsNhgdcfhKdehctmQbsMOyxmBVaTCb5gCGl2C9JtFjhsJpgVBQKIfH7hVi8F4csPcUwTUTJKiSAzZ84cPP7446ioqMCAAQPw9NNP4+yzzza6WJSCwicjh9WMwszGMTHd8tMTXpZgSIMvqEENavAFQ/CpGoqzHLCaTNi0txq56XYcqQ1AUYADNX74VA1WswJNAD41hP0eH+oDIaQ7LEizW7CvyoecNBkatlTUwOMLQtMETCYFChq7+YKagFlRkO6w4Nu9HrhsZhyqDUABoKl+BBRLpFtMCAFPQ4uXqeFkHjpqrFRdIBQJZEB0l+BBbwAHvY0B7LvKxtl45Tj+VPUDNf7I7Y82nWDNnDZiUuQlHxUAuel2pNtl8D1UG4DbYYHTZobZpMBsUmAxKahXQ7CZTZHnuJ1WKAA8viCsZhnc3Q4zdpSb8Pr+NchOtyPbZYXVbIIQiIQ+IQQ0ISAEkGaXnwcAhDQN5YfrsWlvNYoyHeiQ7UKPwgxYTAqCmkCGwwIFCqxmBYqiwGJW4PUFcaDGD4fVjI45roZWT8BqNskQaTFFwqS8rUQeCwQ11PhVaBpkAGzYT1GATXuq8V2lFwe9fvz0jHbo1z4T3+7zoF2GHT0KMmA2Kc3CX60/iC0VNRhYkoWQJlCvhpDp5ErnFJukDzKvv/46pk6dimeffRZDhw7F7NmzMWbMGGzduhX5+flGF49IN4vZhHSzqcWlVvp3yAIAtM9K3IwrVVUbrgE0JqrlSw1pMCsKQkIgpAnU+IJw2szyZKvJFoz6hq47k6JADckuPYfFDH9Qg9kkW8BkkAohw2GB1WzCkboALCbZpaaGNKghDYGQBjUoUOHxwWJSUOsPwhcMwd1wWQ+vP4gaXxD1qgxOIU3Ap4aQk2ZDut2C6noVRxpa1WwWE2r9QaQ7LHBYzPD6g9hXXS9PrkKOIasPhFrsZgwLZzYBGayahquDXn/LT2oVE3DkpEbFN/PNXk9Mz4+nl5fvanG72STHc2magKIAvqAW6cJtKsNhQbpdBnJNCFTXqch0WWFWFGQ4LBCQqxXI4Woich8ABAS8viAyXTbkNIRCuV2ORzt02IzZ25aissaPbvnp6JSbBgEZCkOagMvWGBQVBdCEgNNqhqIAdosZFpMCk0mJBMvwfp56OfYtfN+kyBZCRVEab0eOiUhoDFPQ8BxT9HNMTVr/vL4gMp1WKIqsS5MiA3OoofUYkH+UmZo8Hv4e2WaSLZACAodrAzJUmxTku+0wm0xyv6blNjWGz3BAb1o/ChQICNT6Q7CaFfn6QkNdy8uAJUTSB5lZs2bh+uuvx3XXXQcAePbZZzF//nw8//zzuOeee5rt7/f74fc3/oLxeOQPu6qqUON4jZPwseJ5TGoZ6zoxjlfP4fYWM4AshwkNpxTADLgyw92CBk5zj0EgKIOXJoCgJuCwmOAPahBCNIyv0uC0mXG4VgY2n6rB7bDA4wvKk6EAQiGBkJCBDEBk/BAgENKAkBCoqVeR5bLBU+/Hzu3bcNaAvvAGNFTVqQhq8iRZ45d1Hz6xKIoMb8GQgAIZfrNcVrRLt6HC48dXu6uQ6ZS/xk2KghpfEP6gBotZgRBAUNPgslmQ47KissaPGp8clJ/usAACCDSEyECwSZAMich9s0mBzWxChsOCoCb3rfWHoAmBokwH9nv8svtVkSfmoyc2hjSB6voT/9zW+IJRY90ARHWltsqhumM8oABe+diGH6ux4cfqY+xHsbimi4LL4/w7urW/8xUhRMud80kgEAjA5XLhrbfewhVXXBHZPnHiRFRVVeH9999v9pxp06Zh+vTmq77OmzcPLlfzQYlERNSypi0QYTKYATZzkxYrAWiQYSYkgKAmo25QA3yhxucrABxmoDYob2dY5W0BwB8C/KGGrl+zQI2qRI4RDkrhY6DJfQCoD8rXD79u+DFzQ0tJfVCWI8MK1IfQ0Aoh96sPNYaw8OuoGiCgIKjJ7RoAU7gehAz2FkXuF+5+DLcYRb43rT8AwYZ6iarfJnV39PPC790UDokNZdSEbOlxWATqggrsJhF5niYAIZTI8cJlDw/BS7cIWE1AfUiJ1JV8TnQZmpYtFGkJa3wMkJ+/GpL1alKAKzpr+El+fONEXV0dxo8fj+rqarjdx55pm9QtMgcPHkQoFEJBQUHU9oKCAmzZsqXF59x7772YOnVq5L7H40FJSQlGjx593Io4WaqqoqysDKNGjYp5ACodH+s6MVjPicF6ThzWdWK0VT2He1ROJKmDjB52ux12e/NBB1artU3+I7fVcak51nVisJ4Tg/WcOKzrxIh3Pbf2WEl9AZa8vDyYzWbs378/avv+/ftRWNjC0u9ERER0WknqIGOz2XDWWWdh0aJFkW2apmHRokUYNmyYgSUjIiKiZJD0XUtTp07FxIkTMXjwYJx99tmYPXs2amtrI7OYiIiI6PSV9EHml7/8JQ4cOIAHHngAFRUVGDhwIBYuXNhsADARERGdfpI+yADALbfcgltuucXoYhAREVGSSeoxMkRERETHwyBDREREKYtBhoiIiFIWgwwRERGlLAYZIiIiSlkMMkRERJSyGGSIiIgoZTHIEBERUcpKiQXxYiGEAND6y4G3lqqqqKurg8fj4VVV2xjrOjFYz4nBek4c1nVitFU9h8/b4fP4sZzyQaampgYAUFJSYnBJiIiI6GTV1NQgMzPzmI8r4kRRJ8Vpmoa9e/ciIyMDiqLE7bgejwclJSUoLy+H2+2O23GpOdZ1YrCeE4P1nDis68Roq3oWQqCmpgbFxcUwmY49EuaUb5ExmUzo0KFDmx3f7XbzByRBWNeJwXpODNZz4rCuE6Mt6vl4LTFhHOxLREREKYtBhoiIiFIWg4xOdrsdDz74IOx2u9FFOeWxrhOD9ZwYrOfEYV0nhtH1fMoP9iUiIqJTF1tkiIiIKGUxyBAREVHKYpAhIiKilMUgQ0RERCmLQUanOXPmoHPnznA4HBg6dChWrVpldJFSysyZMzFkyBBkZGQgPz8fV1xxBbZu3Rq1j8/nw+TJk5Gbm4v09HRcddVV2L9/f9Q+u3fvxiWXXAKXy4X8/HzceeedCAaDiXwrKeXRRx+Foii4/fbbI9tYz/GxZ88e/OpXv0Jubi6cTif69euHNWvWRB4XQuCBBx5AUVERnE4nRo4cie+++y7qGIcPH8aECRPgdruRlZWF3/72t/B6vYl+K0krFArh/vvvR2lpKZxOJ7p27YqHH3446lo8rGd9lixZgnHjxqG4uBiKouC9996Lejxe9fr111/j//2//weHw4GSkhI89thjsRde0El77bXXhM1mE88//7z45ptvxPXXXy+ysrLE/v37jS5ayhgzZox44YUXxKZNm8T69evF2LFjRceOHYXX643sc+ONN4qSkhKxaNEisWbNGvGTn/xEDB8+PPJ4MBgUffv2FSNHjhTr1q0TCxYsEHl5eeLee+814i0lvVWrVonOnTuL/v37iylTpkS2s55jd/jwYdGpUycxadIksXLlSvHDDz+Ijz/+WGzfvj2yz6OPPioyMzPFe++9JzZs2CAuu+wyUVpaKurr6yP7XHTRRWLAgAFixYoV4j//+Y/o1q2buPbaa414S0lpxowZIjc3V3z44Ydix44d4s033xTp6eniqaeeiuzDetZnwYIF4r777hPvvPOOACDefffdqMfjUa/V1dWioKBATJgwQWzatEm8+uqrwul0ir///e8xlZ1BRoezzz5bTJ48OXI/FAqJ4uJiMXPmTANLldoqKysFALF48WIhhBBVVVXCarWKN998M7LP5s2bBQCxfPlyIYT8wTOZTKKioiKyz9y5c4Xb7RZ+vz+xbyDJ1dTUiO7du4uysjLx05/+NBJkWM/xcffdd4tzzjnnmI9rmiYKCwvF448/HtlWVVUl7Ha7ePXVV4UQQnz77bcCgFi9enVkn48++kgoiiL27NnTdoVPIZdccon4zW9+E7XtZz/7mZgwYYIQgvUcL0cHmXjV6//8z/+I7OzsqN8bd999t+jRo0dM5WXX0kkKBAJYu3YtRo4cGdlmMpkwcuRILF++3MCSpbbq6moAQE5ODgBg7dq1UFU1qp579uyJjh07Rup5+fLl6NevHwoKCiL7jBkzBh6PB998800CS5/8Jk+ejEsuuSSqPgHWc7x88MEHGDx4MK6++mrk5+dj0KBB+Mc//hF5fMeOHaioqIiq58zMTAwdOjSqnrOysjB48ODIPiNHjoTJZMLKlSsT92aS2PDhw7Fo0SJs27YNALBhwwYsXboUF198MQDWc1uJV70uX74c5557Lmw2W2SfMWPGYOvWrThy5Iju8p3yF42Mt4MHDyIUCkX9UgeAgoICbNmyxaBSpTZN03D77bdjxIgR6Nu3LwCgoqICNpsNWVlZUfsWFBSgoqIisk9Ln0P4MZJee+01fPXVV1i9enWzx1jP8fHDDz9g7ty5mDp1Kv74xz9i9erVuO2222Cz2TBx4sRIPbVUj03rOT8/P+pxi8WCnJwc1nODe+65Bx6PBz179oTZbEYoFMKMGTMwYcIEAGA9t5F41WtFRQVKS0ubHSP8WHZ2tq7yMciQ4SZPnoxNmzZh6dKlRhfllFNeXo4pU6agrKwMDofD6OKcsjRNw+DBg/HII48AAAYNGoRNmzbh2WefxcSJEw0u3anjjTfewCuvvIJ58+ahT58+WL9+PW6//XYUFxeznk9j7Fo6SXl5eTCbzc1mdezfvx+FhYUGlSp13XLLLfjwww/x+eefo0OHDpHthYWFCAQCqKqqitq/aT0XFha2+DmEHyPZdVRZWYkzzzwTFosFFosFixcvxt/+9jdYLBYUFBSwnuOgqKgIvXv3jtrWq1cv7N69G0BjPR3v90ZhYSEqKyujHg8Ggzh8+DDrucGdd96Je+65B9dccw369euHX//61/j973+PmTNnAmA9t5V41Wtb/S5hkDlJNpsNZ511FhYtWhTZpmkaFi1ahGHDhhlYstQihMAtt9yCd999F5999lmz5sazzjoLVqs1qp63bt2K3bt3R+p52LBh2LhxY9QPT1lZGdxud7OTyunqwgsvxMaNG7F+/frI1+DBgzFhwoTIbdZz7EaMGNFs+YBt27ahU6dOAIDS0lIUFhZG1bPH48HKlSuj6rmqqgpr166N7PPZZ59B0zQMHTo0Ae8i+dXV1cFkij5tmc1maJoGgPXcVuJVr8OGDcOSJUugqmpkn7KyMvTo0UN3txIATr/W47XXXhN2u128+OKL4ttvvxU33HCDyMrKiprVQcd30003iczMTPHFF1+Iffv2Rb7q6uoi+9x4442iY8eO4rPPPhNr1qwRw4YNE8OGDYs8Hp4WPHr0aLF+/XqxcOFC0a5dO04LPoGms5aEYD3Hw6pVq4TFYhEzZswQ3333nXjllVeEy+US//rXvyL7PProoyIrK0u8//774uuvvxaXX355i9NXBw0aJFauXCmWLl0qunfvftpPC25q4sSJon379pHp1++8847Iy8sTd911V2Qf1rM+NTU1Yt26dWLdunUCgJg1a5ZYt26d2LVrlxAiPvVaVVUlCgoKxK9//WuxadMm8dprrwmXy8Xp10Z5+umnRceOHYXNZhNnn322WLFihdFFSikAWvx64YUXIvvU19eLm2++WWRnZwuXyyWuvPJKsW/fvqjj7Ny5U1x88cXC6XSKvLw88Yc//EGoqprgd5Najg4yrOf4+Pe//y369u0r7Ha76Nmzp3juueeiHtc0Tdx///2ioKBA2O12ceGFF4qtW7dG7XPo0CFx7bXXivT0dOF2u8V1110nampqEvk2kprH4xFTpkwRHTt2FA6HQ3Tp0kXcd999UdN5Wc/6fP755y3+Tp44caIQIn71umHDBnHOOecIu90u2rdvLx599NGYy64I0WRJRCIiIqIUwjEyRERElLIYZIiIiChlMcgQERFRymKQISIiopTFIENEREQpi0GGiIiIUhaDDBEREaUsBhkiIiJKWQwyRHTaURQF7733ntHFIKI4YJAhooSaNGkSFEVp9nXRRRcZXTQiSkEWowtARKefiy66CC+88ELUNrvdblBpiCiVsUWGiBLObrejsLAw6is7OxuA7PaZO3cuLr74YjidTnTp0gVvvfVW1PM3btyICy64AE6nE7m5ubjhhhvg9Xqj9nn++efRp08f2O12FBUV4ZZbbol6/ODBg7jyyivhcrnQvXt3fPDBB237pomoTTDIEFHSuf/++3HVVVdhw4YNmDBhAq655hps3rwZAFBbW4sxY8YgOzsbq1evxptvvolPP/00KqjMnTsXkydPxg033ICNGzfigw8+QLdu3aJeY/r06fjFL36Br7/+GmPHjsWECRNw+PDhhL5PIoqDmK+fTUR0EiZOnCjMZrNIS0uL+poxY4YQQggA4sYbb4x6ztChQ8VNN90khBDiueeeE9nZ2cLr9UYenz9/vjCZTKKiokIIIURxcbG47777jlkGAOJPf/pT5L7X6xUAxEcffRS390lEicExMkSUcOeffz7mzp0btS0nJydye9iwYVGPDRs2DOvXrwcAbN68GQMGDEBaWlrk8REjRkDTNGzduhWKomDv3r248MILj1uG/v37R26npaXB7XajsrJS71siIoMwyBBRwqWlpTXr6okXp9PZqv2sVmvUfUVRoGlaWxSJiNoQx8gQUdJZsWJFs/u9evUCAPTq1QsbNmxAbW1t5PFly5bBZDKhR48eyMjIQOfOnbFo0aKElpmIjMEWGSJKOL/fj4qKiqhtFosFeXl5AIA333wTgwcPxjnnnINXXnkFq1atwj//+U8AwIQJE/Dggw9i4sSJmDZtGg4cOIBbb70Vv/71r1FQUAAAmDZtGm688Ubk5+fj4osvRk1NDZYtW4Zbb701sW+UiNocgwwRJdzChQtRVFQUta1Hjx7YsmULADmj6LXXXsPNN9+MoqIivPrqq+jduzcAwOVy4eOPP8aUKVMwZMgQuFwuXHXVVZg1a1bkWBMnToTP58OTTz6JO+64A3l5efj5z3+euDdIRAmjCCGE0YUgIgpTFAXvvvsurrjiCqOLQkQpgGNkiIiIKGUxyBAREVHK4hgZIkoq7O0mopPBFhkiIiJKWQwyRERElLIYZIiIiChlMcgQERFRymKQISIiopTFIENEREQpi0GGiIiIUhaDDBEREaWs/w/16TBnJsnLVgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So probably shouldn't go for 1000 epochs, there's overfitting there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to implement Early Stopping. It's a form of regularisation - to try to prevent overfitting, and it also will train our model more quickly.\n",
    "\n",
    "<a href=\"https://en.wikipedia.org/wiki/Early_stopping\">Wikipedia Link</a>\n",
    "\n",
    "<a href=\"https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/\">More Early Stopping Detail</a>\n",
    "\n",
    "<a href=\"https://towardsdatascience.com/early-stopping-a-cool-strategy-to-regularize-neural-networks-bfdeca6d722e\">Another Link</a>\n",
    "\n",
    "I mentioned it in lectures without going into any detail and will talk about it more next week.\n",
    "\n",
    "The basic idea is, monitor how well the validation set is performing after every epoch, if there has not been any improvement in its score for a while (say in 10 epochs or whatever you pick as your \"patience\" - we don't just say over 1 epoch as training could just be \"stuck\"). MLPClassifier in sklearn has it sort of implemented and we saw it  above \"Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\"\n",
    "\n",
    "It is added as a callback function that checks for what we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful with restore_best_weights see https://medium.com/@doleron/never-use-restore-best-weights-true-with-earlystopping-754ba5f9b0c6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callback_modelcheckpoint_loss = tf.keras.callbacks.ModelCheckpoint(filepath='best_model_loss.keras', monitor='val_loss', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf2.compile(\n",
    "     optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5807 - loss: 11.1623 - val_accuracy: 0.5106 - val_loss: 3.9312\n",
      "Epoch 2/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6480 - loss: 2.6728 - val_accuracy: 0.8511 - val_loss: 0.9598\n",
      "Epoch 3/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7681 - loss: 1.2616 - val_accuracy: 0.8723 - val_loss: 0.5424\n",
      "Epoch 4/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7832 - loss: 0.8196 - val_accuracy: 0.8723 - val_loss: 0.5303\n",
      "Epoch 5/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8104 - loss: 0.6826 - val_accuracy: 0.8723 - val_loss: 0.4884\n",
      "Epoch 6/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8303 - loss: 0.5636 - val_accuracy: 0.8511 - val_loss: 0.4848\n",
      "Epoch 7/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8474 - loss: 0.5829 - val_accuracy: 0.8936 - val_loss: 0.4646\n",
      "Epoch 8/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8315 - loss: 0.6091 - val_accuracy: 0.8298 - val_loss: 0.7665\n",
      "Epoch 9/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7380 - loss: 0.9605 - val_accuracy: 0.8723 - val_loss: 0.4091\n",
      "Epoch 10/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8299 - loss: 0.4841 - val_accuracy: 0.8723 - val_loss: 0.4922\n",
      "Epoch 11/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7518 - loss: 0.7976 - val_accuracy: 0.8723 - val_loss: 0.3775\n",
      "Epoch 12/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7855 - loss: 0.6388 - val_accuracy: 0.8511 - val_loss: 0.3582\n",
      "Epoch 13/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7948 - loss: 0.6288 - val_accuracy: 0.7447 - val_loss: 0.9901\n",
      "Epoch 14/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7411 - loss: 1.0135 - val_accuracy: 0.7660 - val_loss: 1.1059\n",
      "Epoch 15/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7663 - loss: 0.7776 - val_accuracy: 0.8723 - val_loss: 0.3442\n",
      "Epoch 16/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8230 - loss: 0.4888 - val_accuracy: 0.8723 - val_loss: 0.3864\n",
      "Epoch 17/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8100 - loss: 0.5117 - val_accuracy: 0.8298 - val_loss: 0.5055\n",
      "Epoch 18/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7992 - loss: 0.6421 - val_accuracy: 0.7447 - val_loss: 0.7852\n",
      "Epoch 19/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7993 - loss: 0.7244 - val_accuracy: 0.8723 - val_loss: 0.3117\n",
      "Epoch 20/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8373 - loss: 0.4665 - val_accuracy: 0.8936 - val_loss: 0.3249\n",
      "Epoch 21/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8302 - loss: 0.3669 - val_accuracy: 0.8511 - val_loss: 0.3025\n",
      "Epoch 22/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7993 - loss: 0.5072 - val_accuracy: 0.8723 - val_loss: 0.2974\n",
      "Epoch 23/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8144 - loss: 0.3573 - val_accuracy: 0.8723 - val_loss: 0.3051\n",
      "Epoch 24/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8416 - loss: 0.3352 - val_accuracy: 0.8085 - val_loss: 0.4269\n",
      "Epoch 25/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8341 - loss: 0.3957 - val_accuracy: 0.8723 - val_loss: 0.3215\n",
      "Epoch 26/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8292 - loss: 0.4306 - val_accuracy: 0.8936 - val_loss: 0.3001\n",
      "Epoch 27/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7582 - loss: 0.5160 - val_accuracy: 0.8936 - val_loss: 0.3130\n",
      "Epoch 28/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8250 - loss: 0.4251 - val_accuracy: 0.8936 - val_loss: 0.3130\n",
      "Epoch 29/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7690 - loss: 0.5042 - val_accuracy: 0.8298 - val_loss: 0.4025\n",
      "Epoch 30/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7777 - loss: 0.5509 - val_accuracy: 0.7234 - val_loss: 1.1047\n",
      "Epoch 31/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7507 - loss: 0.7367 - val_accuracy: 0.8085 - val_loss: 0.5064\n",
      "Epoch 32/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7723 - loss: 0.6780 - val_accuracy: 0.7872 - val_loss: 0.6621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7ed1c333bb90>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tf2.fit(X_train.values, y_train_enc, epochs=1000, validation_split=0.2, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I said go for 1000 epochs, but will only go for a certain amount due to early stopping\n",
    "\n",
    "I also said to restore_best_weights, so it should be the model with the lowest val_loss that was found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7934 - loss: 0.3874 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4293298125267029, 0.7820512652397156]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tf2.evaluate(X_test, y_test_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may be worse than sklearn still\n",
    "\n",
    "Anything you run may be different due to randomisation of batches etc\n",
    "\n",
    "You can try adding regularisation. Using a different loss/optimizer and other things to improve your model. Also there is going to be some random chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 80,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
